2023-05-10 09:16:51,668 INFO    : Pytorch 1.13.1
2023-05-10 09:16:51,669 INFO    : [INFO] Create Vocab, vocab path is cache/tweet/vocab
2023-05-10 09:16:51,695 INFO    : [INFO] Finished constructing vocabulary of 30754 total words. Last word added: est:
2023-05-10 09:16:51,755 INFO    : [INFO] Loading external word embedding...
2023-05-10 09:17:25,945 INFO    : [INFO] External Word Embedding iov count: 23075, oov count: 7679
2023-05-10 09:17:26,058 INFO    : Namespace(atten_dropout_prob=0.1, batch_size=50, bert_path='bert_features_tweet', bidirectional=True, cache_dir='cache/tweet', cuda=True, data_dir='/mnt/data/ztl/MTGNN-SUM/data_tweet/exp_data', doc_max_timesteps=150, embed_train=False, embedding_path='glove.42B.300d.txt', feat_embed_size=50, ffn_dropout_prob=0.1, ffn_inner_hidden_size=512, gpu='3', grad_clip=True, hidden_size=64, log_root='log_tweet/', lr=0.0005, lr_descent=True, lstm_hidden_state=128, lstm_layers=2, m=15, max_grad_norm=1.0, model='MTHSG', n_epochs=100, n_feature_size=128, n_head=8, n_iter=1, n_layers=1, recurrent_dropout_prob=0.1, restore_model='None', save_root='models_tweet', seed=666, sent_max_len=100, use_orthnormal_init=True, vocab_size=50000, word_emb_dim=300, word_embedding=True)
2023-05-10 09:17:26,198 INFO    : [MODEL] HeterSumGraph 
2023-05-10 09:17:26,198 INFO    : [INFO] Start reading ExampleSet
2023-05-10 09:17:26,207 INFO    : [INFO] Finish reading ExampleSet. Total time is 0.009074, Total size is 9
2023-05-10 09:17:26,207 INFO    : [INFO] Loading filter word File cache/tweet/filter_word.txt
2023-05-10 09:17:26,216 INFO    : [INFO] Loading word2sent TFIDF file from cache/tweet/train.w2s.tfidf.jsonl!
2023-05-10 09:17:26,426 INFO    : [INFO] Start reading ExampleSet
2023-05-10 09:17:26,427 INFO    : [INFO] Finish reading ExampleSet. Total time is 0.000989, Total size is 1
2023-05-10 09:17:26,427 INFO    : [INFO] Loading filter word File cache/tweet/filter_word.txt
2023-05-10 09:17:26,437 INFO    : [INFO] Loading word2sent TFIDF file from cache/tweet/val.w2s.tfidf.jsonl!
2023-05-10 09:17:27,969 INFO    : [INFO] Use cuda
2023-05-10 09:17:27,969 INFO    : [INFO] Create new model for training...
2023-05-10 09:17:27,976 INFO    : [INFO] Starting run_training
2023-05-10 09:17:41,163 INFO    :        | end of iter   0 | time:  2.58s | train loss 0.5764 | 
2023-05-10 09:17:52,812 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.4068 | 
2023-05-10 09:18:04,417 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.3726 | 
2023-05-10 09:18:15,926 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2830 | 
2023-05-10 09:18:27,309 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2871 | 
2023-05-10 09:18:38,748 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.3570 | 
2023-05-10 09:18:50,166 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.3163 | 
2023-05-10 09:19:01,473 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2608 | 
2023-05-10 09:19:12,824 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.2614 | 
2023-05-10 09:19:24,088 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.2741 | 
2023-05-10 09:19:35,238 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2716 | 
2023-05-10 09:19:46,751 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.2594 | 
2023-05-10 09:19:58,061 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.2529 | 
2023-05-10 09:20:09,283 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2553 | 
2023-05-10 09:20:20,687 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.2533 | 
2023-05-10 09:20:32,441 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2512 | 
2023-05-10 09:20:43,956 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2501 | 
2023-05-10 09:20:55,432 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.2494 | 
2023-05-10 09:21:06,712 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2472 | 
2023-05-10 09:21:17,901 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.2475 | 
2023-05-10 09:21:29,171 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2455 | 
2023-05-10 09:21:40,549 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.2443 | 
2023-05-10 09:21:51,955 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2424 | 
2023-05-10 09:22:03,459 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2389 | 
2023-05-10 09:22:14,743 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2363 | 
2023-05-10 09:22:26,209 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2332 | 
2023-05-10 09:22:37,474 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2277 | 
2023-05-10 09:22:49,210 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2286 | 
2023-05-10 09:23:00,422 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2194 | 
2023-05-10 09:23:11,645 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2150 | 
2023-05-10 09:23:22,968 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2059 | 
2023-05-10 09:23:34,284 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2094 | 
2023-05-10 09:23:45,580 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1997 | 
2023-05-10 09:23:56,978 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.1937 | 
2023-05-10 09:24:08,506 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.1859 | 
2023-05-10 09:24:19,955 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.1794 | 
2023-05-10 09:24:31,668 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1687 | 
2023-05-10 09:24:43,350 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1718 | 
2023-05-10 09:24:55,114 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.1616 | 
2023-05-10 09:25:07,027 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.1555 | 
2023-05-10 09:25:18,468 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1457 | 
2023-05-10 09:25:29,669 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1434 | 
2023-05-10 09:25:40,978 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1339 | 
2023-05-10 09:25:52,487 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.1317 | 
2023-05-10 09:26:03,942 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.1235 | 
2023-05-10 09:26:15,430 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.1110 | 
2023-05-10 09:26:26,863 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.1000 | 
2023-05-10 09:26:38,291 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1174 | 
2023-05-10 09:26:49,662 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1037 | 
2023-05-10 09:27:00,840 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0857 | 
2023-05-10 09:27:00,840 INFO    : [INFO] The learning rate now is 0.000250
2023-05-10 09:27:00,840 INFO    :    | end of epoch   1 | time: 572.86s | epoch train loss 1129.2045 | 
2023-05-10 09:27:00,840 INFO    : [INFO] Found new best model with 1129.205 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:27:00,893 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:27:00,893 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:27:02,848 INFO    : [INFO] End of valid | time:  1.95s | valid loss 17.9547 | 
2023-05-10 09:27:02,848 INFO    : Rouge1:
	p:0.304569, r:0.218182, f:0.254237
Rouge2:
	p:0.086379, r:0.062350, f:0.072423
Rougel:
	p:0.263959, r:0.189091, f:0.220339

2023-05-10 09:27:02,848 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:27:02,848 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:27:02,848 INFO    : [INFO] Found new best model with 17.954659 running_avg_loss. The original loss is None, Saving to models_tweet/eval/bestmodel_0
2023-05-10 09:27:02,964 INFO    : [INFO] Found new best model with 0.105263 F. The original F is None, Saving to models_tweet/eval/bestFmodel
2023-05-10 09:27:14,752 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0834 | 
2023-05-10 09:27:26,172 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0749 | 
2023-05-10 09:27:37,369 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0746 | 
2023-05-10 09:27:48,748 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0704 | 
2023-05-10 09:28:00,047 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0651 | 
2023-05-10 09:28:11,375 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0643 | 
2023-05-10 09:28:22,575 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0596 | 
2023-05-10 09:28:33,803 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0569 | 
2023-05-10 09:28:45,116 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0522 | 
2023-05-10 09:28:56,446 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0497 | 
2023-05-10 09:29:07,697 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0455 | 
2023-05-10 09:29:19,017 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0440 | 
2023-05-10 09:29:30,681 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0411 | 
2023-05-10 09:29:42,038 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0402 | 
2023-05-10 09:29:53,706 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0383 | 
2023-05-10 09:30:05,196 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0374 | 
2023-05-10 09:30:16,533 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0357 | 
2023-05-10 09:30:28,056 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0342 | 
2023-05-10 09:30:39,427 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0336 | 
2023-05-10 09:30:50,775 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0326 | 
2023-05-10 09:31:02,096 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0317 | 
2023-05-10 09:31:13,343 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0305 | 
2023-05-10 09:31:24,810 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0281 | 
2023-05-10 09:31:36,159 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0263 | 
2023-05-10 09:31:47,438 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0244 | 
2023-05-10 09:31:58,784 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0232 | 
2023-05-10 09:32:10,040 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0267 | 
2023-05-10 09:32:21,434 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0202 | 
2023-05-10 09:32:32,730 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0210 | 
2023-05-10 09:32:43,992 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0193 | 
2023-05-10 09:32:55,414 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0189 | 
2023-05-10 09:33:06,725 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0186 | 
2023-05-10 09:33:17,923 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0176 | 
2023-05-10 09:33:29,286 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0172 | 
2023-05-10 09:33:40,710 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0171 | 
2023-05-10 09:33:52,125 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0168 | 
2023-05-10 09:34:03,247 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0161 | 
2023-05-10 09:34:14,788 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0157 | 
2023-05-10 09:34:26,164 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0153 | 
2023-05-10 09:34:37,543 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0148 | 
2023-05-10 09:34:48,954 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0145 | 
2023-05-10 09:35:00,163 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0139 | 
2023-05-10 09:35:11,764 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0136 | 
2023-05-10 09:35:22,949 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0118 | 
2023-05-10 09:35:34,237 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0314 | 
2023-05-10 09:35:45,526 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0127 | 
2023-05-10 09:35:56,771 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0069 | 
2023-05-10 09:36:08,255 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0258 | 
2023-05-10 09:36:19,701 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0232 | 
2023-05-10 09:36:31,132 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0063 | 
2023-05-10 09:36:31,132 INFO    : [INFO] The learning rate now is 0.000167
2023-05-10 09:36:31,132 INFO    :    | end of epoch   2 | time: 567.87s | epoch train loss 161.3246 | 
2023-05-10 09:36:31,132 INFO    : [INFO] Found new best model with 161.325 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:36:31,253 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:36:31,254 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:36:33,226 INFO    : [INFO] End of valid | time:  1.97s | valid loss 28.5944 | 
2023-05-10 09:36:33,226 INFO    : Rouge1:
	p:0.369792, r:0.258182, f:0.304069
Rouge2:
	p:0.076125, r:0.052758, f:0.062323
Rougel:
	p:0.281250, r:0.196364, f:0.231263

2023-05-10 09:36:33,226 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:36:33,226 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:36:44,446 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0066 | 
2023-05-10 09:36:55,621 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0062 | 
2023-05-10 09:37:06,783 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0056 | 
2023-05-10 09:37:17,987 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0054 | 
2023-05-10 09:37:29,453 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0054 | 
2023-05-10 09:37:40,648 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0053 | 
2023-05-10 09:37:51,936 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0051 | 
2023-05-10 09:38:03,255 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0049 | 
2023-05-10 09:38:14,659 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0047 | 
2023-05-10 09:38:26,139 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0046 | 
2023-05-10 09:38:37,464 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0046 | 
2023-05-10 09:38:48,883 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0044 | 
2023-05-10 09:39:00,141 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0043 | 
2023-05-10 09:39:11,318 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0041 | 
2023-05-10 09:39:22,777 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0040 | 
2023-05-10 09:39:34,323 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0039 | 
2023-05-10 09:39:45,672 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0037 | 
2023-05-10 09:39:57,120 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0037 | 
2023-05-10 09:40:08,622 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0036 | 
2023-05-10 09:40:19,925 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0034 | 
2023-05-10 09:40:31,337 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0033 | 
2023-05-10 09:40:42,787 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0032 | 
2023-05-10 09:40:54,147 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0032 | 
2023-05-10 09:41:05,626 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0031 | 
2023-05-10 09:41:17,245 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0030 | 
2023-05-10 09:41:28,707 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0029 | 
2023-05-10 09:41:40,259 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0028 | 
2023-05-10 09:41:52,136 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0027 | 
2023-05-10 09:42:04,265 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0027 | 
2023-05-10 09:42:15,758 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0026 | 
2023-05-10 09:42:27,223 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0025 | 
2023-05-10 09:42:38,825 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0024 | 
2023-05-10 09:42:50,426 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0023 | 
2023-05-10 09:43:01,894 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0023 | 
2023-05-10 09:43:13,359 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0022 | 
2023-05-10 09:43:24,769 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0021 | 
2023-05-10 09:43:36,170 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0021 | 
2023-05-10 09:43:47,656 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0020 | 
2023-05-10 09:43:58,870 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0020 | 
2023-05-10 09:44:10,312 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0019 | 
2023-05-10 09:44:21,578 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0018 | 
2023-05-10 09:44:33,022 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0018 | 
2023-05-10 09:44:44,436 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0017 | 
2023-05-10 09:44:55,745 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0017 | 
2023-05-10 09:45:06,964 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0016 | 
2023-05-10 09:45:18,569 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0016 | 
2023-05-10 09:45:30,009 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0015 | 
2023-05-10 09:45:41,588 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0015 | 
2023-05-10 09:45:53,781 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0014 | 
2023-05-10 09:46:05,350 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0014 | 
2023-05-10 09:46:05,350 INFO    : [INFO] The learning rate now is 0.000125
2023-05-10 09:46:05,350 INFO    :    | end of epoch   3 | time: 572.12s | epoch train loss 16.0957 | 
2023-05-10 09:46:05,351 INFO    : [INFO] Found new best model with 16.096 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:46:05,489 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:46:05,489 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:46:07,449 INFO    : [INFO] End of valid | time:  1.96s | valid loss 34.9757 | 
2023-05-10 09:46:07,449 INFO    : Rouge1:
	p:0.355450, r:0.272727, f:0.308642
Rouge2:
	p:0.106109, r:0.079137, f:0.090659
Rougel:
	p:0.322275, r:0.247273, f:0.279835

2023-05-10 09:46:07,449 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:46:07,450 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:46:19,103 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0014 | 
2023-05-10 09:46:30,922 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0013 | 
2023-05-10 09:46:42,339 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0013 | 
2023-05-10 09:46:53,792 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0013 | 
2023-05-10 09:47:05,156 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0013 | 
2023-05-10 09:47:16,539 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0012 | 
2023-05-10 09:47:28,020 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0012 | 
2023-05-10 09:47:39,289 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0012 | 
2023-05-10 09:47:50,562 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0012 | 
2023-05-10 09:48:01,807 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0011 | 
2023-05-10 09:48:13,087 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0011 | 
2023-05-10 09:48:24,506 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0011 | 
2023-05-10 09:48:35,746 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0011 | 
2023-05-10 09:48:47,016 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0010 | 
2023-05-10 09:48:58,286 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0010 | 
2023-05-10 09:49:09,512 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0010 | 
2023-05-10 09:49:20,868 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0010 | 
2023-05-10 09:49:32,170 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0009 | 
2023-05-10 09:49:43,378 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0009 | 
2023-05-10 09:49:54,754 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0009 | 
2023-05-10 09:50:06,075 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0009 | 
2023-05-10 09:50:17,413 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0009 | 
2023-05-10 09:50:28,733 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0008 | 
2023-05-10 09:50:40,114 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0008 | 
2023-05-10 09:50:51,321 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0008 | 
2023-05-10 09:51:02,627 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0008 | 
2023-05-10 09:51:13,924 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0008 | 
2023-05-10 09:51:25,270 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0008 | 
2023-05-10 09:51:36,524 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:51:47,755 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:51:58,934 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0007 | 
2023-05-10 09:52:10,190 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0007 | 
2023-05-10 09:52:21,637 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0007 | 
2023-05-10 09:52:32,914 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:52:44,297 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:52:55,800 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:53:07,083 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:53:18,476 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:53:29,734 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0006 | 
2023-05-10 09:53:41,133 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0006 | 
2023-05-10 09:53:52,601 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0006 | 
2023-05-10 09:54:04,142 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0006 | 
2023-05-10 09:54:15,326 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:54:26,962 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:54:38,247 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:54:49,562 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:55:00,738 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:55:11,798 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0005 | 
2023-05-10 09:55:23,114 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:55:34,484 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:55:34,485 INFO    : [INFO] The learning rate now is 0.000100
2023-05-10 09:55:34,485 INFO    :    | end of epoch   4 | time: 567.03s | epoch train loss 4.2509 | 
2023-05-10 09:55:34,485 INFO    : [INFO] Found new best model with 4.251 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:55:34,608 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:55:34,608 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:55:36,579 INFO    : [INFO] End of valid | time:  1.97s | valid loss 39.8251 | 
2023-05-10 09:55:36,579 INFO    : Rouge1:
	p:0.355450, r:0.272727, f:0.308642
Rouge2:
	p:0.106109, r:0.079137, f:0.090659
Rougel:
	p:0.317536, r:0.243636, f:0.275720

2023-05-10 09:55:36,579 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:55:36,579 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:55:47,961 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:55:59,094 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:56:10,469 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:56:22,000 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:56:33,244 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:56:44,400 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:56:55,647 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:57:06,943 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:57:18,361 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:57:29,685 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:57:40,968 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:57:52,273 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:03,529 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:14,815 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:26,139 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:37,365 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0004 | 
2023-05-10 09:58:48,619 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:59,838 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:11,262 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:22,449 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:33,787 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:45,078 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:56,421 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:00:07,882 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:00:19,177 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:00:30,483 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:00:41,747 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:00:52,996 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:01:04,277 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:01:15,629 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:01:26,964 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:01:38,585 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0004 | 
2023-05-10 10:01:50,187 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:02:01,621 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0004 | 
2023-05-10 10:02:13,077 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0004 | 
2023-05-10 10:02:24,499 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:02:35,867 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:02:47,264 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:02:58,522 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:03:09,891 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:03:21,262 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:03:32,609 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:03:43,942 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:03:55,203 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:04:06,425 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:04:17,704 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:04:28,982 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:04:40,585 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:04:51,901 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:05:03,183 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0003 | 
2023-05-10 10:05:03,183 INFO    : [INFO] The learning rate now is 0.000083
2023-05-10 10:05:03,183 INFO    :    | end of epoch   5 | time: 566.60s | epoch train loss 1.9553 | 
2023-05-10 10:05:03,183 INFO    : [INFO] Found new best model with 1.955 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:05:03,349 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:05:03,349 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:05:05,339 INFO    : [INFO] End of valid | time:  1.99s | valid loss 42.1063 | 
2023-05-10 10:05:05,339 INFO    : Rouge1:
	p:0.355450, r:0.272727, f:0.308642
Rouge2:
	p:0.106109, r:0.079137, f:0.090659
Rougel:
	p:0.317536, r:0.243636, f:0.275720

2023-05-10 10:05:05,339 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:05:05,339 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:05:16,709 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:05:27,983 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:05:39,373 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:05:50,768 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:06:01,957 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:06:13,407 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:06:24,724 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:06:36,016 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:06:47,197 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:06:58,508 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:07:09,819 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:07:21,050 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:07:32,444 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0003 | 
2023-05-10 10:07:43,672 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:07:55,102 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:08:06,465 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:08:17,851 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:08:29,109 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:08:40,414 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:08:51,656 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:03,033 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:14,312 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:25,375 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:36,505 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:47,994 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:09:59,434 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:10:10,682 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:10:21,863 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:10:33,319 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:10:44,834 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:10:56,145 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0003 | 
2023-05-10 10:11:07,455 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:11:18,808 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:11:30,159 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:11:41,822 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:11:53,282 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:12:04,447 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:12:15,848 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:12:27,240 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:12:38,639 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:12:50,091 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:13:01,762 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:13:13,076 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:13:24,531 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0002 | 
2023-05-10 10:13:35,819 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:13:47,167 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0002 | 
2023-05-10 10:13:58,532 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0002 | 
2023-05-10 10:14:09,752 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:14:21,318 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0002 | 
2023-05-10 10:14:32,599 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:14:32,599 INFO    : [INFO] The learning rate now is 0.000071
2023-05-10 10:14:32,600 INFO    :    | end of epoch   6 | time: 567.26s | epoch train loss 1.3300 | 
2023-05-10 10:14:32,600 INFO    : [INFO] Found new best model with 1.330 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:14:32,726 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:14:32,726 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:14:34,683 INFO    : [INFO] End of valid | time:  1.96s | valid loss 43.5524 | 
2023-05-10 10:14:34,683 INFO    : Rouge1:
	p:0.380282, r:0.294545, f:0.331967
Rouge2:
	p:0.113269, r:0.083933, f:0.096419
Rougel:
	p:0.342723, r:0.265455, f:0.299180

2023-05-10 10:14:34,683 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:14:34,683 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:14:45,802 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:14:56,907 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:15:08,210 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:15:19,709 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:15:31,156 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:15:42,538 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:15:53,823 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:05,143 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:16,531 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:27,752 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:16:39,004 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:50,554 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:17:02,027 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:17:13,406 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:17:24,677 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:17:36,015 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:17:47,294 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:17:58,675 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:09,906 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:21,500 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:18:32,862 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:44,082 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:55,499 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0002 | 
2023-05-10 10:19:06,884 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:19:18,366 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0002 | 
2023-05-10 10:19:29,903 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:19:41,333 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:19:52,563 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:20:04,010 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0002 | 
2023-05-10 10:20:15,354 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0002 | 
2023-05-10 10:20:26,655 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0002 | 
2023-05-10 10:20:37,758 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:20:49,212 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:21:00,547 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:21:11,845 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:21:23,070 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:21:34,496 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:21:45,795 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:21:57,213 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:22:08,559 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:22:19,917 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:22:31,261 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:22:42,465 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:22:53,693 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:23:05,291 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:23:16,687 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:23:27,965 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:23:39,359 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:23:50,689 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:24:01,954 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:24:01,954 INFO    : [INFO] The learning rate now is 0.000063
2023-05-10 10:24:01,955 INFO    :    | end of epoch   7 | time: 567.27s | epoch train loss 1.0350 | 
2023-05-10 10:24:01,955 INFO    : [INFO] Found new best model with 1.035 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:24:02,081 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:24:02,081 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:24:04,040 INFO    : [INFO] End of valid | time:  1.96s | valid loss 44.5473 | 
2023-05-10 10:24:04,040 INFO    : Rouge1:
	p:0.380282, r:0.294545, f:0.331967
Rouge2:
	p:0.113269, r:0.083933, f:0.096419
Rougel:
	p:0.342723, r:0.265455, f:0.299180

2023-05-10 10:24:04,040 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:24:04,041 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:24:15,397 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:24:26,866 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:24:38,276 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:24:49,771 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:01,088 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:12,395 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:23,631 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:34,748 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:46,051 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:57,426 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:08,759 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:20,003 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:31,235 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:26:42,501 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:53,855 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:27:05,091 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:27:16,334 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:27:27,778 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:27:39,287 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:27:50,633 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:28:01,917 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:13,104 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:24,387 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:35,638 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:46,793 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:58,055 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:09,236 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:20,572 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:31,735 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:43,137 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:29:54,390 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:05,614 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:16,877 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:28,144 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:39,403 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:50,619 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:01,889 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:13,283 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:31:24,543 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:35,883 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:47,128 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:58,775 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0002 | 
2023-05-10 10:32:10,322 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:32:21,759 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:32:33,088 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:32:44,408 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:32:55,685 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:33:06,945 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:33:18,505 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0002 | 
2023-05-10 10:33:29,896 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:33:29,896 INFO    : [INFO] The learning rate now is 0.000056
2023-05-10 10:33:29,896 INFO    :    | end of epoch   8 | time: 565.86s | epoch train loss 0.8569 | 
2023-05-10 10:33:29,897 INFO    : [INFO] Found new best model with 0.857 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:33:30,151 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:33:30,151 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:33:32,119 INFO    : [INFO] End of valid | time:  1.97s | valid loss 45.3476 | 
2023-05-10 10:33:32,119 INFO    : Rouge1:
	p:0.360577, r:0.272727, f:0.310559
Rouge2:
	p:0.114379, r:0.083933, f:0.096819
Rougel:
	p:0.326923, r:0.247273, f:0.281573

2023-05-10 10:33:32,119 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:33:32,119 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:33:43,586 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:33:55,035 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:06,430 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:17,800 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:29,126 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:40,272 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:34:51,448 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:35:02,739 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:35:13,965 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:35:25,238 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:35:36,588 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:35:48,008 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:35:59,580 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:36:10,737 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:36:21,898 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:36:33,384 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:36:44,865 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:36:56,174 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:37:07,625 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:37:18,948 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:37:30,302 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:37:41,536 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 10:37:52,650 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:38:04,072 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:38:15,489 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0001 | 
2023-05-10 10:38:27,113 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:38:38,848 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 10:38:50,187 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:39:01,418 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 10:39:12,760 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:39:24,189 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:39:35,531 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:39:46,830 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:39:58,019 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:09,245 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:20,458 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:31,650 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:42,869 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:54,410 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:41:05,748 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:41:17,108 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:41:28,428 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:41:39,855 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:41:51,240 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 10:42:02,728 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:42:14,190 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:42:25,506 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:42:36,822 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 10:42:48,200 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:42:59,574 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:42:59,574 INFO    : [INFO] The learning rate now is 0.000050
2023-05-10 10:42:59,574 INFO    :    | end of epoch   9 | time: 567.46s | epoch train loss 0.7370 | 
2023-05-10 10:42:59,574 INFO    : [INFO] Found new best model with 0.737 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:42:59,724 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:42:59,724 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:43:01,709 INFO    : [INFO] End of valid | time:  1.99s | valid loss 45.9564 | 
2023-05-10 10:43:01,710 INFO    : Rouge1:
	p:0.376744, r:0.294545, f:0.330612
Rouge2:
	p:0.111821, r:0.083933, f:0.095890
Rougel:
	p:0.339535, r:0.265455, f:0.297959

2023-05-10 10:43:01,710 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:43:01,710 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:43:13,055 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:24,293 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:35,740 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:47,084 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:58,580 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 10:44:09,958 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:44:21,599 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 10:44:33,259 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:44:44,431 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:44:56,048 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0001 | 
2023-05-10 10:45:07,409 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:45:18,751 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:45:30,123 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:45:41,508 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:45:52,844 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:04,118 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:15,564 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:46:26,809 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:38,081 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:49,233 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:00,592 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:11,782 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:23,097 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:47:34,350 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:45,501 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:56,899 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:48:08,263 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0001 | 
2023-05-10 10:48:19,594 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:48:30,793 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0001 | 
2023-05-10 10:48:42,116 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 10:48:53,307 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:49:04,602 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 10:49:16,065 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 10:49:27,562 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0001 | 
2023-05-10 10:49:39,057 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:49:50,654 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 10:50:02,005 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:50:13,381 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:50:24,720 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:50:45,565 INFO    :        | end of iter   0 | time: 10.31s | train loss 0.0001 | 
2023-05-10 10:51:08,566 INFO    :        | end of iter   0 | time: 12.14s | train loss 0.0001 | 
2023-05-10 10:51:29,884 INFO    :        | end of iter   0 | time: 10.07s | train loss 0.0001 | 
2023-05-10 10:51:52,154 INFO    :        | end of iter   0 | time: 11.34s | train loss 0.0001 | 
2023-05-10 10:52:15,063 INFO    :        | end of iter   0 | time: 11.86s | train loss 0.0001 | 
2023-05-10 10:52:37,408 INFO    :        | end of iter   0 | time: 11.40s | train loss 0.0001 | 
2023-05-10 10:53:00,488 INFO    :        | end of iter   0 | time: 12.29s | train loss 0.0001 | 
2023-05-10 10:53:22,578 INFO    :        | end of iter   0 | time: 11.38s | train loss 0.0001 | 
2023-05-10 10:53:46,354 INFO    :        | end of iter   0 | time: 12.79s | train loss 0.0001 | 
2023-05-10 10:54:09,580 INFO    :        | end of iter   0 | time: 12.38s | train loss 0.0001 | 
2023-05-10 10:54:32,327 INFO    :        | end of iter   0 | time: 11.42s | train loss 0.0001 | 
2023-05-10 10:54:32,327 INFO    : [INFO] The learning rate now is 0.000045
2023-05-10 10:54:32,327 INFO    :    | end of epoch  10 | time: 690.62s | epoch train loss 0.6509 | 
2023-05-10 10:54:32,327 INFO    : [INFO] Found new best model with 0.651 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:54:32,466 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:54:32,466 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:54:39,817 INFO    : [INFO] End of valid | time:  7.35s | valid loss 46.4386 | 
2023-05-10 10:54:39,818 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 10:54:39,818 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:54:39,818 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:55:02,090 INFO    :        | end of iter   0 | time: 11.04s | train loss 0.0001 | 
2023-05-10 10:55:23,454 INFO    :        | end of iter   0 | time: 10.34s | train loss 0.0001 | 
2023-05-10 10:55:45,722 INFO    :        | end of iter   0 | time: 10.61s | train loss 0.0001 | 
2023-05-10 10:56:08,998 INFO    :        | end of iter   0 | time: 11.72s | train loss 0.0001 | 
2023-05-10 10:56:31,234 INFO    :        | end of iter   0 | time: 11.14s | train loss 0.0001 | 
2023-05-10 10:56:54,027 INFO    :        | end of iter   0 | time: 10.80s | train loss 0.0001 | 
2023-05-10 10:57:16,731 INFO    :        | end of iter   0 | time: 11.59s | train loss 0.0001 | 
2023-05-10 10:57:39,087 INFO    :        | end of iter   0 | time: 10.78s | train loss 0.0001 | 
2023-05-10 10:58:02,721 INFO    :        | end of iter   0 | time: 12.23s | train loss 0.0001 | 
2023-05-10 10:58:26,396 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 10:58:49,553 INFO    :        | end of iter   0 | time: 12.03s | train loss 0.0001 | 
2023-05-10 10:59:11,489 INFO    :        | end of iter   0 | time: 10.85s | train loss 0.0001 | 
2023-05-10 10:59:35,730 INFO    :        | end of iter   0 | time: 12.38s | train loss 0.0001 | 
2023-05-10 10:59:58,990 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 11:00:21,447 INFO    :        | end of iter   0 | time: 11.60s | train loss 0.0001 | 
2023-05-10 11:00:43,516 INFO    :        | end of iter   0 | time: 11.18s | train loss 0.0001 | 
2023-05-10 11:01:07,761 INFO    :        | end of iter   0 | time: 13.13s | train loss 0.0001 | 
2023-05-10 11:01:29,945 INFO    :        | end of iter   0 | time: 10.91s | train loss 0.0001 | 
2023-05-10 11:01:50,898 INFO    :        | end of iter   0 | time: 10.15s | train loss 0.0001 | 
2023-05-10 11:02:14,123 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 11:02:36,446 INFO    :        | end of iter   0 | time: 11.14s | train loss 0.0001 | 
2023-05-10 11:02:59,473 INFO    :        | end of iter   0 | time: 11.52s | train loss 0.0001 | 
2023-05-10 11:03:22,372 INFO    :        | end of iter   0 | time: 11.27s | train loss 0.0001 | 
2023-05-10 11:03:45,541 INFO    :        | end of iter   0 | time: 11.71s | train loss 0.0001 | 
2023-05-10 11:04:06,827 INFO    :        | end of iter   0 | time: 10.37s | train loss 0.0001 | 
2023-05-10 11:04:28,976 INFO    :        | end of iter   0 | time: 10.84s | train loss 0.0001 | 
2023-05-10 11:04:51,602 INFO    :        | end of iter   0 | time: 10.93s | train loss 0.0001 | 
2023-05-10 11:05:15,057 INFO    :        | end of iter   0 | time: 11.59s | train loss 0.0001 | 
2023-05-10 11:05:37,397 INFO    :        | end of iter   0 | time: 11.29s | train loss 0.0001 | 
2023-05-10 11:05:58,665 INFO    :        | end of iter   0 | time: 10.13s | train loss 0.0001 | 
2023-05-10 11:06:21,189 INFO    :        | end of iter   0 | time: 11.09s | train loss 0.0001 | 
2023-05-10 11:06:44,532 INFO    :        | end of iter   0 | time: 12.37s | train loss 0.0001 | 
2023-05-10 11:07:07,601 INFO    :        | end of iter   0 | time: 11.64s | train loss 0.0001 | 
2023-05-10 11:07:31,037 INFO    :        | end of iter   0 | time: 12.06s | train loss 0.0001 | 
2023-05-10 11:07:53,264 INFO    :        | end of iter   0 | time: 10.97s | train loss 0.0001 | 
2023-05-10 11:08:15,050 INFO    :        | end of iter   0 | time: 10.92s | train loss 0.0001 | 
2023-05-10 11:08:38,206 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 11:09:01,356 INFO    :        | end of iter   0 | time: 11.46s | train loss 0.0001 | 
2023-05-10 11:09:24,640 INFO    :        | end of iter   0 | time: 12.16s | train loss 0.0001 | 
2023-05-10 11:09:42,235 INFO    :        | end of iter   0 | time:  6.56s | train loss 0.0001 | 
2023-05-10 11:09:55,291 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 11:10:07,848 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 11:10:19,936 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:10:32,008 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:10:44,141 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:10:56,328 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:11:09,593 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:11:22,156 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:11:34,624 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:11:47,190 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:11:47,190 INFO    : [INFO] The learning rate now is 0.000042
2023-05-10 11:11:47,190 INFO    :    | end of epoch  11 | time: 1027.37s | epoch train loss 0.5838 | 
2023-05-10 11:11:47,190 INFO    : [INFO] Found new best model with 0.584 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:11:47,320 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:11:47,320 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:11:49,540 INFO    : [INFO] End of valid | time:  2.22s | valid loss 46.9055 | 
2023-05-10 11:11:49,541 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 11:11:49,541 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:11:49,541 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:12:02,393 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:12:14,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:12:26,971 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:12:39,371 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:12:51,796 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:13:04,529 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:13:16,787 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:13:29,292 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:13:41,320 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:13:53,666 INFO    :        | end of iter   0 | time:  1.29s | train loss 0.0001 | 
2023-05-10 11:14:06,390 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 11:14:18,326 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 11:14:30,716 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:14:43,086 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:14:55,632 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:15:08,289 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:15:20,029 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:15:32,734 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:15:45,175 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:15:57,378 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:16:09,633 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:16:22,155 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:16:35,318 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:16:48,198 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:17:00,704 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:17:13,329 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:17:26,432 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:17:40,235 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:17:53,171 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:18:05,611 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:18:18,608 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:18:31,400 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:18:43,918 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:18:57,035 INFO    :        | end of iter   0 | time:  1.47s | train loss 0.0001 | 
2023-05-10 11:19:10,185 INFO    :        | end of iter   0 | time:  1.36s | train loss 0.0001 | 
2023-05-10 11:19:23,264 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:19:36,188 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:19:48,541 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 11:20:01,753 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:20:14,593 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:20:26,589 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:20:39,051 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:20:51,275 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:21:03,917 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:21:17,288 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 11:21:30,191 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:21:42,569 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:21:55,645 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:22:08,783 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:22:21,523 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:22:21,524 INFO    : [INFO] The learning rate now is 0.000038
2023-05-10 11:22:21,524 INFO    :    | end of epoch  12 | time: 631.98s | epoch train loss 0.5298 | 
2023-05-10 11:22:21,524 INFO    : [INFO] Found new best model with 0.530 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:22:21,655 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:22:21,655 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:22:23,786 INFO    : [INFO] End of valid | time:  2.13s | valid loss 47.2464 | 
2023-05-10 11:22:23,786 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 11:22:23,786 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:22:23,786 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:22:36,997 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:22:49,395 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:23:02,206 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 11:23:14,686 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:23:27,012 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:23:39,709 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:23:52,063 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:24:04,970 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:24:17,626 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:24:30,251 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:24:42,577 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:24:55,624 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:25:08,414 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 11:25:21,044 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:25:33,916 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:25:47,320 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:25:59,917 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:26:12,574 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:26:24,803 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:26:37,075 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:26:49,881 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:27:01,818 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:27:14,218 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:27:26,712 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:27:39,324 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:27:52,049 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:28:04,672 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:28:17,134 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:28:29,926 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:28:42,671 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:28:55,284 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:07,478 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:29:19,579 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:32,105 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:44,346 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:56,373 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:30:08,747 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:30:22,300 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:30:35,205 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:30:47,930 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:31:00,728 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:31:13,682 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:31:26,657 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:31:39,196 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:31:51,338 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:32:04,134 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:32:16,823 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:32:29,604 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 11:32:41,735 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:32:54,285 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:32:54,286 INFO    : [INFO] The learning rate now is 0.000036
2023-05-10 11:32:54,286 INFO    :    | end of epoch  13 | time: 630.50s | epoch train loss 0.4869 | 
2023-05-10 11:32:54,286 INFO    : [INFO] Found new best model with 0.487 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:32:54,418 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:32:54,418 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:32:56,573 INFO    : [INFO] End of valid | time:  2.15s | valid loss 47.6462 | 
2023-05-10 11:32:56,573 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 11:32:56,573 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:32:56,574 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:33:09,573 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:33:22,284 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:33:35,402 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:33:48,203 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:33:59,802 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:34:11,888 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:34:25,209 INFO    :        | end of iter   0 | time:  1.96s | train loss 0.0001 | 
2023-05-10 11:34:37,429 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:34:50,550 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:35:02,759 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:35:14,886 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:35:26,775 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:35:38,810 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:35:50,809 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:36:02,871 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:36:15,114 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:36:26,981 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:36:38,963 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:36:50,960 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:37:02,898 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 11:37:14,817 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 11:37:27,051 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:37:39,790 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 11:37:51,896 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:38:03,888 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:38:15,933 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:38:27,735 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:38:39,878 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:38:51,849 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:39:03,692 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:39:15,576 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:39:27,471 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:39:39,604 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:39:52,148 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:40:05,185 INFO    :        | end of iter   0 | time:  1.95s | train loss 0.0001 | 
2023-05-10 11:40:17,220 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:40:29,797 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:40:41,884 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:40:53,921 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:41:05,988 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:41:18,003 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:41:29,987 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:41:42,225 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:41:54,430 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:42:06,354 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:42:18,068 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:42:30,165 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 11:42:42,366 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:42:54,148 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:43:06,239 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:43:06,239 INFO    : [INFO] The learning rate now is 0.000033
2023-05-10 11:43:06,239 INFO    :    | end of epoch  14 | time: 609.67s | epoch train loss 0.4522 | 
2023-05-10 11:43:06,239 INFO    : [INFO] Found new best model with 0.452 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:43:06,350 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:43:06,350 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:43:08,470 INFO    : [INFO] End of valid | time:  2.12s | valid loss 47.9029 | 
2023-05-10 11:43:08,470 INFO    : Rouge1:
	p:0.380282, r:0.294545, f:0.331967
Rouge2:
	p:0.118590, r:0.088729, f:0.101509
Rougel:
	p:0.352113, r:0.272727, f:0.307377

2023-05-10 11:43:08,470 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:43:08,470 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:43:21,015 INFO    :        | end of iter   0 | time:  1.72s | train loss 0.0001 | 
2023-05-10 11:43:32,610 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:43:45,217 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 11:43:57,659 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:44:09,937 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:44:22,168 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:44:34,593 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:44:46,807 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:44:58,822 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:45:10,763 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:45:23,295 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:45:35,754 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:45:48,124 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:46:00,503 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:46:12,918 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:46:24,884 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:46:37,774 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:46:49,780 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:47:01,488 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:47:13,469 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:47:25,411 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:47:37,367 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:47:49,209 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:48:01,146 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:48:13,332 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:48:25,544 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 11:48:38,674 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:48:51,163 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:49:03,287 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:49:15,475 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:49:27,385 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:49:39,311 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 11:49:51,254 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 11:50:03,516 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:50:15,442 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:50:27,170 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:50:40,184 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:50:52,412 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:51:04,617 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:51:16,705 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:51:28,520 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:51:40,593 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:51:52,864 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:52:05,170 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:52:17,420 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:52:29,689 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:52:41,657 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:52:53,689 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:53:05,428 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:53:17,590 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:53:17,591 INFO    : [INFO] The learning rate now is 0.000031
2023-05-10 11:53:17,591 INFO    :    | end of epoch  15 | time: 609.12s | epoch train loss 0.4210 | 
2023-05-10 11:53:17,591 INFO    : [INFO] Found new best model with 0.421 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:53:17,738 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:53:17,738 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:53:19,766 INFO    : [INFO] End of valid | time:  2.03s | valid loss 48.1492 | 
2023-05-10 11:53:19,766 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 11:53:19,766 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:53:19,766 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:53:31,849 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:53:43,655 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:53:55,655 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:54:07,553 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:54:20,136 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:54:32,713 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:54:44,801 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:54:56,689 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:55:08,686 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:55:20,747 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:55:32,582 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:55:44,488 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:55:56,842 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 11:56:08,808 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:56:20,451 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:56:32,470 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 11:56:44,326 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:56:56,203 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:57:08,206 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:57:20,258 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:57:32,261 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 11:57:44,281 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:57:56,367 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:58:08,458 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:58:20,483 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:58:32,391 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:58:44,556 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:58:56,918 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:59:09,287 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:59:21,654 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:59:34,006 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:59:46,318 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:59:58,388 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:00:10,255 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:00:22,263 INFO    :        | end of iter   0 | time:  1.37s | train loss 0.0001 | 
2023-05-10 12:00:34,255 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:00:45,997 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:00:58,044 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:01:10,250 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:01:22,362 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:01:34,079 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:01:45,969 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:01:57,926 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:02:09,810 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:02:21,632 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:02:33,548 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 12:02:45,420 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:02:57,374 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:03:09,049 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:03:21,266 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 12:03:21,267 INFO    : [INFO] The learning rate now is 0.000029
2023-05-10 12:03:21,267 INFO    :    | end of epoch  16 | time: 601.50s | epoch train loss 0.3956 | 
2023-05-10 12:03:21,267 INFO    : [INFO] Found new best model with 0.396 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:03:21,412 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:03:21,413 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:03:23,637 INFO    : [INFO] End of valid | time:  2.22s | valid loss 48.3955 | 
2023-05-10 12:03:23,637 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 12:03:23,637 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:03:23,637 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:03:35,689 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:03:47,733 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:03:59,599 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:04:11,854 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:04:23,943 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:04:35,905 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:04:47,777 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:04:59,664 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:05:11,519 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:05:23,548 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:05:35,364 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:05:47,220 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:05:59,325 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:06:11,225 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:06:23,080 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:06:35,054 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:06:47,056 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:06:58,938 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:07:10,881 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:07:22,846 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:07:34,670 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:07:46,425 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:07:58,392 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:08:10,608 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:08:22,640 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:08:34,472 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:08:46,593 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:08:58,411 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:09:10,471 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:09:22,425 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:09:34,277 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:09:46,283 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:09:58,165 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:10:10,003 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:10:21,903 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:10:33,590 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:10:45,398 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:10:57,256 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:11:09,529 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:11:21,480 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:11:33,469 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:11:45,527 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:11:57,460 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:12:09,335 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:12:21,273 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:12:33,036 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:12:44,914 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:12:56,884 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:08,763 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:21,132 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:21,132 INFO    : [INFO] The learning rate now is 0.000028
2023-05-10 12:13:21,132 INFO    :    | end of epoch  17 | time: 597.49s | epoch train loss 0.3736 | 
2023-05-10 12:13:21,132 INFO    : [INFO] Found new best model with 0.374 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:13:21,275 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:13:21,275 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:13:23,306 INFO    : [INFO] End of valid | time:  2.03s | valid loss 48.6219 | 
2023-05-10 12:13:23,306 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 12:13:23,306 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:13:23,306 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:13:35,341 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:47,134 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:13:59,087 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:14:11,067 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:14:22,829 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 12:14:34,805 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:14:46,816 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:14:58,917 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:15:10,713 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:15:22,769 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:15:34,612 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:15:46,520 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:15:58,397 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:16:10,233 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:16:22,159 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:16:33,863 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 12:16:45,727 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:16:57,680 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0001 | 
2023-05-10 12:17:09,561 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 12:17:21,633 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:17:33,892 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:17:46,022 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:17:58,012 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 12:18:10,187 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:18:22,516 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:18:34,468 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:18:46,433 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:18:58,296 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:19:10,269 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:19:22,680 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:19:34,955 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:19:46,944 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:19:58,665 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:20:10,684 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:20:22,740 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:20:34,721 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:20:46,787 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:20:58,791 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:21:10,741 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:21:22,686 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:21:34,439 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:21:46,285 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:21:58,472 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 12:22:10,681 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:22:22,497 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:22:34,376 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:22:46,201 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:22:58,441 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:23:10,643 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:23:22,355 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:23:22,355 INFO    : [INFO] The learning rate now is 0.000026
2023-05-10 12:23:22,356 INFO    :    | end of epoch  18 | time: 599.05s | epoch train loss 0.3532 | 
2023-05-10 12:23:22,356 INFO    : [INFO] Found new best model with 0.353 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:23:22,515 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:23:22,515 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:23:24,605 INFO    : [INFO] End of valid | time:  2.09s | valid loss 48.7289 | 
2023-05-10 12:23:24,606 INFO    : Rouge1:
	p:0.373832, r:0.290909, f:0.327198
Rouge2:
	p:0.115385, r:0.086331, f:0.098765
Rougel:
	p:0.341121, r:0.265455, f:0.298569

2023-05-10 12:23:24,606 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:23:24,606 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:23:36,398 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:23:48,659 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:24:00,462 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 12:24:12,487 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:24:24,382 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:24:36,645 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:24:48,454 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:25:00,580 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:25:12,461 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:25:24,495 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:25:36,485 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:25:48,229 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 12:25:59,979 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:26:12,224 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0001 | 
2023-05-10 12:26:24,175 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:26:36,108 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:26:47,938 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 12:26:59,825 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:27:11,987 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:27:23,767 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:27:35,468 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:27:47,409 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:27:59,406 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:28:11,293 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:28:22,924 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:28:34,658 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:28:46,257 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:28:58,009 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 12:29:10,339 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:29:22,737 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:29:35,081 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:29:47,352 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:29:59,718 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:30:11,730 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:30:23,652 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:30:35,526 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:30:47,384 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:30:59,222 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:31:11,173 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:31:22,966 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:31:34,764 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:31:46,658 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:31:58,711 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:32:10,646 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:32:22,485 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:32:34,491 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:32:46,727 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:32:58,843 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:33:10,909 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:33:22,937 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:33:22,937 INFO    : [INFO] The learning rate now is 0.000025
2023-05-10 12:33:22,937 INFO    :    | end of epoch  19 | time: 598.33s | epoch train loss 0.3352 | 
2023-05-10 12:33:22,937 INFO    : [INFO] Found new best model with 0.335 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:33:23,084 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:33:23,084 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:33:25,112 INFO    : [INFO] End of valid | time:  2.03s | valid loss 48.8899 | 
2023-05-10 12:33:25,112 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.325359, r:0.247273, f:0.280992

2023-05-10 12:33:25,113 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:33:25,113 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:33:37,210 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:33:49,479 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:34:01,362 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:34:13,335 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:34:25,444 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:34:37,670 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:34:50,120 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:35:02,337 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:35:14,174 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:35:26,078 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:35:38,052 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:35:49,585 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:36:01,441 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:36:13,198 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:36:25,033 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:36:36,977 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:36:48,812 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:37:00,760 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:37:13,140 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:37:25,280 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:37:37,243 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:37:49,466 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:38:01,624 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:38:13,670 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:38:25,731 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:38:37,849 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:38:50,070 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 12:39:02,302 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:39:14,430 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:39:26,654 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:39:38,689 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:39:50,693 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:40:02,717 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:40:14,563 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:40:26,514 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 12:40:38,210 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:40:50,175 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:41:02,159 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 12:41:13,838 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:41:25,931 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:41:37,817 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:41:50,038 INFO    :        | end of iter   0 | time:  1.31s | train loss 0.0001 | 
2023-05-10 12:42:02,317 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 12:42:14,729 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:42:26,812 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:42:39,282 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:42:51,689 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:43:03,909 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:43:16,226 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:43:28,348 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:43:28,348 INFO    : [INFO] The learning rate now is 0.000024
2023-05-10 12:43:28,348 INFO    :    | end of epoch  20 | time: 603.24s | epoch train loss 0.3205 | 
2023-05-10 12:43:28,349 INFO    : [INFO] Found new best model with 0.320 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:43:28,467 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:43:28,467 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:43:30,639 INFO    : [INFO] End of valid | time:  2.17s | valid loss 49.0136 | 
2023-05-10 12:43:30,639 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.325359, r:0.247273, f:0.280992

2023-05-10 12:43:30,639 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:43:30,639 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:43:42,483 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:43:54,318 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:06,303 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:18,167 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:44:30,088 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:41,963 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:53,754 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:05,721 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:18,047 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:30,452 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:42,841 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:45:55,221 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:46:07,499 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:46:19,572 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 12:46:31,704 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:46:43,996 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:46:55,944 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 12:47:07,994 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:47:20,008 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 12:47:32,283 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:47:44,339 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:47:56,585 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:48:08,808 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:48:21,152 INFO    :        | end of iter   0 | time:  1.31s | train loss 0.0001 | 
2023-05-10 12:48:33,533 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:48:45,670 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:48:57,910 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:49:10,171 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:49:22,172 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:49:34,539 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:49:46,897 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:49:58,667 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:50:10,483 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:50:22,369 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:50:34,210 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:50:45,908 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:50:57,593 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:51:09,380 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:51:21,199 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:51:33,219 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:51:45,410 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:51:57,691 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:52:09,511 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:52:21,485 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:52:33,473 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:52:45,242 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:52:57,370 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:53:09,677 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:53:21,748 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:53:33,401 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:53:33,401 INFO    : [INFO] The learning rate now is 0.000023
2023-05-10 12:53:33,401 INFO    :    | end of epoch  21 | time: 602.76s | epoch train loss 0.3055 | 
2023-05-10 12:53:33,401 INFO    : [INFO] Found new best model with 0.306 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:53:33,530 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:53:33,531 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:53:35,719 INFO    : [INFO] End of valid | time:  2.19s | valid loss 49.0920 | 
2023-05-10 12:53:35,719 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 12:53:35,719 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:53:35,720 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:53:47,814 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:53:59,641 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:54:11,530 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:54:23,666 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:54:35,745 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:54:47,850 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 12:54:59,983 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:55:11,884 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:55:24,290 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:55:36,452 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:55:48,477 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:56:00,590 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:56:12,784 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:56:24,831 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:56:37,071 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 12:56:48,965 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:57:01,374 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:57:13,757 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 12:57:26,097 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:57:38,474 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:57:50,849 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:58:02,999 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:58:14,823 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:58:27,022 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:58:38,962 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:58:51,069 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:59:02,866 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:59:14,545 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:59:26,753 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:59:38,960 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:59:51,209 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:00:03,408 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:00:15,640 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:00:27,853 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:00:40,007 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:00:52,168 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:01:04,344 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:01:16,480 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:01:28,513 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:01:40,534 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:01:52,471 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:04,306 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:02:16,583 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:28,502 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:40,351 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:52,339 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:03:04,288 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:03:16,507 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:03:28,719 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:03:40,865 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:03:40,866 INFO    : [INFO] The learning rate now is 0.000022
2023-05-10 13:03:40,866 INFO    :    | end of epoch  22 | time: 605.15s | epoch train loss 0.2935 | 
2023-05-10 13:03:40,866 INFO    : [INFO] Found new best model with 0.293 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:03:41,005 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:03:41,005 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:03:43,047 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.1577 | 
2023-05-10 13:03:43,048 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.325359, r:0.247273, f:0.280992

2023-05-10 13:03:43,048 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:03:43,048 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:03:55,304 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:04:07,144 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:04:18,956 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:04:30,929 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:04:42,762 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:04:54,590 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:05:06,331 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:05:18,384 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:05:30,405 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 13:05:42,514 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:05:54,583 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:06:06,435 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:06:18,258 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 13:06:30,119 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 13:06:42,030 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:06:53,946 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 13:07:05,825 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 13:07:17,599 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:07:29,697 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 13:07:42,157 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0001 | 
2023-05-10 13:07:54,369 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:08:06,344 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:08:18,360 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:08:30,491 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:08:42,695 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:08:54,714 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:09:06,549 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:09:18,854 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:09:30,871 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:09:42,689 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:09:54,790 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:10:06,825 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:10:18,766 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:10:30,654 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:10:42,540 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:10:54,343 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:11:06,263 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:11:18,635 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 13:11:30,974 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:11:43,277 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:11:55,461 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:12:07,625 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:12:19,813 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:12:31,950 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:12:43,791 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:12:55,584 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:13:07,479 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 13:13:19,163 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:13:31,133 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:13:43,176 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:13:43,176 INFO    : [INFO] The learning rate now is 0.000021
2023-05-10 13:13:43,176 INFO    :    | end of epoch  23 | time: 600.13s | epoch train loss 0.2813 | 
2023-05-10 13:13:43,176 INFO    : [INFO] Found new best model with 0.281 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:13:43,364 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:13:43,364 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:13:45,416 INFO    : [INFO] End of valid | time:  2.05s | valid loss 49.2349 | 
2023-05-10 13:13:45,416 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 13:13:45,416 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:13:45,416 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:13:57,471 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:14:09,526 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 13:14:21,780 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 13:14:34,125 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:14:46,117 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 13:14:57,997 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 13:15:09,676 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:15:21,670 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0001 | 
2023-05-10 13:15:33,342 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:15:45,323 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:15:57,289 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:16:09,253 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:16:21,121 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:16:32,955 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:16:45,022 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:16:57,088 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:17:08,880 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:17:20,861 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:17:32,636 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 13:17:44,965 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:17:57,077 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:18:09,351 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:18:21,778 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:18:33,693 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:18:45,449 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:18:57,340 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:19:09,252 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:19:21,163 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:19:33,005 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:19:44,883 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:19:56,831 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:20:08,776 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:20:20,720 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:20:32,735 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 13:20:44,404 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:20:56,743 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:21:08,997 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:21:21,256 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:21:33,465 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:21:45,663 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:21:57,928 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:22:09,876 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:22:21,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:22:33,604 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:22:45,450 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:22:57,585 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:23:09,972 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:23:22,105 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:23:34,370 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:23:46,565 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:23:46,565 INFO    : [INFO] The learning rate now is 0.000020
2023-05-10 13:23:46,565 INFO    :    | end of epoch  24 | time: 601.15s | epoch train loss 0.2703 | 
2023-05-10 13:23:46,565 INFO    : [INFO] Found new best model with 0.270 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:23:46,688 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:23:46,688 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:23:48,706 INFO    : [INFO] End of valid | time:  2.02s | valid loss 49.2948 | 
2023-05-10 13:23:48,706 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 13:23:48,706 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:23:48,706 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:24:00,647 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:24:12,572 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:24:25,019 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:24:37,370 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:24:49,607 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:25:01,835 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 13:25:13,861 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:25:25,889 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:25:37,750 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:25:49,644 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 13:26:01,645 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 13:26:13,811 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 13:26:25,385 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:26:37,580 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:26:49,798 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:27:02,034 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:27:14,291 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:27:26,271 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:27:38,672 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:27:51,156 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:28:03,577 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:28:15,750 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:28:27,570 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 13:28:40,011 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:28:52,325 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:29:04,714 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:29:16,508 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0001 | 
2023-05-10 13:29:28,476 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:29:40,373 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:29:51,971 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0001 | 
2023-05-10 13:30:03,560 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:30:15,511 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:30:27,445 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:30:39,513 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:30:51,760 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:31:04,140 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:31:16,297 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:31:28,035 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 13:31:39,874 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:31:51,855 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:32:04,009 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:32:16,122 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:32:28,457 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:32:40,191 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:32:52,234 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:33:04,586 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:33:17,001 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:33:29,381 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:33:41,682 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 13:33:53,907 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:33:53,908 INFO    : [INFO] The learning rate now is 0.000019
2023-05-10 13:33:53,908 INFO    :    | end of epoch  25 | time: 605.20s | epoch train loss 0.2606 | 
2023-05-10 13:33:53,908 INFO    : [INFO] Found new best model with 0.261 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:33:54,047 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:33:54,047 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:33:56,086 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.3306 | 
2023-05-10 13:33:56,086 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 13:33:56,086 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:33:56,086 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:34:08,425 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:34:20,448 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:34:32,409 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:34:44,477 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:34:56,359 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:35:08,201 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:35:20,080 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:35:32,064 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:35:43,997 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:35:56,039 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:36:08,389 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:36:20,483 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:36:32,548 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:36:44,434 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:36:56,163 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:37:07,977 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 13:37:20,135 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 13:37:32,329 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 13:37:44,608 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:37:56,769 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:38:08,663 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:38:20,412 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 13:38:32,529 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:38:44,797 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:38:56,882 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:39:09,183 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:39:21,479 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:39:34,069 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:39:46,559 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:39:58,592 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:40:10,787 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 13:40:22,700 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 13:40:35,064 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:40:47,478 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 13:40:59,741 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:41:11,578 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:41:23,324 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:41:35,441 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:41:47,487 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:41:59,431 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:42:11,614 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:42:24,075 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:42:36,373 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:42:48,566 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:43:00,738 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:43:12,563 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:43:24,346 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:43:36,342 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:43:48,214 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:44:00,389 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:44:00,390 INFO    : [INFO] The learning rate now is 0.000019
2023-05-10 13:44:00,390 INFO    :    | end of epoch  26 | time: 604.30s | epoch train loss 0.2518 | 
2023-05-10 13:44:00,390 INFO    : [INFO] Found new best model with 0.252 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:44:00,526 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:44:00,526 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:44:02,553 INFO    : [INFO] End of valid | time:  2.03s | valid loss 49.3225 | 
2023-05-10 13:44:02,553 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 13:44:02,553 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:44:02,553 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:44:14,584 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:44:26,614 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 13:44:38,378 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:44:50,298 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:45:02,583 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:45:14,923 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:45:27,008 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:45:38,866 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:45:51,121 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:46:03,180 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:46:15,306 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 13:46:27,530 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:46:39,928 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:46:51,906 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:47:03,877 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:47:15,728 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:47:27,679 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:47:39,861 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:47:51,727 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:48:03,556 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:48:15,595 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:48:27,652 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:48:39,573 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:48:51,461 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:03,480 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:49:15,300 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:27,238 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:39,083 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:51,353 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 13:50:03,736 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:50:16,185 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 13:50:28,219 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0000 | 
2023-05-10 13:50:39,934 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 13:50:51,777 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:51:03,478 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:51:15,441 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:51:27,396 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:51:39,691 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:51:52,064 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:52:04,435 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:52:16,784 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:52:29,174 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 13:52:41,331 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:52:53,382 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:53:05,361 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:53:17,442 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:53:29,311 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:53:41,333 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:53:53,113 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:54:05,504 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:54:05,505 INFO    : [INFO] The learning rate now is 0.000018
2023-05-10 13:54:05,505 INFO    :    | end of epoch  27 | time: 602.95s | epoch train loss 0.2427 | 
2023-05-10 13:54:05,505 INFO    : [INFO] Found new best model with 0.243 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:54:05,625 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:54:05,625 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:54:07,662 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.3868 | 
2023-05-10 13:54:07,662 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 13:54:07,663 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:54:07,663 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:54:19,577 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:54:31,292 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:54:43,196 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:54:55,088 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:55:07,385 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0000 | 
2023-05-10 13:55:19,522 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:55:31,656 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:55:43,533 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:55:55,588 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:56:07,535 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:56:19,592 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:56:31,426 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:56:43,277 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:56:55,290 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:57:07,108 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:57:18,949 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:57:30,825 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:57:42,813 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:57:54,888 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:58:06,561 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 13:58:18,913 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 13:58:30,816 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:58:43,007 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:58:55,136 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:59:07,397 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:59:19,626 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:59:31,818 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:59:43,969 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:59:55,915 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:00:07,748 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:00:19,586 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:00:31,397 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:00:43,408 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:00:55,179 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:01:07,023 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:01:19,076 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:01:30,891 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:01:42,786 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:01:54,856 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:02:07,146 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:02:19,748 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:02:32,115 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:02:44,433 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:02:56,441 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:03:08,348 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 14:03:19,825 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:03:31,927 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 14:03:44,080 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:03:56,112 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:04:07,930 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:04:07,931 INFO    : [INFO] The learning rate now is 0.000017
2023-05-10 14:04:07,931 INFO    :    | end of epoch  28 | time: 600.27s | epoch train loss 0.2348 | 
2023-05-10 14:04:07,931 INFO    : [INFO] Found new best model with 0.235 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:04:08,084 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:04:08,084 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:04:10,388 INFO    : [INFO] End of valid | time:  2.30s | valid loss 49.3037 | 
2023-05-10 14:04:10,388 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:04:10,388 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:04:10,389 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:04:22,453 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:04:34,431 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:04:46,197 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:04:58,214 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:05:10,182 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:05:22,135 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 14:05:34,247 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:05:46,490 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:05:58,810 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:06:11,135 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:06:23,058 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:06:34,760 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:06:46,773 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:06:58,859 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:07:10,860 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:07:22,707 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:07:35,023 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:07:47,327 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:07:59,399 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:08:11,460 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:08:23,541 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:08:35,513 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:08:47,374 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:08:59,127 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:09:11,145 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:09:23,032 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:09:35,272 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:09:47,455 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:09:59,637 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:10:11,891 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:10:24,054 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 14:10:36,244 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 14:10:48,118 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:11:00,327 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:11:12,213 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:11:23,890 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:11:35,743 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:11:47,673 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:11:59,661 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:11,637 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:23,918 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:12:35,924 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:47,698 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:59,594 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:13:11,584 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:13:23,538 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:13:35,507 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:13:47,394 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:13:59,319 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:14:11,224 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:14:11,224 INFO    : [INFO] The learning rate now is 0.000017
2023-05-10 14:14:11,224 INFO    :    | end of epoch  29 | time: 600.84s | epoch train loss 0.2274 | 
2023-05-10 14:14:11,224 INFO    : [INFO] Found new best model with 0.227 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:14:11,350 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:14:11,350 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:14:13,393 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.2919 | 
2023-05-10 14:14:13,393 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:14:13,393 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:14:13,393 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:14:25,194 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:14:37,337 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:14:49,388 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:15:01,390 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:15:14,006 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:15:26,241 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:15:38,353 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:15:50,691 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:16:02,894 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:16:14,978 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:16:27,111 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:16:39,105 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:16:51,106 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:17:03,155 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:17:14,879 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:17:26,768 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:17:38,980 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:17:51,188 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:18:03,122 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:18:14,768 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:18:26,871 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:18:38,877 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:18:50,854 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:19:02,739 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:19:14,645 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:19:27,124 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:19:39,371 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:19:51,862 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:20:04,147 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:20:16,367 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:20:28,801 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 14:20:41,068 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:20:53,185 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:21:05,175 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:21:16,859 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:21:29,067 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:21:40,874 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 14:21:52,445 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:22:04,642 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:22:16,702 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:22:28,768 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:22:40,877 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:22:53,255 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:05,516 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:23:17,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:30,000 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:42,386 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:54,703 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:24:07,170 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:24:19,195 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:24:19,196 INFO    : [INFO] The learning rate now is 0.000016
2023-05-10 14:24:19,196 INFO    :    | end of epoch  30 | time: 605.80s | epoch train loss 0.2200 | 
2023-05-10 14:24:19,196 INFO    : [INFO] Found new best model with 0.220 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:24:19,327 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:24:19,327 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:24:21,327 INFO    : [INFO] End of valid | time:  2.00s | valid loss 49.1885 | 
2023-05-10 14:24:21,327 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:24:21,327 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:24:21,327 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:24:33,320 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:24:45,183 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:24:57,262 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:25:09,259 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:25:21,196 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:25:33,147 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:25:45,054 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:25:57,004 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:26:08,964 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:26:20,710 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:26:32,632 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:26:44,556 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:26:56,351 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:27:08,479 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:27:20,508 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:27:32,386 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:27:44,432 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:27:56,229 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:28:08,825 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:28:21,091 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:28:33,082 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 14:28:45,345 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:28:57,689 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:29:09,787 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:29:21,672 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:29:34,030 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:29:45,947 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:29:58,315 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:30:10,637 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:30:22,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:30:34,795 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:30:46,606 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 14:30:58,517 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:31:10,823 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:31:22,947 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:31:35,199 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:31:47,228 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:31:59,351 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:32:11,526 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 14:32:23,914 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:32:36,263 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:32:48,111 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:32:59,975 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:33:12,112 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:33:24,309 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:33:36,449 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:33:48,901 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:34:00,980 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:34:12,742 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:34:24,528 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 14:34:24,529 INFO    : [INFO] The learning rate now is 0.000016
2023-05-10 14:34:24,529 INFO    :    | end of epoch  31 | time: 603.20s | epoch train loss 0.2138 | 
2023-05-10 14:34:24,529 INFO    : [INFO] Found new best model with 0.214 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:34:24,668 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:34:24,668 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:34:26,679 INFO    : [INFO] End of valid | time:  2.01s | valid loss 49.2524 | 
2023-05-10 14:34:26,680 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:34:26,680 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:34:26,680 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:34:38,542 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:34:50,408 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:35:02,876 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:35:14,971 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:35:26,707 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:35:38,556 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:35:50,530 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:36:02,362 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:36:15,680 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:36:27,756 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:36:40,160 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:36:52,259 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:37:04,224 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:37:16,141 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:37:28,454 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0000 | 
2023-05-10 14:37:40,818 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:37:53,224 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:38:05,289 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:38:17,164 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:38:29,240 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:38:41,290 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:38:53,456 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 14:39:05,787 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:39:18,211 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:39:29,827 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:39:41,674 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:39:53,426 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:40:05,684 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:40:17,588 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:40:29,309 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:40:41,600 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:40:53,846 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:41:06,245 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:41:18,276 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:41:30,283 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:41:42,345 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:41:54,328 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:42:06,653 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:42:19,177 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 14:42:31,462 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:42:43,398 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:42:55,047 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:43:07,310 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 14:43:19,642 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:43:32,093 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:43:43,927 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:43:56,208 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:44:08,283 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:44:20,422 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:44:32,337 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:44:32,337 INFO    : [INFO] The learning rate now is 0.000015
2023-05-10 14:44:32,337 INFO    :    | end of epoch  32 | time: 605.66s | epoch train loss 0.2073 | 
2023-05-10 14:44:32,337 INFO    : [INFO] Found new best model with 0.207 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:44:32,495 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:44:32,496 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:44:34,500 INFO    : [INFO] End of valid | time:  2.00s | valid loss 49.0409 | 
2023-05-10 14:44:34,500 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:44:34,500 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:44:34,500 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:44:46,478 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:44:58,560 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:45:10,745 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 14:45:22,858 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:45:35,180 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:45:47,261 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:45:59,505 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0000 | 
2023-05-10 14:46:11,455 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:46:23,456 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:46:35,533 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:46:47,875 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:46:59,980 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:12,058 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:24,409 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:36,233 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:48,096 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:48:00,304 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:48:12,597 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:48:24,965 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:48:37,244 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:48:49,231 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:49:01,074 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:49:13,021 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:49:24,998 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:49:37,229 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:49:49,517 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:50:01,736 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:50:14,045 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:50:26,477 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:50:38,871 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:50:50,834 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:51:02,774 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:51:15,264 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:51:27,809 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:51:40,283 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 14:51:52,137 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:52:04,399 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:52:16,898 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:52:29,106 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:52:41,503 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:52:53,642 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:53:05,709 INFO    :        | end of iter   0 | time:  1.32s | train loss 0.0000 | 
2023-05-10 14:53:17,497 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 14:53:29,483 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:53:41,160 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 14:53:53,066 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:54:04,927 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:54:17,058 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:54:29,186 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:54:41,328 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:54:41,328 INFO    : [INFO] The learning rate now is 0.000015
2023-05-10 14:54:41,328 INFO    :    | end of epoch  33 | time: 606.83s | epoch train loss 0.2018 | 
2023-05-10 14:54:41,328 INFO    : [INFO] Found new best model with 0.202 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:54:41,437 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:54:41,437 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:54:43,492 INFO    : [INFO] End of valid | time:  2.05s | valid loss 48.8934 | 
2023-05-10 14:54:43,492 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:54:43,492 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:54:43,492 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:54:55,506 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:55:07,385 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:55:19,321 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:55:31,248 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 14:55:43,651 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:55:55,891 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 14:56:08,108 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:56:20,361 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:56:32,566 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:56:44,337 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:56:56,283 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 14:57:08,258 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:57:20,168 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:57:32,132 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:57:44,029 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:57:56,173 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 14:58:08,081 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:58:20,182 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:58:32,159 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:58:43,834 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:58:55,577 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:59:07,799 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:59:19,743 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:59:31,940 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 14:59:43,852 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:59:55,819 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:00:07,980 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:00:19,998 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:00:32,033 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:00:44,095 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:00:55,851 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:01:07,910 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:01:19,916 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:01:31,892 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:01:43,815 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:01:55,878 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:02:07,760 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:02:19,648 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:02:31,484 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:02:43,572 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 15:02:55,843 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:07,674 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:03:19,401 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:31,246 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:43,126 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:55,137 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:04:07,078 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:04:18,856 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:04:30,810 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:04:42,964 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:04:42,964 INFO    : [INFO] The learning rate now is 0.000014
2023-05-10 15:04:42,965 INFO    :    | end of epoch  34 | time: 599.47s | epoch train loss 0.1966 | 
2023-05-10 15:04:42,965 INFO    : [INFO] Found new best model with 0.197 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:04:43,092 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:04:43,092 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:04:45,130 INFO    : [INFO] End of valid | time:  2.04s | valid loss 48.6949 | 
2023-05-10 15:04:45,130 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:04:45,130 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:04:45,130 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:04:56,976 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:05:08,836 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:05:20,774 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:05:32,838 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:05:44,916 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:05:56,812 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:06:08,681 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:06:20,615 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:06:32,456 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:06:44,421 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:06:56,354 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:07:07,898 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:07:19,812 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:07:31,743 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:07:43,596 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:07:55,525 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:08:07,416 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:08:19,428 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:08:31,350 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:08:43,190 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:08:55,049 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:09:06,799 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:09:18,740 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:09:30,872 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:09:42,920 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:09:54,948 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:10:06,622 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:10:18,540 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0000 | 
2023-05-10 15:10:30,539 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:10:42,608 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:10:54,477 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:11:06,423 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:11:18,274 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:11:30,383 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 15:11:42,118 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:11:53,959 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:12:05,800 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:12:17,915 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:12:30,110 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:12:41,958 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:12:53,806 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:13:05,756 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:13:17,881 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:13:29,818 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 15:13:41,819 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:13:53,704 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:14:05,582 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:14:17,425 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:14:29,566 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:14:41,677 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:14:41,677 INFO    : [INFO] The learning rate now is 0.000014
2023-05-10 15:14:41,677 INFO    :    | end of epoch  35 | time: 596.55s | epoch train loss 0.1914 | 
2023-05-10 15:14:41,677 INFO    : [INFO] Found new best model with 0.191 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:14:41,817 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:14:41,817 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:14:43,887 INFO    : [INFO] End of valid | time:  2.07s | valid loss 48.6150 | 
2023-05-10 15:14:43,888 INFO    : Rouge1:
	p:0.373832, r:0.290909, f:0.327198
Rouge2:
	p:0.115385, r:0.086331, f:0.098765
Rougel:
	p:0.341121, r:0.265455, f:0.298569

2023-05-10 15:14:43,888 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:14:43,888 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:14:56,005 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:15:07,956 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:15:19,842 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:15:31,660 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:15:43,671 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:15:55,922 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:16:07,698 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:16:19,669 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:16:31,628 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:16:43,648 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:16:55,880 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:17:07,717 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:17:19,552 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:17:31,268 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:17:43,213 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:17:55,501 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:18:07,417 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:18:19,472 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:18:31,251 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:18:43,313 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:18:55,333 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:19:07,447 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 15:19:19,332 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:19:31,222 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:19:43,484 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:19:55,335 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:20:07,334 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:20:19,343 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0000 | 
2023-05-10 15:20:31,450 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 15:20:43,431 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:20:55,613 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0000 | 
2023-05-10 15:21:07,613 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:21:19,107 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:21:31,111 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:21:43,000 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:21:55,047 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:22:06,947 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:22:19,065 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:22:31,094 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:22:43,090 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:22:54,903 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:06,841 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:18,899 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:23:30,881 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:42,876 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:54,761 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:24:06,806 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 15:24:18,703 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:24:31,013 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:24:42,886 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:24:42,887 INFO    : [INFO] The learning rate now is 0.000014
2023-05-10 15:24:42,887 INFO    :    | end of epoch  36 | time: 599.00s | epoch train loss 0.1862 | 
2023-05-10 15:24:42,887 INFO    : [INFO] Found new best model with 0.186 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:24:43,074 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:24:43,074 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:24:45,097 INFO    : [INFO] End of valid | time:  2.02s | valid loss 48.5618 | 
2023-05-10 15:24:45,097 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:24:45,097 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:24:45,097 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:24:56,958 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:25:08,993 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:25:20,870 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:25:32,645 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:25:44,750 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:25:56,685 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:26:08,403 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:26:20,371 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:26:32,256 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:26:44,592 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:26:56,721 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:27:09,014 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:27:21,327 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:27:33,234 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:27:45,195 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:27:57,108 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:28:09,022 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:28:20,901 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:28:32,983 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 15:28:44,982 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:28:56,640 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:29:08,659 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:29:20,683 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:29:32,409 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:29:44,340 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:29:56,296 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:30:08,254 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:30:20,402 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:30:32,751 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:30:45,075 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:30:57,150 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:31:09,088 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:31:21,285 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 15:31:33,597 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:31:45,926 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:31:58,131 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:32:10,306 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:32:22,466 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:32:34,759 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:32:47,012 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 15:32:59,242 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:33:11,589 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:33:23,924 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:33:36,027 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:33:48,142 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:34:00,517 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 15:34:12,742 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:34:24,804 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:34:37,196 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:34:49,523 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:34:49,523 INFO    : [INFO] The learning rate now is 0.000013
2023-05-10 15:34:49,523 INFO    :    | end of epoch  37 | time: 604.43s | epoch train loss 0.1816 | 
2023-05-10 15:34:49,523 INFO    : [INFO] Found new best model with 0.182 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:34:49,658 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:34:49,658 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:34:51,862 INFO    : [INFO] End of valid | time:  2.20s | valid loss 48.3523 | 
2023-05-10 15:34:51,862 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:34:51,862 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:34:51,862 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:35:04,085 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:35:16,010 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:35:28,170 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:35:40,509 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 15:35:52,992 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:36:05,197 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:36:17,408 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:36:29,804 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:36:42,095 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:36:54,192 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:37:06,138 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:37:17,898 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:37:29,821 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:37:42,154 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:37:54,414 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:38:06,616 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:38:18,589 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:38:30,604 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:38:42,582 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:38:54,453 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:39:06,530 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:39:18,396 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 15:39:30,146 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:39:42,206 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:39:54,139 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:40:06,172 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:40:18,248 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:40:30,280 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:40:42,079 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:40:53,931 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:41:05,934 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 15:41:18,237 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:41:30,312 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:41:42,295 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:41:54,657 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:42:06,872 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:42:18,997 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:42:31,147 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 15:42:43,181 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:42:54,946 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:43:07,508 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:43:19,567 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:43:31,698 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:43:43,818 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:43:55,611 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 15:44:07,343 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:44:19,906 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:44:31,981 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:44:44,481 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:44:56,646 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:44:56,646 INFO    : [INFO] The learning rate now is 0.000013
2023-05-10 15:44:56,646 INFO    :    | end of epoch  38 | time: 604.78s | epoch train loss 0.1770 | 
2023-05-10 15:44:56,646 INFO    : [INFO] Found new best model with 0.177 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:44:56,791 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:44:56,791 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:44:58,996 INFO    : [INFO] End of valid | time:  2.20s | valid loss 48.3640 | 
2023-05-10 15:44:58,996 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:44:58,996 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:44:58,996 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:45:11,245 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:45:23,451 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 15:45:35,659 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:45:47,823 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:46:00,178 INFO    :        | end of iter   0 | time:  1.32s | train loss 0.0000 | 
2023-05-10 15:46:12,339 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:46:24,451 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 15:46:36,852 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 15:46:49,160 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:47:01,549 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:47:13,767 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 15:47:25,676 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:47:37,271 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:47:49,243 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 15:48:01,138 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:48:13,268 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:48:25,270 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:48:36,953 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:48:48,944 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 15:49:00,836 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:49:12,732 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:49:24,663 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:49:36,486 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:49:48,756 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:50:00,628 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 15:50:12,460 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:50:24,437 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:50:36,406 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:50:48,322 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:51:00,225 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:51:12,399 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:51:24,177 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:51:35,944 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:51:47,787 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 15:51:59,775 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:52:11,831 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:52:23,744 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:52:35,909 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:52:48,159 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:53:00,155 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:53:11,903 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:53:23,606 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:53:35,552 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:53:47,453 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:53:59,382 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:54:11,360 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:54:23,381 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:54:35,359 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:54:47,450 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:54:59,496 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:54:59,496 INFO    : [INFO] The learning rate now is 0.000013
2023-05-10 15:54:59,496 INFO    :    | end of epoch  39 | time: 600.50s | epoch train loss 0.1729 | 
2023-05-10 15:54:59,496 INFO    : [INFO] Found new best model with 0.173 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:54:59,617 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:54:59,617 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:55:01,609 INFO    : [INFO] End of valid | time:  1.99s | valid loss 47.9388 | 
2023-05-10 15:55:01,609 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 15:55:01,609 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:55:01,609 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:55:13,431 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:55:25,256 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:55:37,093 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:55:49,063 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:56:01,181 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:56:13,440 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:56:25,535 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:56:37,539 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:56:49,378 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:57:01,493 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:57:13,742 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:57:26,161 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:57:38,383 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:57:50,452 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:58:02,588 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:58:14,971 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:58:27,426 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:58:39,663 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:58:51,946 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:59:04,284 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:59:16,031 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:59:28,095 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:59:39,971 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:59:51,980 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 16:00:04,278 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:00:16,860 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:00:28,770 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 16:00:41,051 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 16:00:53,052 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:01:05,052 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:01:17,239 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 16:01:29,239 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 16:01:41,633 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 16:01:57,650 INFO    :        | end of iter   0 | time:  5.09s | train loss 0.0000 | 
2023-05-10 16:02:13,976 INFO    :        | end of iter   0 | time:  5.02s | train loss 0.0000 | 
2023-05-10 16:02:30,996 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:02:48,136 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 16:03:05,149 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:03:21,660 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:03:38,479 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:03:55,649 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:04:12,321 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 16:04:29,567 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 16:04:46,589 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:05:03,080 INFO    :        | end of iter   0 | time:  5.36s | train loss 0.0000 | 
2023-05-10 16:05:19,703 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:05:36,271 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 16:05:52,480 INFO    :        | end of iter   0 | time:  5.22s | train loss 0.0000 | 
2023-05-10 16:06:09,596 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:06:26,008 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:06:26,009 INFO    : [INFO] The learning rate now is 0.000012
2023-05-10 16:06:26,009 INFO    :    | end of epoch  40 | time: 684.40s | epoch train loss 0.1687 | 
2023-05-10 16:06:26,009 INFO    : [INFO] Found new best model with 0.169 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:06:26,127 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:06:26,128 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:06:30,653 INFO    : [INFO] End of valid | time:  4.52s | valid loss 47.7662 | 
2023-05-10 16:06:30,653 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 16:06:30,653 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:06:30,653 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:06:47,318 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:07:03,251 INFO    :        | end of iter   0 | time:  4.87s | train loss 0.0000 | 
2023-05-10 16:07:20,337 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:07:37,261 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 16:07:54,015 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:08:10,869 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:08:27,482 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 16:08:44,051 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 16:09:01,245 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 16:09:17,867 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:09:34,514 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 16:09:51,711 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:10:08,648 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:10:25,591 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:10:42,411 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 16:10:58,865 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 16:11:15,552 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:11:32,095 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 16:11:48,372 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:12:05,109 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:12:21,742 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:12:38,252 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:12:55,150 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:13:11,685 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:13:28,555 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 16:13:45,049 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:14:01,943 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:14:18,711 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:14:34,926 INFO    :        | end of iter   0 | time:  5.23s | train loss 0.0000 | 
2023-05-10 16:14:51,395 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:15:08,259 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:15:25,241 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 16:15:41,973 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:15:58,663 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 16:16:15,638 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 16:16:32,278 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:16:49,253 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:17:06,495 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 16:17:23,302 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 16:17:40,405 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:17:57,753 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 16:18:15,013 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:18:32,524 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 16:18:49,511 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:19:06,821 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:19:23,651 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:19:40,835 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:19:57,901 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:20:14,736 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 16:20:31,963 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 16:20:31,963 INFO    : [INFO] The learning rate now is 0.000012
2023-05-10 16:20:31,963 INFO    :    | end of epoch  41 | time: 841.31s | epoch train loss 0.1646 | 
2023-05-10 16:20:31,963 INFO    : [INFO] Found new best model with 0.165 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:20:32,356 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:20:32,357 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:20:37,224 INFO    : [INFO] End of valid | time:  4.87s | valid loss 47.5876 | 
2023-05-10 16:20:37,224 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 16:20:37,224 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:20:37,224 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:20:54,394 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 16:21:11,467 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 16:21:28,672 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 16:21:45,702 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 16:22:02,246 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:22:18,760 INFO    :        | end of iter   0 | time:  5.29s | train loss 0.0000 | 
2023-05-10 16:22:35,891 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 16:22:52,764 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:23:09,453 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 16:23:26,209 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 16:23:42,996 INFO    :        | end of iter   0 | time:  5.28s | train loss 0.0000 | 
2023-05-10 16:24:00,136 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:24:17,287 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:24:33,690 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 16:24:50,943 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 16:25:07,599 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:25:24,151 INFO    :        | end of iter   0 | time:  5.22s | train loss 0.0000 | 
2023-05-10 16:25:40,920 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:25:57,836 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 16:26:14,300 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:26:31,464 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 16:26:48,316 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 16:27:05,123 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 16:27:22,602 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:27:39,748 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:27:56,764 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 16:28:13,519 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:28:30,254 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:28:47,545 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 16:29:04,377 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:29:21,272 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:29:38,089 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:29:54,796 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:30:11,275 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 16:30:28,531 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 16:30:45,392 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:31:02,199 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:31:18,934 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:31:36,026 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:31:52,714 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:32:09,395 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 16:32:26,111 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:32:42,693 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 16:32:59,587 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 16:33:16,098 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:33:32,938 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:33:50,596 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 16:34:07,790 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 16:34:24,468 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 16:34:41,348 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:34:41,349 INFO    : [INFO] The learning rate now is 0.000012
2023-05-10 16:34:41,349 INFO    :    | end of epoch  42 | time: 844.12s | epoch train loss 0.1613 | 
2023-05-10 16:34:41,349 INFO    : [INFO] Found new best model with 0.161 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:34:41,516 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:34:41,517 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:34:45,718 INFO    : [INFO] End of valid | time:  4.20s | valid loss 47.5389 | 
2023-05-10 16:34:45,718 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 16:34:45,718 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:34:45,719 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:35:02,797 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:35:19,735 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:35:36,168 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:35:52,849 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:36:09,919 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:36:26,679 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:36:43,687 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:36:59,967 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 16:37:17,668 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 16:37:34,719 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 16:37:52,182 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 16:38:08,950 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:38:25,299 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 16:38:41,889 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:38:58,418 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:39:15,047 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:39:31,521 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:39:48,546 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:40:05,397 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:40:22,226 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 16:40:39,052 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:40:55,871 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:41:12,316 INFO    :        | end of iter   0 | time:  5.39s | train loss 0.0000 | 
2023-05-10 16:41:29,138 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:41:45,938 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:42:02,623 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:42:19,366 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:42:35,924 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 16:42:53,047 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 16:43:10,020 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:43:27,074 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:43:44,444 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 16:44:01,623 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:44:18,417 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 16:44:35,269 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:44:51,419 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 16:45:05,172 INFO    :        | end of iter   0 | time:  2.81s | train loss 0.0000 | 
2023-05-10 16:45:22,152 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:45:39,106 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:45:56,377 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:46:13,178 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 16:46:29,804 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:46:46,194 INFO    :        | end of iter   0 | time:  5.14s | train loss 0.0000 | 
2023-05-10 16:47:02,815 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:47:19,411 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:47:36,535 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 16:47:53,954 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 16:48:12,305 INFO    :        | end of iter   0 | time:  6.64s | train loss 0.0000 | 
2023-05-10 16:48:30,404 INFO    :        | end of iter   0 | time:  6.78s | train loss 0.0000 | 
2023-05-10 16:48:47,797 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:48:47,797 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 16:48:47,798 INFO    :    | end of epoch  43 | time: 842.08s | epoch train loss 0.1573 | 
2023-05-10 16:48:47,798 INFO    : [INFO] Found new best model with 0.157 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:48:47,950 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:48:47,950 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:48:52,693 INFO    : [INFO] End of valid | time:  4.74s | valid loss 47.2103 | 
2023-05-10 16:48:52,694 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 16:48:52,694 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:48:52,694 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:49:10,125 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 16:49:27,285 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:49:44,347 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:50:01,503 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:50:18,427 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:50:35,301 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 16:50:52,394 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:51:09,712 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 16:51:26,801 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:51:44,134 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:52:01,121 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:52:18,354 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:52:34,785 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:52:51,434 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:53:08,211 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:53:25,028 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:53:41,441 INFO    :        | end of iter   0 | time:  5.42s | train loss 0.0000 | 
2023-05-10 16:53:57,829 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:54:14,431 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:54:31,140 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:54:47,883 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 16:55:04,596 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:55:21,163 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:55:37,967 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:55:54,768 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 16:56:10,803 INFO    :        | end of iter   0 | time:  5.06s | train loss 0.0000 | 
2023-05-10 16:56:27,584 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:56:44,667 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:57:01,819 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:57:18,644 INFO    :        | end of iter   0 | time:  5.36s | train loss 0.0000 | 
2023-05-10 16:57:35,929 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:57:52,856 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 16:58:09,826 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:58:27,173 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:58:44,675 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-10 16:59:01,753 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 16:59:18,261 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:59:35,019 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:59:51,507 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 17:00:08,473 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:00:25,548 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:00:42,291 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 17:00:59,628 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:01:16,932 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 17:01:34,131 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:01:51,144 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 17:02:07,767 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:02:24,965 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:02:42,187 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:02:58,988 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:02:58,989 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 17:02:58,989 INFO    :    | end of epoch  44 | time: 846.30s | epoch train loss 0.1540 | 
2023-05-10 17:02:58,989 INFO    : [INFO] Found new best model with 0.154 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:02:59,113 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:02:59,113 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:03:03,495 INFO    : [INFO] End of valid | time:  4.38s | valid loss 47.0493 | 
2023-05-10 17:03:03,495 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.339713, r:0.258182, f:0.293388

2023-05-10 17:03:03,495 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:03:03,496 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:03:20,413 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:03:37,505 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:03:54,326 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 17:04:11,692 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:04:28,120 INFO    :        | end of iter   0 | time:  5.27s | train loss 0.0000 | 
2023-05-10 17:04:44,814 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 17:05:01,510 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:05:18,481 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:05:36,016 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-10 17:05:52,809 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 17:06:09,978 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 17:06:27,123 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:06:43,515 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:07:00,088 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:07:16,813 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:07:33,709 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:07:50,684 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 17:08:07,439 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:08:23,882 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:08:40,622 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:08:57,443 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 17:09:14,208 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:09:31,377 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:09:47,930 INFO    :        | end of iter   0 | time:  5.29s | train loss 0.0000 | 
2023-05-10 17:10:04,436 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:10:21,479 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:10:38,461 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 17:10:55,542 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:11:12,213 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:11:28,887 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:11:45,990 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:12:03,421 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 17:12:20,269 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 17:12:37,293 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:12:54,090 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:13:10,707 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:13:27,341 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:13:44,124 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:14:00,773 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 17:14:17,577 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 17:14:34,352 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 17:14:51,451 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 17:15:08,642 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 17:15:25,784 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:15:43,020 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:16:00,272 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 17:16:17,511 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:16:34,675 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:16:51,841 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:17:08,687 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 17:17:08,687 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 17:17:08,687 INFO    :    | end of epoch  45 | time: 845.19s | epoch train loss 0.1507 | 
2023-05-10 17:17:08,687 INFO    : [INFO] Found new best model with 0.151 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:17:09,046 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:17:09,046 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:17:13,373 INFO    : [INFO] End of valid | time:  4.33s | valid loss 47.0650 | 
2023-05-10 17:17:13,373 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.339713, r:0.258182, f:0.293388

2023-05-10 17:17:13,373 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:17:13,374 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:17:29,523 INFO    :        | end of iter   0 | time:  5.14s | train loss 0.0000 | 
2023-05-10 17:17:45,891 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:18:02,228 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 17:18:19,356 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 17:18:36,236 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 17:18:53,402 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:19:10,415 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 17:19:27,609 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 17:19:44,225 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:20:00,620 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:20:17,505 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 17:20:34,757 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:20:51,391 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 17:21:07,533 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 17:21:24,000 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:21:41,004 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-10 17:21:57,862 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 17:22:14,637 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:22:31,685 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 17:22:48,416 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:23:04,949 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 17:23:21,349 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 17:23:37,666 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 17:23:54,364 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 17:24:10,599 INFO    :        | end of iter   0 | time:  5.24s | train loss 0.0000 | 
2023-05-10 17:24:27,633 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:24:44,727 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:25:01,699 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:25:18,161 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:25:35,012 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:25:51,739 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:26:08,630 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 17:26:25,216 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 17:26:42,113 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:26:59,109 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:27:15,674 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:27:32,496 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 17:27:49,352 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 17:28:05,851 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:28:22,634 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 17:28:39,368 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:28:56,085 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:29:12,839 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:29:29,642 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 17:29:46,101 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:30:02,673 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:30:19,824 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:30:36,916 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 17:30:53,638 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 17:31:10,343 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:31:10,343 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 17:31:10,344 INFO    :    | end of epoch  46 | time: 836.97s | epoch train loss 0.1473 | 
2023-05-10 17:31:10,344 INFO    : [INFO] Found new best model with 0.147 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:31:10,503 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:31:10,503 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:31:15,176 INFO    : [INFO] End of valid | time:  4.67s | valid loss 47.0596 | 
2023-05-10 17:31:15,177 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.350711, r:0.269091, f:0.304527

2023-05-10 17:31:15,177 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:31:15,177 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:31:32,023 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:31:48,780 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:32:05,986 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 17:32:22,815 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 17:32:39,904 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:32:57,049 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 17:33:13,912 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:33:30,454 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:33:47,510 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 17:34:04,462 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 17:34:20,965 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 17:34:35,723 INFO    :        | end of iter   0 | time:  3.68s | train loss 0.0000 | 
2023-05-10 17:34:53,612 INFO    :        | end of iter   0 | time:  6.90s | train loss 0.0000 | 
2023-05-10 17:35:10,276 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:35:26,853 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 17:35:43,863 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:36:00,944 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 17:36:17,849 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 17:36:34,242 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:36:51,035 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 17:37:07,662 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 17:37:24,813 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:37:41,598 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:37:58,107 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:38:15,284 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:38:32,059 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 17:38:49,231 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 17:39:06,335 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:39:23,337 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 17:39:39,975 INFO    :        | end of iter   0 | time:  5.41s | train loss 0.0000 | 
2023-05-10 17:39:56,904 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 17:40:13,869 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:40:30,218 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 17:40:46,602 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 17:41:03,306 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:41:20,132 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:41:37,053 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:41:53,995 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:42:10,839 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 17:42:27,889 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:42:45,488 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 17:43:02,466 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:43:19,590 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:43:36,785 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 17:43:54,026 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:44:11,061 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:44:28,124 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:44:45,217 INFO    :        | end of iter   0 | time:  5.42s | train loss 0.0000 | 
2023-05-10 17:45:01,594 INFO    :        | end of iter   0 | time:  5.41s | train loss 0.0000 | 
2023-05-10 17:45:18,331 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 17:45:18,331 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 17:45:18,331 INFO    :    | end of epoch  47 | time: 843.15s | epoch train loss 0.1443 | 
2023-05-10 17:45:18,331 INFO    : [INFO] Found new best model with 0.144 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:45:18,456 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:45:18,457 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:45:22,945 INFO    : [INFO] End of valid | time:  4.49s | valid loss 46.9625 | 
2023-05-10 17:45:22,945 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 17:45:22,945 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:45:22,945 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:45:39,687 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:45:56,600 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:46:12,975 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:46:29,573 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:46:46,393 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:47:02,924 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:47:20,034 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 17:47:36,576 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:47:52,804 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 17:48:09,827 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:48:26,271 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:48:43,348 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:49:00,233 INFO    :        | end of iter   0 | time:  5.34s | train loss 0.0000 | 
2023-05-10 17:49:16,973 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:49:33,460 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 17:49:49,925 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 17:50:06,919 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:50:23,424 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 17:50:40,104 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 17:50:57,246 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 17:51:14,141 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 17:51:31,084 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 17:51:48,034 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:52:04,758 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:52:21,182 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 17:52:38,234 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 17:52:54,637 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 17:53:11,635 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:53:28,818 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:53:45,479 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:54:02,297 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:54:19,496 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 17:54:36,510 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:54:53,746 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 17:55:10,744 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:55:27,824 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 17:55:44,907 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:56:01,960 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:56:18,573 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 17:56:35,065 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:56:52,404 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:57:09,045 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 17:57:26,003 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:57:42,855 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:57:59,617 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:58:16,749 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 17:58:33,493 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:58:50,446 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 17:59:06,991 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 17:59:23,969 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 17:59:23,970 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 17:59:23,970 INFO    :    | end of epoch  48 | time: 841.02s | epoch train loss 0.1415 | 
2023-05-10 17:59:23,970 INFO    : [INFO] Found new best model with 0.141 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:59:24,144 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:59:24,144 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:59:28,572 INFO    : [INFO] End of valid | time:  4.43s | valid loss 46.8998 | 
2023-05-10 17:59:28,572 INFO    : Rouge1:
	p:0.373832, r:0.290909, f:0.327198
Rouge2:
	p:0.115385, r:0.086331, f:0.098765
Rougel:
	p:0.345794, r:0.269091, f:0.302658

2023-05-10 17:59:28,572 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:59:28,572 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:59:45,299 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 18:00:01,988 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 18:00:18,561 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:00:35,693 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:00:52,944 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:01:09,740 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 18:01:26,224 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 18:01:42,735 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:01:59,390 INFO    :        | end of iter   0 | time:  5.12s | train loss 0.0000 | 
2023-05-10 18:02:16,467 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:02:33,471 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:02:50,534 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 18:03:07,623 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:03:24,672 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:03:41,637 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:03:58,390 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:04:15,247 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:04:32,469 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 18:04:49,260 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:05:05,822 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:05:22,251 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:05:39,186 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:05:56,021 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:06:13,206 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-10 18:06:30,292 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:06:47,228 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 18:07:04,212 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:07:20,764 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:07:37,970 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 18:07:54,885 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 18:08:11,697 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:08:28,208 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:08:44,742 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:09:01,487 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:09:18,230 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 18:09:34,739 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 18:09:51,065 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 18:10:08,055 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:10:25,179 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:10:42,034 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:10:58,748 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 18:11:15,385 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:11:32,407 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 18:11:48,796 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:12:05,592 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:12:22,253 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:12:39,398 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:12:56,062 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:13:13,284 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 18:13:29,891 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:13:29,891 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 18:13:29,892 INFO    :    | end of epoch  49 | time: 841.32s | epoch train loss 0.1387 | 
2023-05-10 18:13:29,892 INFO    : [INFO] Found new best model with 0.139 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:13:30,045 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:13:30,045 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:13:34,462 INFO    : [INFO] End of valid | time:  4.42s | valid loss 46.7764 | 
2023-05-10 18:13:34,463 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 18:13:34,463 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:13:34,463 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:13:51,613 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:14:08,778 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:14:26,016 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 18:14:43,153 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 18:14:59,712 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:15:16,115 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 18:15:33,135 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:15:49,808 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:16:06,326 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:16:23,010 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:16:39,838 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:16:56,586 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:17:13,580 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:17:30,454 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:17:47,556 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 18:18:04,018 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:18:20,739 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:18:37,497 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:18:54,635 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:19:11,850 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:19:28,861 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:19:45,800 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 18:20:02,815 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 18:20:19,792 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 18:20:36,967 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:20:53,782 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 18:21:07,715 INFO    :        | end of iter   0 | time:  2.90s | train loss 0.0000 | 
2023-05-10 18:21:25,036 INFO    :        | end of iter   0 | time:  6.63s | train loss 0.0000 | 
2023-05-10 18:21:41,276 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 18:21:58,299 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:22:15,281 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 18:22:32,666 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:22:49,264 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:23:06,237 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 18:23:22,913 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 18:23:39,665 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:23:56,948 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:24:13,545 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 18:24:30,146 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 18:24:47,012 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:25:04,108 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 18:25:20,745 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:25:38,036 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:25:55,110 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 18:26:12,279 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:26:29,323 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:26:45,857 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 18:27:02,199 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 18:27:18,922 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:27:35,599 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:27:35,599 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 18:27:35,599 INFO    :    | end of epoch  50 | time: 841.14s | epoch train loss 0.1358 | 
2023-05-10 18:27:35,599 INFO    : [INFO] Found new best model with 0.136 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:27:35,732 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:27:35,732 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:27:40,014 INFO    : [INFO] End of valid | time:  4.28s | valid loss 46.7294 | 
2023-05-10 18:27:40,014 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 18:27:40,014 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:27:40,015 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:27:56,942 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:28:13,657 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:28:30,328 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:28:46,952 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:29:03,458 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 18:29:20,183 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 18:29:37,008 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 18:29:53,922 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 18:30:11,273 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:30:28,282 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:30:45,014 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:31:01,366 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 18:31:18,452 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:31:35,241 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 18:31:52,549 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:32:09,150 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 18:32:26,427 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:32:43,094 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:32:59,545 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:33:16,511 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:33:33,310 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 18:33:50,268 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:34:06,921 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:34:23,622 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:34:39,650 INFO    :        | end of iter   0 | time:  5.19s | train loss 0.0000 | 
2023-05-10 18:34:56,457 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:35:13,318 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:35:30,145 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 18:35:46,808 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:36:03,628 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:36:20,317 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 18:36:37,064 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 18:36:53,714 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:37:10,606 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 18:37:27,575 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:37:44,837 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 18:38:02,025 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:38:19,236 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:38:36,344 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:38:53,573 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:39:10,518 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:39:27,263 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:39:44,407 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 18:40:01,432 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 18:40:18,235 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:40:35,323 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 18:40:51,788 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 18:41:08,493 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:41:25,252 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:41:42,176 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:41:42,177 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 18:41:42,177 INFO    :    | end of epoch  51 | time: 842.16s | epoch train loss 0.1330 | 
2023-05-10 18:41:42,177 INFO    : [INFO] Found new best model with 0.133 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:41:42,313 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:41:42,313 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:41:46,916 INFO    : [INFO] End of valid | time:  4.60s | valid loss 46.7178 | 
2023-05-10 18:41:46,917 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.341232, r:0.261818, f:0.296296

2023-05-10 18:41:46,917 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:41:46,917 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:42:03,982 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:42:20,674 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:42:37,882 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:42:55,363 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 18:43:12,710 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:43:29,628 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:43:47,048 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 18:43:59,798 INFO    :        | end of iter   0 | time:  1.41s | train loss 0.0000 | 
2023-05-10 18:44:16,945 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:44:34,314 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 18:44:51,625 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:45:09,268 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 18:45:26,554 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 18:45:43,417 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 18:46:00,308 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:46:16,747 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 18:46:33,467 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:46:50,176 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 18:47:07,224 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:47:24,167 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:47:40,672 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:47:57,250 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:48:14,341 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:48:31,641 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:48:48,801 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:49:05,861 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:49:22,989 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:49:39,984 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:49:57,093 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:50:14,480 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:50:31,498 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:50:48,038 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:51:04,849 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:51:22,026 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:51:39,371 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:51:56,864 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 18:52:14,161 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:52:31,246 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:52:48,103 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:53:04,643 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:53:21,792 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:53:38,793 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:53:55,234 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:54:11,830 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:54:28,920 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 18:54:46,119 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:55:03,140 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:55:20,236 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:55:37,655 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:55:54,362 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:55:54,363 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 18:55:54,363 INFO    :    | end of epoch  52 | time: 847.45s | epoch train loss 0.1306 | 
2023-05-10 18:55:54,363 INFO    : [INFO] Found new best model with 0.131 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:55:54,522 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:55:54,523 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:55:59,191 INFO    : [INFO] End of valid | time:  4.67s | valid loss 46.7858 | 
2023-05-10 18:55:59,191 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.350711, r:0.269091, f:0.304527

2023-05-10 18:55:59,191 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:55:59,191 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:56:15,647 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 18:56:32,549 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:56:49,540 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:57:07,122 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-10 18:57:24,461 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:57:41,616 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:57:58,760 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:58:15,761 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:58:33,265 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 18:58:50,744 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:59:07,729 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:59:23,922 INFO    :        | end of iter   0 | time:  5.12s | train loss 0.0000 | 
2023-05-10 18:59:40,911 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:59:57,603 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 19:00:14,510 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:00:31,412 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:00:48,404 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 19:01:05,543 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:01:22,621 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 19:01:39,841 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 19:01:56,891 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 19:02:14,175 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 19:02:30,761 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:02:47,682 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 19:03:04,586 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:03:21,849 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 19:03:38,709 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 19:03:55,508 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 19:04:12,197 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:04:28,856 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 19:04:45,185 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 19:05:02,015 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 19:05:18,517 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 19:05:35,399 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 19:05:52,287 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:06:08,938 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:06:25,590 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:06:42,482 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 19:06:59,352 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 19:07:16,676 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 19:07:33,682 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 19:07:51,498 INFO    :        | end of iter   0 | time:  6.85s | train loss 0.0000 | 
2023-05-10 19:08:08,766 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 19:08:25,751 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 19:08:42,952 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 19:08:59,652 INFO    :        | end of iter   0 | time:  5.23s | train loss 0.0000 | 
2023-05-10 19:09:16,857 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 19:09:33,863 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:09:50,523 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 19:10:07,422 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 19:10:07,422 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 19:10:07,423 INFO    :    | end of epoch  53 | time: 848.23s | epoch train loss 0.1281 | 
2023-05-10 19:10:07,423 INFO    : [INFO] Found new best model with 0.128 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 19:10:07,562 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 19:10:07,563 INFO    : [INFO] Starting eval for this model ...
2023-05-10 19:10:12,174 INFO    : [INFO] End of valid | time:  4.61s | valid loss 46.6701 | 
2023-05-10 19:10:12,174 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 19:10:12,174 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 19:10:12,174 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 19:10:29,079 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 19:10:45,692 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
