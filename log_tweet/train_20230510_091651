2023-05-10 09:16:51,668 INFO    : Pytorch 1.13.1
2023-05-10 09:16:51,669 INFO    : [INFO] Create Vocab, vocab path is cache/tweet/vocab
2023-05-10 09:16:51,695 INFO    : [INFO] Finished constructing vocabulary of 30754 total words. Last word added: est:
2023-05-10 09:16:51,755 INFO    : [INFO] Loading external word embedding...
2023-05-10 09:17:25,945 INFO    : [INFO] External Word Embedding iov count: 23075, oov count: 7679
2023-05-10 09:17:26,058 INFO    : Namespace(atten_dropout_prob=0.1, batch_size=50, bert_path='bert_features_tweet', bidirectional=True, cache_dir='cache/tweet', cuda=True, data_dir='/mnt/data/ztl/MTGNN-SUM/data_tweet/exp_data', doc_max_timesteps=150, embed_train=False, embedding_path='glove.42B.300d.txt', feat_embed_size=50, ffn_dropout_prob=0.1, ffn_inner_hidden_size=512, gpu='3', grad_clip=True, hidden_size=64, log_root='log_tweet/', lr=0.0005, lr_descent=True, lstm_hidden_state=128, lstm_layers=2, m=15, max_grad_norm=1.0, model='MTHSG', n_epochs=100, n_feature_size=128, n_head=8, n_iter=1, n_layers=1, recurrent_dropout_prob=0.1, restore_model='None', save_root='models_tweet', seed=666, sent_max_len=100, use_orthnormal_init=True, vocab_size=50000, word_emb_dim=300, word_embedding=True)
2023-05-10 09:17:26,198 INFO    : [MODEL] HeterSumGraph 
2023-05-10 09:17:26,198 INFO    : [INFO] Start reading ExampleSet
2023-05-10 09:17:26,207 INFO    : [INFO] Finish reading ExampleSet. Total time is 0.009074, Total size is 9
2023-05-10 09:17:26,207 INFO    : [INFO] Loading filter word File cache/tweet/filter_word.txt
2023-05-10 09:17:26,216 INFO    : [INFO] Loading word2sent TFIDF file from cache/tweet/train.w2s.tfidf.jsonl!
2023-05-10 09:17:26,426 INFO    : [INFO] Start reading ExampleSet
2023-05-10 09:17:26,427 INFO    : [INFO] Finish reading ExampleSet. Total time is 0.000989, Total size is 1
2023-05-10 09:17:26,427 INFO    : [INFO] Loading filter word File cache/tweet/filter_word.txt
2023-05-10 09:17:26,437 INFO    : [INFO] Loading word2sent TFIDF file from cache/tweet/val.w2s.tfidf.jsonl!
2023-05-10 09:17:27,969 INFO    : [INFO] Use cuda
2023-05-10 09:17:27,969 INFO    : [INFO] Create new model for training...
2023-05-10 09:17:27,976 INFO    : [INFO] Starting run_training
2023-05-10 09:17:41,163 INFO    :        | end of iter   0 | time:  2.58s | train loss 0.5764 | 
2023-05-10 09:17:52,812 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.4068 | 
2023-05-10 09:18:04,417 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.3726 | 
2023-05-10 09:18:15,926 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2830 | 
2023-05-10 09:18:27,309 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2871 | 
2023-05-10 09:18:38,748 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.3570 | 
2023-05-10 09:18:50,166 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.3163 | 
2023-05-10 09:19:01,473 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2608 | 
2023-05-10 09:19:12,824 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.2614 | 
2023-05-10 09:19:24,088 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.2741 | 
2023-05-10 09:19:35,238 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2716 | 
2023-05-10 09:19:46,751 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.2594 | 
2023-05-10 09:19:58,061 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.2529 | 
2023-05-10 09:20:09,283 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2553 | 
2023-05-10 09:20:20,687 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.2533 | 
2023-05-10 09:20:32,441 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2512 | 
2023-05-10 09:20:43,956 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2501 | 
2023-05-10 09:20:55,432 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.2494 | 
2023-05-10 09:21:06,712 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2472 | 
2023-05-10 09:21:17,901 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.2475 | 
2023-05-10 09:21:29,171 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2455 | 
2023-05-10 09:21:40,549 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.2443 | 
2023-05-10 09:21:51,955 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2424 | 
2023-05-10 09:22:03,459 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2389 | 
2023-05-10 09:22:14,743 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2363 | 
2023-05-10 09:22:26,209 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2332 | 
2023-05-10 09:22:37,474 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2277 | 
2023-05-10 09:22:49,210 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.2286 | 
2023-05-10 09:23:00,422 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2194 | 
2023-05-10 09:23:11,645 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2150 | 
2023-05-10 09:23:22,968 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2059 | 
2023-05-10 09:23:34,284 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.2094 | 
2023-05-10 09:23:45,580 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1997 | 
2023-05-10 09:23:56,978 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.1937 | 
2023-05-10 09:24:08,506 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.1859 | 
2023-05-10 09:24:19,955 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.1794 | 
2023-05-10 09:24:31,668 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1687 | 
2023-05-10 09:24:43,350 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1718 | 
2023-05-10 09:24:55,114 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.1616 | 
2023-05-10 09:25:07,027 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.1555 | 
2023-05-10 09:25:18,468 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1457 | 
2023-05-10 09:25:29,669 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1434 | 
2023-05-10 09:25:40,978 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1339 | 
2023-05-10 09:25:52,487 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.1317 | 
2023-05-10 09:26:03,942 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.1235 | 
2023-05-10 09:26:15,430 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.1110 | 
2023-05-10 09:26:26,863 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.1000 | 
2023-05-10 09:26:38,291 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.1174 | 
2023-05-10 09:26:49,662 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.1037 | 
2023-05-10 09:27:00,840 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0857 | 
2023-05-10 09:27:00,840 INFO    : [INFO] The learning rate now is 0.000250
2023-05-10 09:27:00,840 INFO    :    | end of epoch   1 | time: 572.86s | epoch train loss 1129.2045 | 
2023-05-10 09:27:00,840 INFO    : [INFO] Found new best model with 1129.205 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:27:00,893 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:27:00,893 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:27:02,848 INFO    : [INFO] End of valid | time:  1.95s | valid loss 17.9547 | 
2023-05-10 09:27:02,848 INFO    : Rouge1:
	p:0.304569, r:0.218182, f:0.254237
Rouge2:
	p:0.086379, r:0.062350, f:0.072423
Rougel:
	p:0.263959, r:0.189091, f:0.220339

2023-05-10 09:27:02,848 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:27:02,848 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:27:02,848 INFO    : [INFO] Found new best model with 17.954659 running_avg_loss. The original loss is None, Saving to models_tweet/eval/bestmodel_0
2023-05-10 09:27:02,964 INFO    : [INFO] Found new best model with 0.105263 F. The original F is None, Saving to models_tweet/eval/bestFmodel
2023-05-10 09:27:14,752 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0834 | 
2023-05-10 09:27:26,172 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0749 | 
2023-05-10 09:27:37,369 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0746 | 
2023-05-10 09:27:48,748 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0704 | 
2023-05-10 09:28:00,047 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0651 | 
2023-05-10 09:28:11,375 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0643 | 
2023-05-10 09:28:22,575 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0596 | 
2023-05-10 09:28:33,803 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0569 | 
2023-05-10 09:28:45,116 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0522 | 
2023-05-10 09:28:56,446 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0497 | 
2023-05-10 09:29:07,697 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0455 | 
2023-05-10 09:29:19,017 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0440 | 
2023-05-10 09:29:30,681 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0411 | 
2023-05-10 09:29:42,038 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0402 | 
2023-05-10 09:29:53,706 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0383 | 
2023-05-10 09:30:05,196 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0374 | 
2023-05-10 09:30:16,533 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0357 | 
2023-05-10 09:30:28,056 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0342 | 
2023-05-10 09:30:39,427 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0336 | 
2023-05-10 09:30:50,775 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0326 | 
2023-05-10 09:31:02,096 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0317 | 
2023-05-10 09:31:13,343 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0305 | 
2023-05-10 09:31:24,810 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0281 | 
2023-05-10 09:31:36,159 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0263 | 
2023-05-10 09:31:47,438 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0244 | 
2023-05-10 09:31:58,784 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0232 | 
2023-05-10 09:32:10,040 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0267 | 
2023-05-10 09:32:21,434 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0202 | 
2023-05-10 09:32:32,730 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0210 | 
2023-05-10 09:32:43,992 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0193 | 
2023-05-10 09:32:55,414 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0189 | 
2023-05-10 09:33:06,725 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0186 | 
2023-05-10 09:33:17,923 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0176 | 
2023-05-10 09:33:29,286 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0172 | 
2023-05-10 09:33:40,710 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0171 | 
2023-05-10 09:33:52,125 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0168 | 
2023-05-10 09:34:03,247 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0161 | 
2023-05-10 09:34:14,788 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0157 | 
2023-05-10 09:34:26,164 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0153 | 
2023-05-10 09:34:37,543 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0148 | 
2023-05-10 09:34:48,954 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0145 | 
2023-05-10 09:35:00,163 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0139 | 
2023-05-10 09:35:11,764 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0136 | 
2023-05-10 09:35:22,949 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0118 | 
2023-05-10 09:35:34,237 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0314 | 
2023-05-10 09:35:45,526 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0127 | 
2023-05-10 09:35:56,771 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0069 | 
2023-05-10 09:36:08,255 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0258 | 
2023-05-10 09:36:19,701 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0232 | 
2023-05-10 09:36:31,132 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0063 | 
2023-05-10 09:36:31,132 INFO    : [INFO] The learning rate now is 0.000167
2023-05-10 09:36:31,132 INFO    :    | end of epoch   2 | time: 567.87s | epoch train loss 161.3246 | 
2023-05-10 09:36:31,132 INFO    : [INFO] Found new best model with 161.325 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:36:31,253 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:36:31,254 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:36:33,226 INFO    : [INFO] End of valid | time:  1.97s | valid loss 28.5944 | 
2023-05-10 09:36:33,226 INFO    : Rouge1:
	p:0.369792, r:0.258182, f:0.304069
Rouge2:
	p:0.076125, r:0.052758, f:0.062323
Rougel:
	p:0.281250, r:0.196364, f:0.231263

2023-05-10 09:36:33,226 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:36:33,226 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:36:44,446 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0066 | 
2023-05-10 09:36:55,621 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0062 | 
2023-05-10 09:37:06,783 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0056 | 
2023-05-10 09:37:17,987 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0054 | 
2023-05-10 09:37:29,453 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0054 | 
2023-05-10 09:37:40,648 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0053 | 
2023-05-10 09:37:51,936 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0051 | 
2023-05-10 09:38:03,255 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0049 | 
2023-05-10 09:38:14,659 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0047 | 
2023-05-10 09:38:26,139 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0046 | 
2023-05-10 09:38:37,464 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0046 | 
2023-05-10 09:38:48,883 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0044 | 
2023-05-10 09:39:00,141 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0043 | 
2023-05-10 09:39:11,318 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0041 | 
2023-05-10 09:39:22,777 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0040 | 
2023-05-10 09:39:34,323 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0039 | 
2023-05-10 09:39:45,672 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0037 | 
2023-05-10 09:39:57,120 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0037 | 
2023-05-10 09:40:08,622 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0036 | 
2023-05-10 09:40:19,925 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0034 | 
2023-05-10 09:40:31,337 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0033 | 
2023-05-10 09:40:42,787 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0032 | 
2023-05-10 09:40:54,147 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0032 | 
2023-05-10 09:41:05,626 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0031 | 
2023-05-10 09:41:17,245 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0030 | 
2023-05-10 09:41:28,707 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0029 | 
2023-05-10 09:41:40,259 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0028 | 
2023-05-10 09:41:52,136 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0027 | 
2023-05-10 09:42:04,265 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0027 | 
2023-05-10 09:42:15,758 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0026 | 
2023-05-10 09:42:27,223 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0025 | 
2023-05-10 09:42:38,825 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0024 | 
2023-05-10 09:42:50,426 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0023 | 
2023-05-10 09:43:01,894 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0023 | 
2023-05-10 09:43:13,359 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0022 | 
2023-05-10 09:43:24,769 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0021 | 
2023-05-10 09:43:36,170 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0021 | 
2023-05-10 09:43:47,656 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0020 | 
2023-05-10 09:43:58,870 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0020 | 
2023-05-10 09:44:10,312 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0019 | 
2023-05-10 09:44:21,578 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0018 | 
2023-05-10 09:44:33,022 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0018 | 
2023-05-10 09:44:44,436 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0017 | 
2023-05-10 09:44:55,745 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0017 | 
2023-05-10 09:45:06,964 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0016 | 
2023-05-10 09:45:18,569 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0016 | 
2023-05-10 09:45:30,009 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0015 | 
2023-05-10 09:45:41,588 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0015 | 
2023-05-10 09:45:53,781 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0014 | 
2023-05-10 09:46:05,350 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0014 | 
2023-05-10 09:46:05,350 INFO    : [INFO] The learning rate now is 0.000125
2023-05-10 09:46:05,350 INFO    :    | end of epoch   3 | time: 572.12s | epoch train loss 16.0957 | 
2023-05-10 09:46:05,351 INFO    : [INFO] Found new best model with 16.096 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:46:05,489 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:46:05,489 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:46:07,449 INFO    : [INFO] End of valid | time:  1.96s | valid loss 34.9757 | 
2023-05-10 09:46:07,449 INFO    : Rouge1:
	p:0.355450, r:0.272727, f:0.308642
Rouge2:
	p:0.106109, r:0.079137, f:0.090659
Rougel:
	p:0.322275, r:0.247273, f:0.279835

2023-05-10 09:46:07,449 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:46:07,450 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:46:19,103 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0014 | 
2023-05-10 09:46:30,922 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0013 | 
2023-05-10 09:46:42,339 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0013 | 
2023-05-10 09:46:53,792 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0013 | 
2023-05-10 09:47:05,156 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0013 | 
2023-05-10 09:47:16,539 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0012 | 
2023-05-10 09:47:28,020 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0012 | 
2023-05-10 09:47:39,289 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0012 | 
2023-05-10 09:47:50,562 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0012 | 
2023-05-10 09:48:01,807 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0011 | 
2023-05-10 09:48:13,087 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0011 | 
2023-05-10 09:48:24,506 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0011 | 
2023-05-10 09:48:35,746 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0011 | 
2023-05-10 09:48:47,016 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0010 | 
2023-05-10 09:48:58,286 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0010 | 
2023-05-10 09:49:09,512 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0010 | 
2023-05-10 09:49:20,868 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0010 | 
2023-05-10 09:49:32,170 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0009 | 
2023-05-10 09:49:43,378 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0009 | 
2023-05-10 09:49:54,754 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0009 | 
2023-05-10 09:50:06,075 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0009 | 
2023-05-10 09:50:17,413 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0009 | 
2023-05-10 09:50:28,733 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0008 | 
2023-05-10 09:50:40,114 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0008 | 
2023-05-10 09:50:51,321 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0008 | 
2023-05-10 09:51:02,627 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0008 | 
2023-05-10 09:51:13,924 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0008 | 
2023-05-10 09:51:25,270 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0008 | 
2023-05-10 09:51:36,524 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:51:47,755 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:51:58,934 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0007 | 
2023-05-10 09:52:10,190 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0007 | 
2023-05-10 09:52:21,637 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0007 | 
2023-05-10 09:52:32,914 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:52:44,297 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0007 | 
2023-05-10 09:52:55,800 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:53:07,083 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:53:18,476 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:53:29,734 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0006 | 
2023-05-10 09:53:41,133 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0006 | 
2023-05-10 09:53:52,601 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0006 | 
2023-05-10 09:54:04,142 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0006 | 
2023-05-10 09:54:15,326 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:54:26,962 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0006 | 
2023-05-10 09:54:38,247 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:54:49,562 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:55:00,738 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:55:11,798 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0005 | 
2023-05-10 09:55:23,114 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:55:34,484 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:55:34,485 INFO    : [INFO] The learning rate now is 0.000100
2023-05-10 09:55:34,485 INFO    :    | end of epoch   4 | time: 567.03s | epoch train loss 4.2509 | 
2023-05-10 09:55:34,485 INFO    : [INFO] Found new best model with 4.251 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 09:55:34,608 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 09:55:34,608 INFO    : [INFO] Starting eval for this model ...
2023-05-10 09:55:36,579 INFO    : [INFO] End of valid | time:  1.97s | valid loss 39.8251 | 
2023-05-10 09:55:36,579 INFO    : Rouge1:
	p:0.355450, r:0.272727, f:0.308642
Rouge2:
	p:0.106109, r:0.079137, f:0.090659
Rougel:
	p:0.317536, r:0.243636, f:0.275720

2023-05-10 09:55:36,579 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 09:55:36,579 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 09:55:47,961 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:55:59,094 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:56:10,469 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:56:22,000 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:56:33,244 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:56:44,400 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:56:55,647 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:57:06,943 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0005 | 
2023-05-10 09:57:18,361 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:57:29,685 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0005 | 
2023-05-10 09:57:40,968 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:57:52,273 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:03,529 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:14,815 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:26,139 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:37,365 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0004 | 
2023-05-10 09:58:48,619 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:58:59,838 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:11,262 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:22,449 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:33,787 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:45,078 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 09:59:56,421 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:00:07,882 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:00:19,177 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:00:30,483 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:00:41,747 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:00:52,996 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:01:04,277 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:01:15,629 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0004 | 
2023-05-10 10:01:26,964 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:01:38,585 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0004 | 
2023-05-10 10:01:50,187 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0004 | 
2023-05-10 10:02:01,621 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0004 | 
2023-05-10 10:02:13,077 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0004 | 
2023-05-10 10:02:24,499 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:02:35,867 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:02:47,264 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:02:58,522 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:03:09,891 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:03:21,262 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:03:32,609 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:03:43,942 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:03:55,203 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:04:06,425 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:04:17,704 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:04:28,982 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:04:40,585 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:04:51,901 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:05:03,183 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0003 | 
2023-05-10 10:05:03,183 INFO    : [INFO] The learning rate now is 0.000083
2023-05-10 10:05:03,183 INFO    :    | end of epoch   5 | time: 566.60s | epoch train loss 1.9553 | 
2023-05-10 10:05:03,183 INFO    : [INFO] Found new best model with 1.955 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:05:03,349 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:05:03,349 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:05:05,339 INFO    : [INFO] End of valid | time:  1.99s | valid loss 42.1063 | 
2023-05-10 10:05:05,339 INFO    : Rouge1:
	p:0.355450, r:0.272727, f:0.308642
Rouge2:
	p:0.106109, r:0.079137, f:0.090659
Rougel:
	p:0.317536, r:0.243636, f:0.275720

2023-05-10 10:05:05,339 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:05:05,339 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:05:16,709 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:05:27,983 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:05:39,373 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:05:50,768 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:06:01,957 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:06:13,407 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:06:24,724 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:06:36,016 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:06:47,197 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:06:58,508 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:07:09,819 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:07:21,050 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:07:32,444 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0003 | 
2023-05-10 10:07:43,672 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:07:55,102 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:08:06,465 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:08:17,851 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:08:29,109 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:08:40,414 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:08:51,656 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:03,033 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:14,312 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:25,375 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:36,505 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:09:47,994 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:09:59,434 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:10:10,682 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:10:21,863 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:10:33,319 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:10:44,834 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:10:56,145 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0003 | 
2023-05-10 10:11:07,455 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:11:18,808 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:11:30,159 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:11:41,822 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0003 | 
2023-05-10 10:11:53,282 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:12:04,447 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0003 | 
2023-05-10 10:12:15,848 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:12:27,240 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:12:38,639 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:12:50,091 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:13:01,762 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:13:13,076 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:13:24,531 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0002 | 
2023-05-10 10:13:35,819 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:13:47,167 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0002 | 
2023-05-10 10:13:58,532 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0002 | 
2023-05-10 10:14:09,752 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:14:21,318 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0002 | 
2023-05-10 10:14:32,599 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:14:32,599 INFO    : [INFO] The learning rate now is 0.000071
2023-05-10 10:14:32,600 INFO    :    | end of epoch   6 | time: 567.26s | epoch train loss 1.3300 | 
2023-05-10 10:14:32,600 INFO    : [INFO] Found new best model with 1.330 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:14:32,726 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:14:32,726 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:14:34,683 INFO    : [INFO] End of valid | time:  1.96s | valid loss 43.5524 | 
2023-05-10 10:14:34,683 INFO    : Rouge1:
	p:0.380282, r:0.294545, f:0.331967
Rouge2:
	p:0.113269, r:0.083933, f:0.096419
Rougel:
	p:0.342723, r:0.265455, f:0.299180

2023-05-10 10:14:34,683 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:14:34,683 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:14:45,802 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:14:56,907 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:15:08,210 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:15:19,709 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:15:31,156 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:15:42,538 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:15:53,823 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:05,143 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:16,531 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:27,752 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:16:39,004 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:16:50,554 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:17:02,027 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:17:13,406 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:17:24,677 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:17:36,015 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:17:47,294 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:17:58,675 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:09,906 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:21,500 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:18:32,862 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:44,082 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:18:55,499 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0002 | 
2023-05-10 10:19:06,884 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:19:18,366 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0002 | 
2023-05-10 10:19:29,903 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0002 | 
2023-05-10 10:19:41,333 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:19:52,563 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:20:04,010 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0002 | 
2023-05-10 10:20:15,354 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0002 | 
2023-05-10 10:20:26,655 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0002 | 
2023-05-10 10:20:37,758 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:20:49,212 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:21:00,547 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:21:11,845 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:21:23,070 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:21:34,496 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:21:45,795 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:21:57,213 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:22:08,559 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:22:19,917 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:22:31,261 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:22:42,465 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:22:53,693 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:23:05,291 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:23:16,687 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:23:27,965 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:23:39,359 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:23:50,689 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:24:01,954 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:24:01,954 INFO    : [INFO] The learning rate now is 0.000063
2023-05-10 10:24:01,955 INFO    :    | end of epoch   7 | time: 567.27s | epoch train loss 1.0350 | 
2023-05-10 10:24:01,955 INFO    : [INFO] Found new best model with 1.035 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:24:02,081 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:24:02,081 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:24:04,040 INFO    : [INFO] End of valid | time:  1.96s | valid loss 44.5473 | 
2023-05-10 10:24:04,040 INFO    : Rouge1:
	p:0.380282, r:0.294545, f:0.331967
Rouge2:
	p:0.113269, r:0.083933, f:0.096419
Rougel:
	p:0.342723, r:0.265455, f:0.299180

2023-05-10 10:24:04,040 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:24:04,041 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:24:15,397 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:24:26,866 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:24:38,276 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:24:49,771 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:01,088 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:12,395 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:23,631 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:34,748 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:46,051 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:25:57,426 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:08,759 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:20,003 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:31,235 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:26:42,501 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:26:53,855 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:27:05,091 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:27:16,334 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:27:27,778 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:27:39,287 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:27:50,633 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:28:01,917 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:13,104 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:24,387 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:35,638 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:46,793 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:28:58,055 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:09,236 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:20,572 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:31,735 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:29:43,137 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:29:54,390 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:05,614 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:16,877 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:28,144 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:39,403 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:30:50,619 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:01,889 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:13,283 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:31:24,543 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:35,883 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:47,128 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:31:58,775 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0002 | 
2023-05-10 10:32:10,322 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:32:21,759 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:32:33,088 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:32:44,408 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:32:55,685 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:33:06,945 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:33:18,505 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0002 | 
2023-05-10 10:33:29,896 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:33:29,896 INFO    : [INFO] The learning rate now is 0.000056
2023-05-10 10:33:29,896 INFO    :    | end of epoch   8 | time: 565.86s | epoch train loss 0.8569 | 
2023-05-10 10:33:29,897 INFO    : [INFO] Found new best model with 0.857 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:33:30,151 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:33:30,151 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:33:32,119 INFO    : [INFO] End of valid | time:  1.97s | valid loss 45.3476 | 
2023-05-10 10:33:32,119 INFO    : Rouge1:
	p:0.360577, r:0.272727, f:0.310559
Rouge2:
	p:0.114379, r:0.083933, f:0.096819
Rougel:
	p:0.326923, r:0.247273, f:0.281573

2023-05-10 10:33:32,119 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:33:32,119 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:33:43,586 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:33:55,035 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:06,430 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:17,800 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:29,126 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:34:40,272 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:34:51,448 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:35:02,739 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:35:13,965 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:35:25,238 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:35:36,588 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:35:48,008 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:35:59,580 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0002 | 
2023-05-10 10:36:10,737 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:36:21,898 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0002 | 
2023-05-10 10:36:33,384 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:36:44,865 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:36:56,174 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0002 | 
2023-05-10 10:37:07,625 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:37:18,948 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0002 | 
2023-05-10 10:37:30,302 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:37:41,536 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 10:37:52,650 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:38:04,072 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:38:15,489 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0001 | 
2023-05-10 10:38:27,113 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:38:38,848 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 10:38:50,187 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:39:01,418 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 10:39:12,760 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:39:24,189 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:39:35,531 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:39:46,830 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:39:58,019 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:09,245 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:20,458 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:31,650 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:42,869 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:40:54,410 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:41:05,748 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:41:17,108 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:41:28,428 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:41:39,855 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:41:51,240 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 10:42:02,728 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:42:14,190 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:42:25,506 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:42:36,822 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 10:42:48,200 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:42:59,574 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:42:59,574 INFO    : [INFO] The learning rate now is 0.000050
2023-05-10 10:42:59,574 INFO    :    | end of epoch   9 | time: 567.46s | epoch train loss 0.7370 | 
2023-05-10 10:42:59,574 INFO    : [INFO] Found new best model with 0.737 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:42:59,724 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:42:59,724 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:43:01,709 INFO    : [INFO] End of valid | time:  1.99s | valid loss 45.9564 | 
2023-05-10 10:43:01,710 INFO    : Rouge1:
	p:0.376744, r:0.294545, f:0.330612
Rouge2:
	p:0.111821, r:0.083933, f:0.095890
Rougel:
	p:0.339535, r:0.265455, f:0.297959

2023-05-10 10:43:01,710 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:43:01,710 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:43:13,055 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:24,293 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:35,740 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:47,084 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:43:58,580 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 10:44:09,958 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:44:21,599 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 10:44:33,259 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:44:44,431 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:44:56,048 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0001 | 
2023-05-10 10:45:07,409 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:45:18,751 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:45:30,123 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:45:41,508 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:45:52,844 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:04,118 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:15,564 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:46:26,809 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:38,081 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:46:49,233 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:00,592 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:11,782 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:23,097 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:47:34,350 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:45,501 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:47:56,899 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:48:08,263 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0001 | 
2023-05-10 10:48:19,594 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:48:30,793 INFO    :        | end of iter   0 | time:  0.96s | train loss 0.0001 | 
2023-05-10 10:48:42,116 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 10:48:53,307 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:49:04,602 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 10:49:16,065 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 10:49:27,562 INFO    :        | end of iter   0 | time:  0.99s | train loss 0.0001 | 
2023-05-10 10:49:39,057 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:49:50,654 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 10:50:02,005 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:50:13,381 INFO    :        | end of iter   0 | time:  0.97s | train loss 0.0001 | 
2023-05-10 10:50:24,720 INFO    :        | end of iter   0 | time:  0.98s | train loss 0.0001 | 
2023-05-10 10:50:45,565 INFO    :        | end of iter   0 | time: 10.31s | train loss 0.0001 | 
2023-05-10 10:51:08,566 INFO    :        | end of iter   0 | time: 12.14s | train loss 0.0001 | 
2023-05-10 10:51:29,884 INFO    :        | end of iter   0 | time: 10.07s | train loss 0.0001 | 
2023-05-10 10:51:52,154 INFO    :        | end of iter   0 | time: 11.34s | train loss 0.0001 | 
2023-05-10 10:52:15,063 INFO    :        | end of iter   0 | time: 11.86s | train loss 0.0001 | 
2023-05-10 10:52:37,408 INFO    :        | end of iter   0 | time: 11.40s | train loss 0.0001 | 
2023-05-10 10:53:00,488 INFO    :        | end of iter   0 | time: 12.29s | train loss 0.0001 | 
2023-05-10 10:53:22,578 INFO    :        | end of iter   0 | time: 11.38s | train loss 0.0001 | 
2023-05-10 10:53:46,354 INFO    :        | end of iter   0 | time: 12.79s | train loss 0.0001 | 
2023-05-10 10:54:09,580 INFO    :        | end of iter   0 | time: 12.38s | train loss 0.0001 | 
2023-05-10 10:54:32,327 INFO    :        | end of iter   0 | time: 11.42s | train loss 0.0001 | 
2023-05-10 10:54:32,327 INFO    : [INFO] The learning rate now is 0.000045
2023-05-10 10:54:32,327 INFO    :    | end of epoch  10 | time: 690.62s | epoch train loss 0.6509 | 
2023-05-10 10:54:32,327 INFO    : [INFO] Found new best model with 0.651 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 10:54:32,466 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 10:54:32,466 INFO    : [INFO] Starting eval for this model ...
2023-05-10 10:54:39,817 INFO    : [INFO] End of valid | time:  7.35s | valid loss 46.4386 | 
2023-05-10 10:54:39,818 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 10:54:39,818 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 10:54:39,818 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 10:55:02,090 INFO    :        | end of iter   0 | time: 11.04s | train loss 0.0001 | 
2023-05-10 10:55:23,454 INFO    :        | end of iter   0 | time: 10.34s | train loss 0.0001 | 
2023-05-10 10:55:45,722 INFO    :        | end of iter   0 | time: 10.61s | train loss 0.0001 | 
2023-05-10 10:56:08,998 INFO    :        | end of iter   0 | time: 11.72s | train loss 0.0001 | 
2023-05-10 10:56:31,234 INFO    :        | end of iter   0 | time: 11.14s | train loss 0.0001 | 
2023-05-10 10:56:54,027 INFO    :        | end of iter   0 | time: 10.80s | train loss 0.0001 | 
2023-05-10 10:57:16,731 INFO    :        | end of iter   0 | time: 11.59s | train loss 0.0001 | 
2023-05-10 10:57:39,087 INFO    :        | end of iter   0 | time: 10.78s | train loss 0.0001 | 
2023-05-10 10:58:02,721 INFO    :        | end of iter   0 | time: 12.23s | train loss 0.0001 | 
2023-05-10 10:58:26,396 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 10:58:49,553 INFO    :        | end of iter   0 | time: 12.03s | train loss 0.0001 | 
2023-05-10 10:59:11,489 INFO    :        | end of iter   0 | time: 10.85s | train loss 0.0001 | 
2023-05-10 10:59:35,730 INFO    :        | end of iter   0 | time: 12.38s | train loss 0.0001 | 
2023-05-10 10:59:58,990 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 11:00:21,447 INFO    :        | end of iter   0 | time: 11.60s | train loss 0.0001 | 
2023-05-10 11:00:43,516 INFO    :        | end of iter   0 | time: 11.18s | train loss 0.0001 | 
2023-05-10 11:01:07,761 INFO    :        | end of iter   0 | time: 13.13s | train loss 0.0001 | 
2023-05-10 11:01:29,945 INFO    :        | end of iter   0 | time: 10.91s | train loss 0.0001 | 
2023-05-10 11:01:50,898 INFO    :        | end of iter   0 | time: 10.15s | train loss 0.0001 | 
2023-05-10 11:02:14,123 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 11:02:36,446 INFO    :        | end of iter   0 | time: 11.14s | train loss 0.0001 | 
2023-05-10 11:02:59,473 INFO    :        | end of iter   0 | time: 11.52s | train loss 0.0001 | 
2023-05-10 11:03:22,372 INFO    :        | end of iter   0 | time: 11.27s | train loss 0.0001 | 
2023-05-10 11:03:45,541 INFO    :        | end of iter   0 | time: 11.71s | train loss 0.0001 | 
2023-05-10 11:04:06,827 INFO    :        | end of iter   0 | time: 10.37s | train loss 0.0001 | 
2023-05-10 11:04:28,976 INFO    :        | end of iter   0 | time: 10.84s | train loss 0.0001 | 
2023-05-10 11:04:51,602 INFO    :        | end of iter   0 | time: 10.93s | train loss 0.0001 | 
2023-05-10 11:05:15,057 INFO    :        | end of iter   0 | time: 11.59s | train loss 0.0001 | 
2023-05-10 11:05:37,397 INFO    :        | end of iter   0 | time: 11.29s | train loss 0.0001 | 
2023-05-10 11:05:58,665 INFO    :        | end of iter   0 | time: 10.13s | train loss 0.0001 | 
2023-05-10 11:06:21,189 INFO    :        | end of iter   0 | time: 11.09s | train loss 0.0001 | 
2023-05-10 11:06:44,532 INFO    :        | end of iter   0 | time: 12.37s | train loss 0.0001 | 
2023-05-10 11:07:07,601 INFO    :        | end of iter   0 | time: 11.64s | train loss 0.0001 | 
2023-05-10 11:07:31,037 INFO    :        | end of iter   0 | time: 12.06s | train loss 0.0001 | 
2023-05-10 11:07:53,264 INFO    :        | end of iter   0 | time: 10.97s | train loss 0.0001 | 
2023-05-10 11:08:15,050 INFO    :        | end of iter   0 | time: 10.92s | train loss 0.0001 | 
2023-05-10 11:08:38,206 INFO    :        | end of iter   0 | time: 12.20s | train loss 0.0001 | 
2023-05-10 11:09:01,356 INFO    :        | end of iter   0 | time: 11.46s | train loss 0.0001 | 
2023-05-10 11:09:24,640 INFO    :        | end of iter   0 | time: 12.16s | train loss 0.0001 | 
2023-05-10 11:09:42,235 INFO    :        | end of iter   0 | time:  6.56s | train loss 0.0001 | 
2023-05-10 11:09:55,291 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 11:10:07,848 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 11:10:19,936 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:10:32,008 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:10:44,141 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:10:56,328 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:11:09,593 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:11:22,156 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:11:34,624 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:11:47,190 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:11:47,190 INFO    : [INFO] The learning rate now is 0.000042
2023-05-10 11:11:47,190 INFO    :    | end of epoch  11 | time: 1027.37s | epoch train loss 0.5838 | 
2023-05-10 11:11:47,190 INFO    : [INFO] Found new best model with 0.584 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:11:47,320 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:11:47,320 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:11:49,540 INFO    : [INFO] End of valid | time:  2.22s | valid loss 46.9055 | 
2023-05-10 11:11:49,541 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 11:11:49,541 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:11:49,541 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:12:02,393 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:12:14,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:12:26,971 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:12:39,371 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:12:51,796 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:13:04,529 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:13:16,787 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:13:29,292 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:13:41,320 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:13:53,666 INFO    :        | end of iter   0 | time:  1.29s | train loss 0.0001 | 
2023-05-10 11:14:06,390 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 11:14:18,326 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 11:14:30,716 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:14:43,086 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:14:55,632 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:15:08,289 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:15:20,029 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:15:32,734 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:15:45,175 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:15:57,378 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:16:09,633 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:16:22,155 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:16:35,318 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:16:48,198 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:17:00,704 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:17:13,329 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:17:26,432 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:17:40,235 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:17:53,171 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:18:05,611 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:18:18,608 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:18:31,400 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:18:43,918 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:18:57,035 INFO    :        | end of iter   0 | time:  1.47s | train loss 0.0001 | 
2023-05-10 11:19:10,185 INFO    :        | end of iter   0 | time:  1.36s | train loss 0.0001 | 
2023-05-10 11:19:23,264 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:19:36,188 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:19:48,541 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 11:20:01,753 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:20:14,593 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:20:26,589 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:20:39,051 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:20:51,275 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:21:03,917 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:21:17,288 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 11:21:30,191 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:21:42,569 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:21:55,645 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:22:08,783 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:22:21,523 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:22:21,524 INFO    : [INFO] The learning rate now is 0.000038
2023-05-10 11:22:21,524 INFO    :    | end of epoch  12 | time: 631.98s | epoch train loss 0.5298 | 
2023-05-10 11:22:21,524 INFO    : [INFO] Found new best model with 0.530 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:22:21,655 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:22:21,655 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:22:23,786 INFO    : [INFO] End of valid | time:  2.13s | valid loss 47.2464 | 
2023-05-10 11:22:23,786 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 11:22:23,786 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:22:23,786 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:22:36,997 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:22:49,395 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:23:02,206 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 11:23:14,686 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:23:27,012 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:23:39,709 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:23:52,063 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:24:04,970 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:24:17,626 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:24:30,251 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:24:42,577 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:24:55,624 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:25:08,414 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 11:25:21,044 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:25:33,916 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:25:47,320 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:25:59,917 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:26:12,574 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:26:24,803 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:26:37,075 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:26:49,881 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:27:01,818 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:27:14,218 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:27:26,712 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:27:39,324 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:27:52,049 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:28:04,672 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:28:17,134 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:28:29,926 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:28:42,671 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:28:55,284 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:07,478 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:29:19,579 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:32,105 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:44,346 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:29:56,373 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:30:08,747 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:30:22,300 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0001 | 
2023-05-10 11:30:35,205 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:30:47,930 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:31:00,728 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:31:13,682 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:31:26,657 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:31:39,196 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:31:51,338 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:32:04,134 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:32:16,823 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:32:29,604 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 11:32:41,735 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:32:54,285 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:32:54,286 INFO    : [INFO] The learning rate now is 0.000036
2023-05-10 11:32:54,286 INFO    :    | end of epoch  13 | time: 630.50s | epoch train loss 0.4869 | 
2023-05-10 11:32:54,286 INFO    : [INFO] Found new best model with 0.487 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:32:54,418 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:32:54,418 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:32:56,573 INFO    : [INFO] End of valid | time:  2.15s | valid loss 47.6462 | 
2023-05-10 11:32:56,573 INFO    : Rouge1:
	p:0.360190, r:0.276364, f:0.312757
Rouge2:
	p:0.112903, r:0.083933, f:0.096286
Rougel:
	p:0.327014, r:0.250909, f:0.283951

2023-05-10 11:32:56,573 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:32:56,574 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:33:09,573 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:33:22,284 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:33:35,402 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:33:48,203 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:33:59,802 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:34:11,888 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:34:25,209 INFO    :        | end of iter   0 | time:  1.96s | train loss 0.0001 | 
2023-05-10 11:34:37,429 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:34:50,550 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:35:02,759 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:35:14,886 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:35:26,775 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:35:38,810 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:35:50,809 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:36:02,871 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:36:15,114 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:36:26,981 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:36:38,963 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:36:50,960 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:37:02,898 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 11:37:14,817 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 11:37:27,051 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:37:39,790 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 11:37:51,896 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:38:03,888 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:38:15,933 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:38:27,735 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:38:39,878 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:38:51,849 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:39:03,692 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:39:15,576 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:39:27,471 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:39:39,604 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:39:52,148 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:40:05,185 INFO    :        | end of iter   0 | time:  1.95s | train loss 0.0001 | 
2023-05-10 11:40:17,220 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:40:29,797 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:40:41,884 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:40:53,921 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:41:05,988 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:41:18,003 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:41:29,987 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:41:42,225 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:41:54,430 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:42:06,354 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:42:18,068 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:42:30,165 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 11:42:42,366 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:42:54,148 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:43:06,239 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:43:06,239 INFO    : [INFO] The learning rate now is 0.000033
2023-05-10 11:43:06,239 INFO    :    | end of epoch  14 | time: 609.67s | epoch train loss 0.4522 | 
2023-05-10 11:43:06,239 INFO    : [INFO] Found new best model with 0.452 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:43:06,350 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:43:06,350 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:43:08,470 INFO    : [INFO] End of valid | time:  2.12s | valid loss 47.9029 | 
2023-05-10 11:43:08,470 INFO    : Rouge1:
	p:0.380282, r:0.294545, f:0.331967
Rouge2:
	p:0.118590, r:0.088729, f:0.101509
Rougel:
	p:0.352113, r:0.272727, f:0.307377

2023-05-10 11:43:08,470 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:43:08,470 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:43:21,015 INFO    :        | end of iter   0 | time:  1.72s | train loss 0.0001 | 
2023-05-10 11:43:32,610 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:43:45,217 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 11:43:57,659 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:44:09,937 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:44:22,168 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:44:34,593 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:44:46,807 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:44:58,822 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:45:10,763 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:45:23,295 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 11:45:35,754 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:45:48,124 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:46:00,503 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:46:12,918 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:46:24,884 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:46:37,774 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:46:49,780 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:47:01,488 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:47:13,469 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:47:25,411 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:47:37,367 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:47:49,209 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:48:01,146 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:48:13,332 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:48:25,544 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 11:48:38,674 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0001 | 
2023-05-10 11:48:51,163 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:49:03,287 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:49:15,475 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:49:27,385 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:49:39,311 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 11:49:51,254 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 11:50:03,516 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:50:15,442 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:50:27,170 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:50:40,184 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:50:52,412 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:51:04,617 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:51:16,705 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:51:28,520 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:51:40,593 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:51:52,864 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:52:05,170 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:52:17,420 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:52:29,689 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:52:41,657 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:52:53,689 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:53:05,428 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:53:17,590 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:53:17,591 INFO    : [INFO] The learning rate now is 0.000031
2023-05-10 11:53:17,591 INFO    :    | end of epoch  15 | time: 609.12s | epoch train loss 0.4210 | 
2023-05-10 11:53:17,591 INFO    : [INFO] Found new best model with 0.421 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 11:53:17,738 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 11:53:17,738 INFO    : [INFO] Starting eval for this model ...
2023-05-10 11:53:19,766 INFO    : [INFO] End of valid | time:  2.03s | valid loss 48.1492 | 
2023-05-10 11:53:19,766 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 11:53:19,766 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 11:53:19,766 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 11:53:31,849 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:53:43,655 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:53:55,655 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:54:07,553 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:54:20,136 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:54:32,713 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:54:44,801 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:54:56,689 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:55:08,686 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:55:20,747 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:55:32,582 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:55:44,488 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:55:56,842 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 11:56:08,808 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:56:20,451 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:56:32,470 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 11:56:44,326 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:56:56,203 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:57:08,206 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 11:57:20,258 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:57:32,261 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 11:57:44,281 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 11:57:56,367 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:58:08,458 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 11:58:20,483 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 11:58:32,391 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:58:44,556 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 11:58:56,918 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:59:09,287 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 11:59:21,654 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 11:59:34,006 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 11:59:46,318 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 11:59:58,388 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:00:10,255 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:00:22,263 INFO    :        | end of iter   0 | time:  1.37s | train loss 0.0001 | 
2023-05-10 12:00:34,255 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:00:45,997 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:00:58,044 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:01:10,250 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:01:22,362 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:01:34,079 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:01:45,969 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:01:57,926 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:02:09,810 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:02:21,632 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:02:33,548 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 12:02:45,420 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:02:57,374 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:03:09,049 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:03:21,266 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 12:03:21,267 INFO    : [INFO] The learning rate now is 0.000029
2023-05-10 12:03:21,267 INFO    :    | end of epoch  16 | time: 601.50s | epoch train loss 0.3956 | 
2023-05-10 12:03:21,267 INFO    : [INFO] Found new best model with 0.396 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:03:21,412 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:03:21,413 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:03:23,637 INFO    : [INFO] End of valid | time:  2.22s | valid loss 48.3955 | 
2023-05-10 12:03:23,637 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 12:03:23,637 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:03:23,637 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:03:35,689 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:03:47,733 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:03:59,599 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:04:11,854 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:04:23,943 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:04:35,905 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:04:47,777 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:04:59,664 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:05:11,519 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:05:23,548 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:05:35,364 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:05:47,220 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:05:59,325 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:06:11,225 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:06:23,080 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:06:35,054 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:06:47,056 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:06:58,938 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:07:10,881 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:07:22,846 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:07:34,670 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:07:46,425 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:07:58,392 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:08:10,608 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:08:22,640 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:08:34,472 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:08:46,593 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:08:58,411 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:09:10,471 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:09:22,425 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:09:34,277 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:09:46,283 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:09:58,165 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:10:10,003 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:10:21,903 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:10:33,590 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:10:45,398 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:10:57,256 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:11:09,529 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:11:21,480 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:11:33,469 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:11:45,527 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:11:57,460 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:12:09,335 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:12:21,273 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:12:33,036 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:12:44,914 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:12:56,884 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:08,763 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:21,132 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:21,132 INFO    : [INFO] The learning rate now is 0.000028
2023-05-10 12:13:21,132 INFO    :    | end of epoch  17 | time: 597.49s | epoch train loss 0.3736 | 
2023-05-10 12:13:21,132 INFO    : [INFO] Found new best model with 0.374 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:13:21,275 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:13:21,275 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:13:23,306 INFO    : [INFO] End of valid | time:  2.03s | valid loss 48.6219 | 
2023-05-10 12:13:23,306 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 12:13:23,306 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:13:23,306 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:13:35,341 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:13:47,134 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:13:59,087 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:14:11,067 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:14:22,829 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 12:14:34,805 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:14:46,816 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:14:58,917 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:15:10,713 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:15:22,769 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:15:34,612 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:15:46,520 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:15:58,397 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:16:10,233 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:16:22,159 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:16:33,863 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 12:16:45,727 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:16:57,680 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0001 | 
2023-05-10 12:17:09,561 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 12:17:21,633 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:17:33,892 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:17:46,022 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:17:58,012 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 12:18:10,187 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:18:22,516 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:18:34,468 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:18:46,433 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:18:58,296 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:19:10,269 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:19:22,680 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:19:34,955 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:19:46,944 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:19:58,665 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:20:10,684 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:20:22,740 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:20:34,721 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:20:46,787 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:20:58,791 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:21:10,741 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:21:22,686 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:21:34,439 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:21:46,285 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:21:58,472 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 12:22:10,681 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:22:22,497 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:22:34,376 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:22:46,201 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:22:58,441 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:23:10,643 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:23:22,355 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:23:22,355 INFO    : [INFO] The learning rate now is 0.000026
2023-05-10 12:23:22,356 INFO    :    | end of epoch  18 | time: 599.05s | epoch train loss 0.3532 | 
2023-05-10 12:23:22,356 INFO    : [INFO] Found new best model with 0.353 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:23:22,515 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:23:22,515 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:23:24,605 INFO    : [INFO] End of valid | time:  2.09s | valid loss 48.7289 | 
2023-05-10 12:23:24,606 INFO    : Rouge1:
	p:0.373832, r:0.290909, f:0.327198
Rouge2:
	p:0.115385, r:0.086331, f:0.098765
Rougel:
	p:0.341121, r:0.265455, f:0.298569

2023-05-10 12:23:24,606 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:23:24,606 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:23:36,398 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:23:48,659 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:24:00,462 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 12:24:12,487 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:24:24,382 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:24:36,645 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:24:48,454 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:25:00,580 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:25:12,461 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:25:24,495 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:25:36,485 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:25:48,229 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 12:25:59,979 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:26:12,224 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0001 | 
2023-05-10 12:26:24,175 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:26:36,108 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:26:47,938 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 12:26:59,825 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:27:11,987 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:27:23,767 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:27:35,468 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:27:47,409 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:27:59,406 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:28:11,293 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:28:22,924 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:28:34,658 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:28:46,257 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:28:58,009 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 12:29:10,339 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:29:22,737 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:29:35,081 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:29:47,352 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:29:59,718 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:30:11,730 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:30:23,652 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:30:35,526 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:30:47,384 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:30:59,222 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:31:11,173 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:31:22,966 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:31:34,764 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:31:46,658 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:31:58,711 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:32:10,646 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:32:22,485 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:32:34,491 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:32:46,727 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:32:58,843 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:33:10,909 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:33:22,937 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:33:22,937 INFO    : [INFO] The learning rate now is 0.000025
2023-05-10 12:33:22,937 INFO    :    | end of epoch  19 | time: 598.33s | epoch train loss 0.3352 | 
2023-05-10 12:33:22,937 INFO    : [INFO] Found new best model with 0.335 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:33:23,084 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:33:23,084 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:33:25,112 INFO    : [INFO] End of valid | time:  2.03s | valid loss 48.8899 | 
2023-05-10 12:33:25,112 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.325359, r:0.247273, f:0.280992

2023-05-10 12:33:25,113 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:33:25,113 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:33:37,210 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:33:49,479 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:34:01,362 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:34:13,335 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:34:25,444 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:34:37,670 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:34:50,120 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:35:02,337 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:35:14,174 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:35:26,078 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:35:38,052 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:35:49,585 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:36:01,441 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:36:13,198 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:36:25,033 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:36:36,977 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:36:48,812 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:37:00,760 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:37:13,140 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:37:25,280 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:37:37,243 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:37:49,466 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:38:01,624 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:38:13,670 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:38:25,731 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:38:37,849 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:38:50,070 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0001 | 
2023-05-10 12:39:02,302 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:39:14,430 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:39:26,654 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:39:38,689 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:39:50,693 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:40:02,717 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:40:14,563 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:40:26,514 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 12:40:38,210 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:40:50,175 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:41:02,159 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 12:41:13,838 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:41:25,931 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:41:37,817 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:41:50,038 INFO    :        | end of iter   0 | time:  1.31s | train loss 0.0001 | 
2023-05-10 12:42:02,317 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 12:42:14,729 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:42:26,812 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:42:39,282 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:42:51,689 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:43:03,909 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:43:16,226 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:43:28,348 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:43:28,348 INFO    : [INFO] The learning rate now is 0.000024
2023-05-10 12:43:28,348 INFO    :    | end of epoch  20 | time: 603.24s | epoch train loss 0.3205 | 
2023-05-10 12:43:28,349 INFO    : [INFO] Found new best model with 0.320 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:43:28,467 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:43:28,467 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:43:30,639 INFO    : [INFO] End of valid | time:  2.17s | valid loss 49.0136 | 
2023-05-10 12:43:30,639 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.325359, r:0.247273, f:0.280992

2023-05-10 12:43:30,639 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:43:30,639 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:43:42,483 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:43:54,318 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:06,303 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:18,167 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:44:30,088 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:41,963 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:44:53,754 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:05,721 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:18,047 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:30,452 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:45:42,841 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:45:55,221 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:46:07,499 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:46:19,572 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 12:46:31,704 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:46:43,996 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:46:55,944 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 12:47:07,994 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:47:20,008 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 12:47:32,283 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:47:44,339 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:47:56,585 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:48:08,808 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:48:21,152 INFO    :        | end of iter   0 | time:  1.31s | train loss 0.0001 | 
2023-05-10 12:48:33,533 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:48:45,670 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:48:57,910 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:49:10,171 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:49:22,172 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:49:34,539 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:49:46,897 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:49:58,667 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:50:10,483 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:50:22,369 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:50:34,210 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 12:50:45,908 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:50:57,593 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:51:09,380 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:51:21,199 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:51:33,219 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:51:45,410 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:51:57,691 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:52:09,511 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:52:21,485 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:52:33,473 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:52:45,242 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:52:57,370 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:53:09,677 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:53:21,748 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:53:33,401 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:53:33,401 INFO    : [INFO] The learning rate now is 0.000023
2023-05-10 12:53:33,401 INFO    :    | end of epoch  21 | time: 602.76s | epoch train loss 0.3055 | 
2023-05-10 12:53:33,401 INFO    : [INFO] Found new best model with 0.306 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 12:53:33,530 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 12:53:33,531 INFO    : [INFO] Starting eval for this model ...
2023-05-10 12:53:35,719 INFO    : [INFO] End of valid | time:  2.19s | valid loss 49.0920 | 
2023-05-10 12:53:35,719 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 12:53:35,719 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 12:53:35,720 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 12:53:47,814 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:53:59,641 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:54:11,530 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:54:23,666 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 12:54:35,745 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 12:54:47,850 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 12:54:59,983 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:55:11,884 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:55:24,290 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 12:55:36,452 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 12:55:48,477 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 12:56:00,590 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:56:12,784 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:56:24,831 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:56:37,071 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 12:56:48,965 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 12:57:01,374 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 12:57:13,757 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0001 | 
2023-05-10 12:57:26,097 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0001 | 
2023-05-10 12:57:38,474 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:57:50,849 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:58:02,999 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 12:58:14,823 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:58:27,022 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:58:38,962 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:58:51,069 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 12:59:02,866 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 12:59:14,545 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 12:59:26,753 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:59:38,960 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 12:59:51,209 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:00:03,408 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:00:15,640 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:00:27,853 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:00:40,007 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:00:52,168 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:01:04,344 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:01:16,480 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:01:28,513 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:01:40,534 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:01:52,471 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:04,306 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:02:16,583 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:28,502 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:40,351 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:02:52,339 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:03:04,288 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:03:16,507 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:03:28,719 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:03:40,865 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:03:40,866 INFO    : [INFO] The learning rate now is 0.000022
2023-05-10 13:03:40,866 INFO    :    | end of epoch  22 | time: 605.15s | epoch train loss 0.2935 | 
2023-05-10 13:03:40,866 INFO    : [INFO] Found new best model with 0.293 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:03:41,005 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:03:41,005 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:03:43,047 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.1577 | 
2023-05-10 13:03:43,048 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.325359, r:0.247273, f:0.280992

2023-05-10 13:03:43,048 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:03:43,048 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:03:55,304 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:04:07,144 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:04:18,956 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:04:30,929 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:04:42,762 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:04:54,590 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:05:06,331 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:05:18,384 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:05:30,405 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 13:05:42,514 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:05:54,583 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:06:06,435 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:06:18,258 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 13:06:30,119 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0001 | 
2023-05-10 13:06:42,030 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:06:53,946 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 13:07:05,825 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 13:07:17,599 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:07:29,697 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 13:07:42,157 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0001 | 
2023-05-10 13:07:54,369 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:08:06,344 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:08:18,360 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:08:30,491 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:08:42,695 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:08:54,714 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:09:06,549 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:09:18,854 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:09:30,871 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:09:42,689 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:09:54,790 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:10:06,825 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:10:18,766 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:10:30,654 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:10:42,540 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:10:54,343 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:11:06,263 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:11:18,635 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 13:11:30,974 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:11:43,277 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:11:55,461 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:12:07,625 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:12:19,813 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:12:31,950 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:12:43,791 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:12:55,584 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:13:07,479 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0001 | 
2023-05-10 13:13:19,163 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:13:31,133 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:13:43,176 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:13:43,176 INFO    : [INFO] The learning rate now is 0.000021
2023-05-10 13:13:43,176 INFO    :    | end of epoch  23 | time: 600.13s | epoch train loss 0.2813 | 
2023-05-10 13:13:43,176 INFO    : [INFO] Found new best model with 0.281 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:13:43,364 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:13:43,364 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:13:45,416 INFO    : [INFO] End of valid | time:  2.05s | valid loss 49.2349 | 
2023-05-10 13:13:45,416 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 13:13:45,416 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:13:45,416 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:13:57,471 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:14:09,526 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0001 | 
2023-05-10 13:14:21,780 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 13:14:34,125 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:14:46,117 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 13:14:57,997 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0001 | 
2023-05-10 13:15:09,676 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:15:21,670 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0001 | 
2023-05-10 13:15:33,342 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:15:45,323 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:15:57,289 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:16:09,253 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:16:21,121 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:16:32,955 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:16:45,022 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:16:57,088 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:17:08,880 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:17:20,861 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:17:32,636 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 13:17:44,965 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:17:57,077 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:18:09,351 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:18:21,778 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:18:33,693 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:18:45,449 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:18:57,340 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:19:09,252 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:19:21,163 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:19:33,005 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:19:44,883 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:19:56,831 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:20:08,776 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:20:20,720 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:20:32,735 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0001 | 
2023-05-10 13:20:44,404 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:20:56,743 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:21:08,997 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:21:21,256 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:21:33,465 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:21:45,663 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:21:57,928 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:22:09,876 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:22:21,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:22:33,604 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:22:45,450 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:22:57,585 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:23:09,972 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:23:22,105 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:23:34,370 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:23:46,565 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:23:46,565 INFO    : [INFO] The learning rate now is 0.000020
2023-05-10 13:23:46,565 INFO    :    | end of epoch  24 | time: 601.15s | epoch train loss 0.2703 | 
2023-05-10 13:23:46,565 INFO    : [INFO] Found new best model with 0.270 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:23:46,688 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:23:46,688 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:23:48,706 INFO    : [INFO] End of valid | time:  2.02s | valid loss 49.2948 | 
2023-05-10 13:23:48,706 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 13:23:48,706 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:23:48,706 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:24:00,647 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:24:12,572 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:24:25,019 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:24:37,370 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:24:49,607 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:25:01,835 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0001 | 
2023-05-10 13:25:13,861 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:25:25,889 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:25:37,750 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:25:49,644 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0001 | 
2023-05-10 13:26:01,645 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 13:26:13,811 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0001 | 
2023-05-10 13:26:25,385 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:26:37,580 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:26:49,798 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:27:02,034 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:27:14,291 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:27:26,271 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:27:38,672 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:27:51,156 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:28:03,577 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:28:15,750 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:28:27,570 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 13:28:40,011 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:28:52,325 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:29:04,714 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:29:16,508 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0001 | 
2023-05-10 13:29:28,476 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:29:40,373 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:29:51,971 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0001 | 
2023-05-10 13:30:03,560 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:30:15,511 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:30:27,445 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:30:39,513 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:30:51,760 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:31:04,140 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:31:16,297 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:31:28,035 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 13:31:39,874 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:31:51,855 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:32:04,009 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:32:16,122 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:32:28,457 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:32:40,191 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:32:52,234 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:33:04,586 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:33:17,001 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:33:29,381 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:33:41,682 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0001 | 
2023-05-10 13:33:53,907 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:33:53,908 INFO    : [INFO] The learning rate now is 0.000019
2023-05-10 13:33:53,908 INFO    :    | end of epoch  25 | time: 605.20s | epoch train loss 0.2606 | 
2023-05-10 13:33:53,908 INFO    : [INFO] Found new best model with 0.261 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:33:54,047 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:33:54,047 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:33:56,086 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.3306 | 
2023-05-10 13:33:56,086 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 13:33:56,086 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:33:56,086 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:34:08,425 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:34:20,448 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:34:32,409 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:34:44,477 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:34:56,359 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:35:08,201 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:35:20,080 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:35:32,064 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:35:43,997 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:35:56,039 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:36:08,389 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:36:20,483 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:36:32,548 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:36:44,434 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:36:56,163 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:37:07,977 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0001 | 
2023-05-10 13:37:20,135 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0001 | 
2023-05-10 13:37:32,329 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0001 | 
2023-05-10 13:37:44,608 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:37:56,769 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:38:08,663 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:38:20,412 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0001 | 
2023-05-10 13:38:32,529 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:38:44,797 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:38:56,882 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:39:09,183 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:39:21,479 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0001 | 
2023-05-10 13:39:34,069 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0001 | 
2023-05-10 13:39:46,559 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0001 | 
2023-05-10 13:39:58,592 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:40:10,787 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 13:40:22,700 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 13:40:35,064 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:40:47,478 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0001 | 
2023-05-10 13:40:59,741 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0001 | 
2023-05-10 13:41:11,578 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:41:23,324 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:41:35,441 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:41:47,487 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0001 | 
2023-05-10 13:41:59,431 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:42:11,614 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0001 | 
2023-05-10 13:42:24,075 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:42:36,373 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:42:48,566 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:43:00,738 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:43:12,563 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0001 | 
2023-05-10 13:43:24,346 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:43:36,342 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:43:48,214 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:44:00,389 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:44:00,390 INFO    : [INFO] The learning rate now is 0.000019
2023-05-10 13:44:00,390 INFO    :    | end of epoch  26 | time: 604.30s | epoch train loss 0.2518 | 
2023-05-10 13:44:00,390 INFO    : [INFO] Found new best model with 0.252 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:44:00,526 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:44:00,526 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:44:02,553 INFO    : [INFO] End of valid | time:  2.03s | valid loss 49.3225 | 
2023-05-10 13:44:02,553 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 13:44:02,553 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:44:02,553 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:44:14,584 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:44:26,614 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 13:44:38,378 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:44:50,298 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:45:02,583 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:45:14,923 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:45:27,008 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:45:38,866 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:45:51,121 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:46:03,180 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:46:15,306 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 13:46:27,530 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:46:39,928 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:46:51,906 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:47:03,877 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:47:15,728 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:47:27,679 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:47:39,861 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:47:51,727 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:48:03,556 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:48:15,595 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:48:27,652 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:48:39,573 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:48:51,461 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:03,480 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:49:15,300 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:27,238 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:39,083 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:49:51,353 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 13:50:03,736 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:50:16,185 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 13:50:28,219 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0000 | 
2023-05-10 13:50:39,934 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 13:50:51,777 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:51:03,478 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:51:15,441 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:51:27,396 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:51:39,691 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:51:52,064 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:52:04,435 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:52:16,784 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:52:29,174 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 13:52:41,331 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:52:53,382 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:53:05,361 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:53:17,442 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:53:29,311 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:53:41,333 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:53:53,113 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:54:05,504 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:54:05,505 INFO    : [INFO] The learning rate now is 0.000018
2023-05-10 13:54:05,505 INFO    :    | end of epoch  27 | time: 602.95s | epoch train loss 0.2427 | 
2023-05-10 13:54:05,505 INFO    : [INFO] Found new best model with 0.243 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 13:54:05,625 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 13:54:05,625 INFO    : [INFO] Starting eval for this model ...
2023-05-10 13:54:07,662 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.3868 | 
2023-05-10 13:54:07,662 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 13:54:07,663 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 13:54:07,663 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 13:54:19,577 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:54:31,292 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:54:43,196 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:54:55,088 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:55:07,385 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0000 | 
2023-05-10 13:55:19,522 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:55:31,656 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:55:43,533 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:55:55,588 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:56:07,535 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:56:19,592 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:56:31,426 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:56:43,277 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 13:56:55,290 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:57:07,108 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 13:57:18,949 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:57:30,825 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:57:42,813 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:57:54,888 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 13:58:06,561 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 13:58:18,913 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 13:58:30,816 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:58:43,007 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:58:55,136 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 13:59:07,397 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:59:19,626 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 13:59:31,818 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 13:59:43,969 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 13:59:55,915 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:00:07,748 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:00:19,586 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:00:31,397 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:00:43,408 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:00:55,179 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:01:07,023 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:01:19,076 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:01:30,891 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:01:42,786 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:01:54,856 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:02:07,146 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:02:19,748 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:02:32,115 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:02:44,433 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:02:56,441 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:03:08,348 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 14:03:19,825 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:03:31,927 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 14:03:44,080 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:03:56,112 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:04:07,930 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:04:07,931 INFO    : [INFO] The learning rate now is 0.000017
2023-05-10 14:04:07,931 INFO    :    | end of epoch  28 | time: 600.27s | epoch train loss 0.2348 | 
2023-05-10 14:04:07,931 INFO    : [INFO] Found new best model with 0.235 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:04:08,084 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:04:08,084 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:04:10,388 INFO    : [INFO] End of valid | time:  2.30s | valid loss 49.3037 | 
2023-05-10 14:04:10,388 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:04:10,388 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:04:10,389 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:04:22,453 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:04:34,431 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:04:46,197 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:04:58,214 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:05:10,182 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:05:22,135 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 14:05:34,247 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:05:46,490 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:05:58,810 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:06:11,135 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:06:23,058 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:06:34,760 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:06:46,773 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:06:58,859 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:07:10,860 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:07:22,707 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:07:35,023 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:07:47,327 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:07:59,399 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:08:11,460 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:08:23,541 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:08:35,513 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:08:47,374 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:08:59,127 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:09:11,145 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:09:23,032 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:09:35,272 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:09:47,455 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:09:59,637 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:10:11,891 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:10:24,054 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 14:10:36,244 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 14:10:48,118 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:11:00,327 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:11:12,213 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:11:23,890 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:11:35,743 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:11:47,673 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:11:59,661 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:11,637 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:23,918 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:12:35,924 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:47,698 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:12:59,594 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:13:11,584 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:13:23,538 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:13:35,507 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:13:47,394 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:13:59,319 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:14:11,224 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:14:11,224 INFO    : [INFO] The learning rate now is 0.000017
2023-05-10 14:14:11,224 INFO    :    | end of epoch  29 | time: 600.84s | epoch train loss 0.2274 | 
2023-05-10 14:14:11,224 INFO    : [INFO] Found new best model with 0.227 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:14:11,350 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:14:11,350 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:14:13,393 INFO    : [INFO] End of valid | time:  2.04s | valid loss 49.2919 | 
2023-05-10 14:14:13,393 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:14:13,393 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:14:13,393 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:14:25,194 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:14:37,337 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:14:49,388 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:15:01,390 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:15:14,006 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:15:26,241 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:15:38,353 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:15:50,691 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:16:02,894 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:16:14,978 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:16:27,111 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:16:39,105 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:16:51,106 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:17:03,155 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:17:14,879 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:17:26,768 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:17:38,980 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:17:51,188 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:18:03,122 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:18:14,768 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:18:26,871 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:18:38,877 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:18:50,854 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:19:02,739 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:19:14,645 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:19:27,124 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:19:39,371 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:19:51,862 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:20:04,147 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:20:16,367 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:20:28,801 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 14:20:41,068 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:20:53,185 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:21:05,175 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:21:16,859 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:21:29,067 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:21:40,874 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 14:21:52,445 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:22:04,642 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:22:16,702 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:22:28,768 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:22:40,877 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:22:53,255 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:05,516 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:23:17,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:30,000 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:42,386 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:23:54,703 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:24:07,170 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:24:19,195 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:24:19,196 INFO    : [INFO] The learning rate now is 0.000016
2023-05-10 14:24:19,196 INFO    :    | end of epoch  30 | time: 605.80s | epoch train loss 0.2200 | 
2023-05-10 14:24:19,196 INFO    : [INFO] Found new best model with 0.220 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:24:19,327 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:24:19,327 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:24:21,327 INFO    : [INFO] End of valid | time:  2.00s | valid loss 49.1885 | 
2023-05-10 14:24:21,327 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:24:21,327 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:24:21,327 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:24:33,320 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:24:45,183 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:24:57,262 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:25:09,259 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:25:21,196 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:25:33,147 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:25:45,054 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:25:57,004 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:26:08,964 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:26:20,710 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:26:32,632 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:26:44,556 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:26:56,351 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:27:08,479 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:27:20,508 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:27:32,386 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:27:44,432 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:27:56,229 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:28:08,825 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:28:21,091 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:28:33,082 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 14:28:45,345 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:28:57,689 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:29:09,787 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:29:21,672 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:29:34,030 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:29:45,947 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:29:58,315 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:30:10,637 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:30:22,722 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:30:34,795 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:30:46,606 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 14:30:58,517 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:31:10,823 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:31:22,947 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:31:35,199 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:31:47,228 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:31:59,351 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:32:11,526 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 14:32:23,914 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:32:36,263 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:32:48,111 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:32:59,975 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:33:12,112 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:33:24,309 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:33:36,449 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:33:48,901 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:34:00,980 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:34:12,742 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:34:24,528 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 14:34:24,529 INFO    : [INFO] The learning rate now is 0.000016
2023-05-10 14:34:24,529 INFO    :    | end of epoch  31 | time: 603.20s | epoch train loss 0.2138 | 
2023-05-10 14:34:24,529 INFO    : [INFO] Found new best model with 0.214 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:34:24,668 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:34:24,668 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:34:26,679 INFO    : [INFO] End of valid | time:  2.01s | valid loss 49.2524 | 
2023-05-10 14:34:26,680 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:34:26,680 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:34:26,680 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:34:38,542 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:34:50,408 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:35:02,876 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:35:14,971 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:35:26,707 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:35:38,556 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:35:50,530 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:36:02,362 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:36:15,680 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:36:27,756 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:36:40,160 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:36:52,259 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:37:04,224 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:37:16,141 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:37:28,454 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0000 | 
2023-05-10 14:37:40,818 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:37:53,224 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:38:05,289 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:38:17,164 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:38:29,240 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:38:41,290 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:38:53,456 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 14:39:05,787 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:39:18,211 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:39:29,827 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:39:41,674 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:39:53,426 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:40:05,684 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:40:17,588 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:40:29,309 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:40:41,600 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:40:53,846 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:41:06,245 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:41:18,276 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:41:30,283 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:41:42,345 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:41:54,328 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:42:06,653 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:42:19,177 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 14:42:31,462 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:42:43,398 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:42:55,047 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:43:07,310 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 14:43:19,642 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:43:32,093 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:43:43,927 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:43:56,208 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:44:08,283 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:44:20,422 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:44:32,337 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:44:32,337 INFO    : [INFO] The learning rate now is 0.000015
2023-05-10 14:44:32,337 INFO    :    | end of epoch  32 | time: 605.66s | epoch train loss 0.2073 | 
2023-05-10 14:44:32,337 INFO    : [INFO] Found new best model with 0.207 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:44:32,495 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:44:32,496 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:44:34,500 INFO    : [INFO] End of valid | time:  2.00s | valid loss 49.0409 | 
2023-05-10 14:44:34,500 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:44:34,500 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:44:34,500 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:44:46,478 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:44:58,560 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:45:10,745 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 14:45:22,858 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:45:35,180 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:45:47,261 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 14:45:59,505 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0000 | 
2023-05-10 14:46:11,455 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:46:23,456 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:46:35,533 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:46:47,875 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:46:59,980 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:12,058 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:24,409 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:36,233 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:47:48,096 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:48:00,304 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:48:12,597 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:48:24,965 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:48:37,244 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:48:49,231 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:49:01,074 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:49:13,021 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:49:24,998 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:49:37,229 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:49:49,517 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:50:01,736 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 14:50:14,045 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:50:26,477 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:50:38,871 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:50:50,834 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:51:02,774 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:51:15,264 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:51:27,809 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:51:40,283 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 14:51:52,137 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:52:04,399 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:52:16,898 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:52:29,106 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:52:41,503 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:52:53,642 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:53:05,709 INFO    :        | end of iter   0 | time:  1.32s | train loss 0.0000 | 
2023-05-10 14:53:17,497 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 14:53:29,483 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 14:53:41,160 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 14:53:53,066 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:54:04,927 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 14:54:17,058 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:54:29,186 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:54:41,328 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 14:54:41,328 INFO    : [INFO] The learning rate now is 0.000015
2023-05-10 14:54:41,328 INFO    :    | end of epoch  33 | time: 606.83s | epoch train loss 0.2018 | 
2023-05-10 14:54:41,328 INFO    : [INFO] Found new best model with 0.202 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 14:54:41,437 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 14:54:41,437 INFO    : [INFO] Starting eval for this model ...
2023-05-10 14:54:43,492 INFO    : [INFO] End of valid | time:  2.05s | valid loss 48.8934 | 
2023-05-10 14:54:43,492 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 14:54:43,492 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 14:54:43,492 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 14:54:55,506 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:55:07,385 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:55:19,321 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:55:31,248 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 14:55:43,651 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 14:55:55,891 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 14:56:08,108 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:56:20,361 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:56:32,566 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:56:44,337 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:56:56,283 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 14:57:08,258 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:57:20,168 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:57:32,132 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 14:57:44,029 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 14:57:56,173 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 14:58:08,081 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:58:20,182 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 14:58:32,159 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:58:43,834 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:58:55,577 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:59:07,799 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 14:59:19,743 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 14:59:31,940 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 14:59:43,852 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 14:59:55,819 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:00:07,980 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:00:19,998 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:00:32,033 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:00:44,095 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:00:55,851 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:01:07,910 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:01:19,916 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:01:31,892 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:01:43,815 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:01:55,878 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:02:07,760 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:02:19,648 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:02:31,484 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:02:43,572 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 15:02:55,843 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:07,674 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:03:19,401 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:31,246 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:43,126 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:03:55,137 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:04:07,078 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:04:18,856 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:04:30,810 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:04:42,964 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:04:42,964 INFO    : [INFO] The learning rate now is 0.000014
2023-05-10 15:04:42,965 INFO    :    | end of epoch  34 | time: 599.47s | epoch train loss 0.1966 | 
2023-05-10 15:04:42,965 INFO    : [INFO] Found new best model with 0.197 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:04:43,092 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:04:43,092 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:04:45,130 INFO    : [INFO] End of valid | time:  2.04s | valid loss 48.6949 | 
2023-05-10 15:04:45,130 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:04:45,130 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:04:45,130 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:04:56,976 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:05:08,836 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:05:20,774 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:05:32,838 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:05:44,916 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:05:56,812 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:06:08,681 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:06:20,615 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:06:32,456 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:06:44,421 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:06:56,354 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:07:07,898 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:07:19,812 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:07:31,743 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:07:43,596 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:07:55,525 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:08:07,416 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:08:19,428 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:08:31,350 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:08:43,190 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:08:55,049 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:09:06,799 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:09:18,740 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:09:30,872 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:09:42,920 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:09:54,948 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:10:06,622 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:10:18,540 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0000 | 
2023-05-10 15:10:30,539 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:10:42,608 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:10:54,477 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:11:06,423 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:11:18,274 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:11:30,383 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 15:11:42,118 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:11:53,959 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:12:05,800 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:12:17,915 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:12:30,110 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:12:41,958 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:12:53,806 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:13:05,756 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:13:17,881 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:13:29,818 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 15:13:41,819 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:13:53,704 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:14:05,582 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:14:17,425 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:14:29,566 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:14:41,677 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:14:41,677 INFO    : [INFO] The learning rate now is 0.000014
2023-05-10 15:14:41,677 INFO    :    | end of epoch  35 | time: 596.55s | epoch train loss 0.1914 | 
2023-05-10 15:14:41,677 INFO    : [INFO] Found new best model with 0.191 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:14:41,817 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:14:41,817 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:14:43,887 INFO    : [INFO] End of valid | time:  2.07s | valid loss 48.6150 | 
2023-05-10 15:14:43,888 INFO    : Rouge1:
	p:0.373832, r:0.290909, f:0.327198
Rouge2:
	p:0.115385, r:0.086331, f:0.098765
Rougel:
	p:0.341121, r:0.265455, f:0.298569

2023-05-10 15:14:43,888 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:14:43,888 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:14:56,005 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:15:07,956 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:15:19,842 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:15:31,660 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:15:43,671 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:15:55,922 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:16:07,698 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:16:19,669 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:16:31,628 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:16:43,648 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:16:55,880 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:17:07,717 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:17:19,552 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:17:31,268 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:17:43,213 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:17:55,501 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:18:07,417 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:18:19,472 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:18:31,251 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:18:43,313 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:18:55,333 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:19:07,447 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 15:19:19,332 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:19:31,222 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:19:43,484 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:19:55,335 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:20:07,334 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:20:19,343 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0000 | 
2023-05-10 15:20:31,450 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 15:20:43,431 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:20:55,613 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0000 | 
2023-05-10 15:21:07,613 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:21:19,107 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:21:31,111 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:21:43,000 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:21:55,047 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:22:06,947 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:22:19,065 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:22:31,094 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:22:43,090 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:22:54,903 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:06,841 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:18,899 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:23:30,881 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:42,876 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:23:54,761 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:24:06,806 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 15:24:18,703 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:24:31,013 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:24:42,886 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:24:42,887 INFO    : [INFO] The learning rate now is 0.000014
2023-05-10 15:24:42,887 INFO    :    | end of epoch  36 | time: 599.00s | epoch train loss 0.1862 | 
2023-05-10 15:24:42,887 INFO    : [INFO] Found new best model with 0.186 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:24:43,074 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:24:43,074 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:24:45,097 INFO    : [INFO] End of valid | time:  2.02s | valid loss 48.5618 | 
2023-05-10 15:24:45,097 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:24:45,097 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:24:45,097 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:24:56,958 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:25:08,993 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:25:20,870 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:25:32,645 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:25:44,750 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:25:56,685 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:26:08,403 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:26:20,371 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:26:32,256 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:26:44,592 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:26:56,721 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:27:09,014 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:27:21,327 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:27:33,234 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:27:45,195 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:27:57,108 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:28:09,022 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:28:20,901 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:28:32,983 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 15:28:44,982 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:28:56,640 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:29:08,659 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:29:20,683 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:29:32,409 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:29:44,340 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:29:56,296 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:30:08,254 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:30:20,402 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:30:32,751 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:30:45,075 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:30:57,150 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:31:09,088 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:31:21,285 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 15:31:33,597 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:31:45,926 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:31:58,131 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:32:10,306 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:32:22,466 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:32:34,759 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:32:47,012 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 15:32:59,242 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:33:11,589 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:33:23,924 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:33:36,027 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:33:48,142 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:34:00,517 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 15:34:12,742 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:34:24,804 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:34:37,196 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:34:49,523 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:34:49,523 INFO    : [INFO] The learning rate now is 0.000013
2023-05-10 15:34:49,523 INFO    :    | end of epoch  37 | time: 604.43s | epoch train loss 0.1816 | 
2023-05-10 15:34:49,523 INFO    : [INFO] Found new best model with 0.182 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:34:49,658 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:34:49,658 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:34:51,862 INFO    : [INFO] End of valid | time:  2.20s | valid loss 48.3523 | 
2023-05-10 15:34:51,862 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:34:51,862 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:34:51,862 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:35:04,085 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:35:16,010 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:35:28,170 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:35:40,509 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 15:35:52,992 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:36:05,197 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:36:17,408 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:36:29,804 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:36:42,095 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:36:54,192 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:37:06,138 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:37:17,898 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:37:29,821 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:37:42,154 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:37:54,414 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:38:06,616 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:38:18,589 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:38:30,604 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:38:42,582 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:38:54,453 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:39:06,530 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:39:18,396 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 15:39:30,146 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:39:42,206 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:39:54,139 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:40:06,172 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:40:18,248 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:40:30,280 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:40:42,079 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:40:53,931 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:41:05,934 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 15:41:18,237 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:41:30,312 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:41:42,295 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:41:54,657 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:42:06,872 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:42:18,997 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:42:31,147 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 15:42:43,181 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:42:54,946 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 15:43:07,508 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:43:19,567 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:43:31,698 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:43:43,818 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:43:55,611 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 15:44:07,343 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:44:19,906 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:44:31,981 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:44:44,481 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:44:56,646 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:44:56,646 INFO    : [INFO] The learning rate now is 0.000013
2023-05-10 15:44:56,646 INFO    :    | end of epoch  38 | time: 604.78s | epoch train loss 0.1770 | 
2023-05-10 15:44:56,646 INFO    : [INFO] Found new best model with 0.177 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:44:56,791 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:44:56,791 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:44:58,996 INFO    : [INFO] End of valid | time:  2.20s | valid loss 48.3640 | 
2023-05-10 15:44:58,996 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 15:44:58,996 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:44:58,996 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:45:11,245 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:45:23,451 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 15:45:35,659 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:45:47,823 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:46:00,178 INFO    :        | end of iter   0 | time:  1.32s | train loss 0.0000 | 
2023-05-10 15:46:12,339 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:46:24,451 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 15:46:36,852 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 15:46:49,160 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:47:01,549 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:47:13,767 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 15:47:25,676 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:47:37,271 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:47:49,243 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 15:48:01,138 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:48:13,268 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:48:25,270 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 15:48:36,953 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:48:48,944 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 15:49:00,836 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:49:12,732 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:49:24,663 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:49:36,486 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:49:48,756 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:50:00,628 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 15:50:12,460 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:50:24,437 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:50:36,406 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:50:48,322 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:51:00,225 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:51:12,399 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:51:24,177 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:51:35,944 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 15:51:47,787 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 15:51:59,775 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:52:11,831 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:52:23,744 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:52:35,909 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:52:48,159 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:53:00,155 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:53:11,903 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:53:23,606 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:53:35,552 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:53:47,453 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:53:59,382 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 15:54:11,360 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:54:23,381 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:54:35,359 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:54:47,450 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:54:59,496 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:54:59,496 INFO    : [INFO] The learning rate now is 0.000013
2023-05-10 15:54:59,496 INFO    :    | end of epoch  39 | time: 600.50s | epoch train loss 0.1729 | 
2023-05-10 15:54:59,496 INFO    : [INFO] Found new best model with 0.173 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 15:54:59,617 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 15:54:59,617 INFO    : [INFO] Starting eval for this model ...
2023-05-10 15:55:01,609 INFO    : [INFO] End of valid | time:  1.99s | valid loss 47.9388 | 
2023-05-10 15:55:01,609 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 15:55:01,609 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 15:55:01,609 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 15:55:13,431 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:55:25,256 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:55:37,093 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:55:49,063 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:56:01,181 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:56:13,440 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:56:25,535 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:56:37,539 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 15:56:49,378 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:57:01,493 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:57:13,742 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:57:26,161 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:57:38,383 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:57:50,452 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:58:02,588 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:58:14,971 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:58:27,426 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:58:39,663 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 15:58:51,946 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:59:04,284 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 15:59:16,031 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:59:28,095 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 15:59:39,971 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 15:59:51,980 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 16:00:04,278 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:00:16,860 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:00:28,770 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 16:00:41,051 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 16:00:53,052 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:01:05,052 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 16:01:17,239 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 16:01:29,239 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 16:01:41,633 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 16:01:57,650 INFO    :        | end of iter   0 | time:  5.09s | train loss 0.0000 | 
2023-05-10 16:02:13,976 INFO    :        | end of iter   0 | time:  5.02s | train loss 0.0000 | 
2023-05-10 16:02:30,996 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:02:48,136 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 16:03:05,149 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:03:21,660 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:03:38,479 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:03:55,649 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:04:12,321 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 16:04:29,567 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 16:04:46,589 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:05:03,080 INFO    :        | end of iter   0 | time:  5.36s | train loss 0.0000 | 
2023-05-10 16:05:19,703 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:05:36,271 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 16:05:52,480 INFO    :        | end of iter   0 | time:  5.22s | train loss 0.0000 | 
2023-05-10 16:06:09,596 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:06:26,008 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:06:26,009 INFO    : [INFO] The learning rate now is 0.000012
2023-05-10 16:06:26,009 INFO    :    | end of epoch  40 | time: 684.40s | epoch train loss 0.1687 | 
2023-05-10 16:06:26,009 INFO    : [INFO] Found new best model with 0.169 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:06:26,127 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:06:26,128 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:06:30,653 INFO    : [INFO] End of valid | time:  4.52s | valid loss 47.7662 | 
2023-05-10 16:06:30,653 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 16:06:30,653 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:06:30,653 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:06:47,318 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:07:03,251 INFO    :        | end of iter   0 | time:  4.87s | train loss 0.0000 | 
2023-05-10 16:07:20,337 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:07:37,261 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 16:07:54,015 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:08:10,869 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:08:27,482 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 16:08:44,051 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 16:09:01,245 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 16:09:17,867 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:09:34,514 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 16:09:51,711 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:10:08,648 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:10:25,591 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:10:42,411 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 16:10:58,865 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 16:11:15,552 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:11:32,095 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 16:11:48,372 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:12:05,109 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:12:21,742 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:12:38,252 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:12:55,150 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:13:11,685 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:13:28,555 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 16:13:45,049 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:14:01,943 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:14:18,711 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:14:34,926 INFO    :        | end of iter   0 | time:  5.23s | train loss 0.0000 | 
2023-05-10 16:14:51,395 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:15:08,259 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:15:25,241 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 16:15:41,973 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:15:58,663 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 16:16:15,638 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 16:16:32,278 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:16:49,253 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:17:06,495 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 16:17:23,302 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 16:17:40,405 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:17:57,753 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 16:18:15,013 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:18:32,524 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 16:18:49,511 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:19:06,821 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:19:23,651 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:19:40,835 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:19:57,901 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:20:14,736 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 16:20:31,963 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 16:20:31,963 INFO    : [INFO] The learning rate now is 0.000012
2023-05-10 16:20:31,963 INFO    :    | end of epoch  41 | time: 841.31s | epoch train loss 0.1646 | 
2023-05-10 16:20:31,963 INFO    : [INFO] Found new best model with 0.165 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:20:32,356 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:20:32,357 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:20:37,224 INFO    : [INFO] End of valid | time:  4.87s | valid loss 47.5876 | 
2023-05-10 16:20:37,224 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 16:20:37,224 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:20:37,224 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:20:54,394 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 16:21:11,467 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 16:21:28,672 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 16:21:45,702 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 16:22:02,246 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:22:18,760 INFO    :        | end of iter   0 | time:  5.29s | train loss 0.0000 | 
2023-05-10 16:22:35,891 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 16:22:52,764 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:23:09,453 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 16:23:26,209 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 16:23:42,996 INFO    :        | end of iter   0 | time:  5.28s | train loss 0.0000 | 
2023-05-10 16:24:00,136 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:24:17,287 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:24:33,690 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 16:24:50,943 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 16:25:07,599 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:25:24,151 INFO    :        | end of iter   0 | time:  5.22s | train loss 0.0000 | 
2023-05-10 16:25:40,920 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:25:57,836 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 16:26:14,300 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 16:26:31,464 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 16:26:48,316 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 16:27:05,123 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 16:27:22,602 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:27:39,748 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:27:56,764 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 16:28:13,519 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:28:30,254 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:28:47,545 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 16:29:04,377 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:29:21,272 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 16:29:38,089 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:29:54,796 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:30:11,275 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 16:30:28,531 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 16:30:45,392 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:31:02,199 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 16:31:18,934 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:31:36,026 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:31:52,714 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:32:09,395 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 16:32:26,111 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:32:42,693 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 16:32:59,587 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 16:33:16,098 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:33:32,938 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 16:33:50,596 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 16:34:07,790 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 16:34:24,468 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 16:34:41,348 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:34:41,349 INFO    : [INFO] The learning rate now is 0.000012
2023-05-10 16:34:41,349 INFO    :    | end of epoch  42 | time: 844.12s | epoch train loss 0.1613 | 
2023-05-10 16:34:41,349 INFO    : [INFO] Found new best model with 0.161 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:34:41,516 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:34:41,517 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:34:45,718 INFO    : [INFO] End of valid | time:  4.20s | valid loss 47.5389 | 
2023-05-10 16:34:45,718 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.330144, r:0.250909, f:0.285124

2023-05-10 16:34:45,718 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:34:45,719 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:35:02,797 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:35:19,735 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:35:36,168 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:35:52,849 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:36:09,919 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:36:26,679 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:36:43,687 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:36:59,967 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 16:37:17,668 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 16:37:34,719 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 16:37:52,182 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 16:38:08,950 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:38:25,299 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 16:38:41,889 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:38:58,418 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:39:15,047 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:39:31,521 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:39:48,546 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:40:05,397 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:40:22,226 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 16:40:39,052 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:40:55,871 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:41:12,316 INFO    :        | end of iter   0 | time:  5.39s | train loss 0.0000 | 
2023-05-10 16:41:29,138 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 16:41:45,938 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:42:02,623 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:42:19,366 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:42:35,924 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 16:42:53,047 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 16:43:10,020 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:43:27,074 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:43:44,444 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 16:44:01,623 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 16:44:18,417 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 16:44:35,269 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:44:51,419 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 16:45:05,172 INFO    :        | end of iter   0 | time:  2.81s | train loss 0.0000 | 
2023-05-10 16:45:22,152 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 16:45:39,106 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 16:45:56,377 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:46:13,178 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 16:46:29,804 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 16:46:46,194 INFO    :        | end of iter   0 | time:  5.14s | train loss 0.0000 | 
2023-05-10 16:47:02,815 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:47:19,411 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 16:47:36,535 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 16:47:53,954 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 16:48:12,305 INFO    :        | end of iter   0 | time:  6.64s | train loss 0.0000 | 
2023-05-10 16:48:30,404 INFO    :        | end of iter   0 | time:  6.78s | train loss 0.0000 | 
2023-05-10 16:48:47,797 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:48:47,797 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 16:48:47,798 INFO    :    | end of epoch  43 | time: 842.08s | epoch train loss 0.1573 | 
2023-05-10 16:48:47,798 INFO    : [INFO] Found new best model with 0.157 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 16:48:47,950 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 16:48:47,950 INFO    : [INFO] Starting eval for this model ...
2023-05-10 16:48:52,693 INFO    : [INFO] End of valid | time:  4.74s | valid loss 47.2103 | 
2023-05-10 16:48:52,694 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 16:48:52,694 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 16:48:52,694 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 16:49:10,125 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 16:49:27,285 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:49:44,347 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:50:01,503 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:50:18,427 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:50:35,301 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 16:50:52,394 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 16:51:09,712 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 16:51:26,801 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:51:44,134 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:52:01,121 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 16:52:18,354 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:52:34,785 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 16:52:51,434 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:53:08,211 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:53:25,028 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:53:41,441 INFO    :        | end of iter   0 | time:  5.42s | train loss 0.0000 | 
2023-05-10 16:53:57,829 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:54:14,431 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:54:31,140 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 16:54:47,883 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 16:55:04,596 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:55:21,163 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 16:55:37,967 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 16:55:54,768 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 16:56:10,803 INFO    :        | end of iter   0 | time:  5.06s | train loss 0.0000 | 
2023-05-10 16:56:27,584 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 16:56:44,667 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 16:57:01,819 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 16:57:18,644 INFO    :        | end of iter   0 | time:  5.36s | train loss 0.0000 | 
2023-05-10 16:57:35,929 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 16:57:52,856 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 16:58:09,826 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 16:58:27,173 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 16:58:44,675 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-10 16:59:01,753 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 16:59:18,261 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 16:59:35,019 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 16:59:51,507 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 17:00:08,473 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:00:25,548 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:00:42,291 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 17:00:59,628 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:01:16,932 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 17:01:34,131 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:01:51,144 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 17:02:07,767 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:02:24,965 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:02:42,187 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:02:58,988 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:02:58,989 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 17:02:58,989 INFO    :    | end of epoch  44 | time: 846.30s | epoch train loss 0.1540 | 
2023-05-10 17:02:58,989 INFO    : [INFO] Found new best model with 0.154 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:02:59,113 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:02:59,113 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:03:03,495 INFO    : [INFO] End of valid | time:  4.38s | valid loss 47.0493 | 
2023-05-10 17:03:03,495 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.339713, r:0.258182, f:0.293388

2023-05-10 17:03:03,495 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:03:03,496 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:03:20,413 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:03:37,505 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:03:54,326 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 17:04:11,692 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:04:28,120 INFO    :        | end of iter   0 | time:  5.27s | train loss 0.0000 | 
2023-05-10 17:04:44,814 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 17:05:01,510 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:05:18,481 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:05:36,016 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-10 17:05:52,809 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 17:06:09,978 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 17:06:27,123 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:06:43,515 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:07:00,088 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:07:16,813 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:07:33,709 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:07:50,684 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 17:08:07,439 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:08:23,882 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:08:40,622 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:08:57,443 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 17:09:14,208 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:09:31,377 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:09:47,930 INFO    :        | end of iter   0 | time:  5.29s | train loss 0.0000 | 
2023-05-10 17:10:04,436 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:10:21,479 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:10:38,461 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 17:10:55,542 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:11:12,213 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:11:28,887 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:11:45,990 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:12:03,421 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 17:12:20,269 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 17:12:37,293 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:12:54,090 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:13:10,707 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:13:27,341 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:13:44,124 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:14:00,773 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 17:14:17,577 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 17:14:34,352 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 17:14:51,451 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 17:15:08,642 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 17:15:25,784 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:15:43,020 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:16:00,272 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 17:16:17,511 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:16:34,675 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:16:51,841 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:17:08,687 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 17:17:08,687 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 17:17:08,687 INFO    :    | end of epoch  45 | time: 845.19s | epoch train loss 0.1507 | 
2023-05-10 17:17:08,687 INFO    : [INFO] Found new best model with 0.151 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:17:09,046 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:17:09,046 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:17:13,373 INFO    : [INFO] End of valid | time:  4.33s | valid loss 47.0650 | 
2023-05-10 17:17:13,373 INFO    : Rouge1:
	p:0.358852, r:0.272727, f:0.309917
Rouge2:
	p:0.116505, r:0.086331, f:0.099174
Rougel:
	p:0.339713, r:0.258182, f:0.293388

2023-05-10 17:17:13,373 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:17:13,374 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:17:29,523 INFO    :        | end of iter   0 | time:  5.14s | train loss 0.0000 | 
2023-05-10 17:17:45,891 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:18:02,228 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 17:18:19,356 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 17:18:36,236 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 17:18:53,402 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:19:10,415 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 17:19:27,609 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 17:19:44,225 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:20:00,620 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:20:17,505 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 17:20:34,757 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:20:51,391 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 17:21:07,533 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 17:21:24,000 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:21:41,004 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-10 17:21:57,862 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 17:22:14,637 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:22:31,685 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 17:22:48,416 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:23:04,949 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 17:23:21,349 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 17:23:37,666 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 17:23:54,364 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 17:24:10,599 INFO    :        | end of iter   0 | time:  5.24s | train loss 0.0000 | 
2023-05-10 17:24:27,633 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:24:44,727 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:25:01,699 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:25:18,161 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:25:35,012 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:25:51,739 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:26:08,630 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 17:26:25,216 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 17:26:42,113 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:26:59,109 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:27:15,674 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:27:32,496 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 17:27:49,352 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 17:28:05,851 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:28:22,634 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 17:28:39,368 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:28:56,085 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:29:12,839 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:29:29,642 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 17:29:46,101 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:30:02,673 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:30:19,824 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:30:36,916 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 17:30:53,638 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 17:31:10,343 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:31:10,343 INFO    : [INFO] The learning rate now is 0.000011
2023-05-10 17:31:10,344 INFO    :    | end of epoch  46 | time: 836.97s | epoch train loss 0.1473 | 
2023-05-10 17:31:10,344 INFO    : [INFO] Found new best model with 0.147 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:31:10,503 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:31:10,503 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:31:15,176 INFO    : [INFO] End of valid | time:  4.67s | valid loss 47.0596 | 
2023-05-10 17:31:15,177 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.350711, r:0.269091, f:0.304527

2023-05-10 17:31:15,177 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:31:15,177 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:31:32,023 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:31:48,780 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:32:05,986 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 17:32:22,815 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 17:32:39,904 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:32:57,049 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 17:33:13,912 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 17:33:30,454 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:33:47,510 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 17:34:04,462 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 17:34:20,965 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 17:34:35,723 INFO    :        | end of iter   0 | time:  3.68s | train loss 0.0000 | 
2023-05-10 17:34:53,612 INFO    :        | end of iter   0 | time:  6.90s | train loss 0.0000 | 
2023-05-10 17:35:10,276 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 17:35:26,853 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 17:35:43,863 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:36:00,944 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 17:36:17,849 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 17:36:34,242 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:36:51,035 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 17:37:07,662 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 17:37:24,813 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 17:37:41,598 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:37:58,107 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:38:15,284 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:38:32,059 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 17:38:49,231 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 17:39:06,335 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:39:23,337 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 17:39:39,975 INFO    :        | end of iter   0 | time:  5.41s | train loss 0.0000 | 
2023-05-10 17:39:56,904 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 17:40:13,869 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:40:30,218 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 17:40:46,602 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 17:41:03,306 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:41:20,132 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:41:37,053 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:41:53,995 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 17:42:10,839 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 17:42:27,889 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 17:42:45,488 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 17:43:02,466 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:43:19,590 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:43:36,785 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 17:43:54,026 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 17:44:11,061 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:44:28,124 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:44:45,217 INFO    :        | end of iter   0 | time:  5.42s | train loss 0.0000 | 
2023-05-10 17:45:01,594 INFO    :        | end of iter   0 | time:  5.41s | train loss 0.0000 | 
2023-05-10 17:45:18,331 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 17:45:18,331 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 17:45:18,331 INFO    :    | end of epoch  47 | time: 843.15s | epoch train loss 0.1443 | 
2023-05-10 17:45:18,331 INFO    : [INFO] Found new best model with 0.144 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:45:18,456 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:45:18,457 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:45:22,945 INFO    : [INFO] End of valid | time:  4.49s | valid loss 46.9625 | 
2023-05-10 17:45:22,945 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 17:45:22,945 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:45:22,945 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:45:39,687 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:45:56,600 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:46:12,975 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:46:29,573 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:46:46,393 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 17:47:02,924 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 17:47:20,034 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 17:47:36,576 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 17:47:52,804 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 17:48:09,827 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:48:26,271 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 17:48:43,348 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 17:49:00,233 INFO    :        | end of iter   0 | time:  5.34s | train loss 0.0000 | 
2023-05-10 17:49:16,973 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:49:33,460 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 17:49:49,925 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 17:50:06,919 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:50:23,424 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 17:50:40,104 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 17:50:57,246 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 17:51:14,141 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 17:51:31,084 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 17:51:48,034 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:52:04,758 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 17:52:21,182 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 17:52:38,234 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 17:52:54,637 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 17:53:11,635 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:53:28,818 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:53:45,479 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 17:54:02,297 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:54:19,496 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 17:54:36,510 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 17:54:53,746 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 17:55:10,744 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:55:27,824 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 17:55:44,907 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 17:56:01,960 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 17:56:18,573 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 17:56:35,065 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 17:56:52,404 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 17:57:09,045 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 17:57:26,003 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 17:57:42,855 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 17:57:59,617 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 17:58:16,749 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 17:58:33,493 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 17:58:50,446 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 17:59:06,991 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 17:59:23,969 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 17:59:23,970 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 17:59:23,970 INFO    :    | end of epoch  48 | time: 841.02s | epoch train loss 0.1415 | 
2023-05-10 17:59:23,970 INFO    : [INFO] Found new best model with 0.141 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 17:59:24,144 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 17:59:24,144 INFO    : [INFO] Starting eval for this model ...
2023-05-10 17:59:28,572 INFO    : [INFO] End of valid | time:  4.43s | valid loss 46.8998 | 
2023-05-10 17:59:28,572 INFO    : Rouge1:
	p:0.373832, r:0.290909, f:0.327198
Rouge2:
	p:0.115385, r:0.086331, f:0.098765
Rougel:
	p:0.345794, r:0.269091, f:0.302658

2023-05-10 17:59:28,572 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 17:59:28,572 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 17:59:45,299 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 18:00:01,988 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 18:00:18,561 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:00:35,693 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:00:52,944 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:01:09,740 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 18:01:26,224 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 18:01:42,735 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:01:59,390 INFO    :        | end of iter   0 | time:  5.12s | train loss 0.0000 | 
2023-05-10 18:02:16,467 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:02:33,471 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:02:50,534 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 18:03:07,623 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:03:24,672 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:03:41,637 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:03:58,390 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:04:15,247 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:04:32,469 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 18:04:49,260 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:05:05,822 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:05:22,251 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:05:39,186 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:05:56,021 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:06:13,206 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-10 18:06:30,292 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:06:47,228 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 18:07:04,212 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:07:20,764 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:07:37,970 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 18:07:54,885 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 18:08:11,697 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:08:28,208 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:08:44,742 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:09:01,487 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:09:18,230 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 18:09:34,739 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 18:09:51,065 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 18:10:08,055 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:10:25,179 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:10:42,034 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:10:58,748 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 18:11:15,385 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:11:32,407 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 18:11:48,796 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:12:05,592 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:12:22,253 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:12:39,398 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:12:56,062 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:13:13,284 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 18:13:29,891 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:13:29,891 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 18:13:29,892 INFO    :    | end of epoch  49 | time: 841.32s | epoch train loss 0.1387 | 
2023-05-10 18:13:29,892 INFO    : [INFO] Found new best model with 0.139 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:13:30,045 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:13:30,045 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:13:34,462 INFO    : [INFO] End of valid | time:  4.42s | valid loss 46.7764 | 
2023-05-10 18:13:34,463 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 18:13:34,463 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:13:34,463 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:13:51,613 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:14:08,778 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:14:26,016 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 18:14:43,153 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 18:14:59,712 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:15:16,115 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 18:15:33,135 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:15:49,808 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:16:06,326 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:16:23,010 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:16:39,838 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:16:56,586 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:17:13,580 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:17:30,454 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:17:47,556 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 18:18:04,018 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:18:20,739 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:18:37,497 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:18:54,635 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:19:11,850 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:19:28,861 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:19:45,800 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 18:20:02,815 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 18:20:19,792 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 18:20:36,967 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:20:53,782 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 18:21:07,715 INFO    :        | end of iter   0 | time:  2.90s | train loss 0.0000 | 
2023-05-10 18:21:25,036 INFO    :        | end of iter   0 | time:  6.63s | train loss 0.0000 | 
2023-05-10 18:21:41,276 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 18:21:58,299 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:22:15,281 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 18:22:32,666 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:22:49,264 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:23:06,237 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 18:23:22,913 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 18:23:39,665 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:23:56,948 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:24:13,545 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 18:24:30,146 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 18:24:47,012 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:25:04,108 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 18:25:20,745 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:25:38,036 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:25:55,110 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 18:26:12,279 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:26:29,323 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:26:45,857 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 18:27:02,199 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 18:27:18,922 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:27:35,599 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:27:35,599 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 18:27:35,599 INFO    :    | end of epoch  50 | time: 841.14s | epoch train loss 0.1358 | 
2023-05-10 18:27:35,599 INFO    : [INFO] Found new best model with 0.136 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:27:35,732 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:27:35,732 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:27:40,014 INFO    : [INFO] End of valid | time:  4.28s | valid loss 46.7294 | 
2023-05-10 18:27:40,014 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 18:27:40,014 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:27:40,015 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:27:56,942 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:28:13,657 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:28:30,328 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:28:46,952 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:29:03,458 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 18:29:20,183 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 18:29:37,008 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 18:29:53,922 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 18:30:11,273 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:30:28,282 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:30:45,014 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:31:01,366 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 18:31:18,452 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:31:35,241 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 18:31:52,549 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:32:09,150 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-10 18:32:26,427 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:32:43,094 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:32:59,545 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 18:33:16,511 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:33:33,310 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 18:33:50,268 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 18:34:06,921 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:34:23,622 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:34:39,650 INFO    :        | end of iter   0 | time:  5.19s | train loss 0.0000 | 
2023-05-10 18:34:56,457 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:35:13,318 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:35:30,145 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 18:35:46,808 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:36:03,628 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:36:20,317 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 18:36:37,064 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 18:36:53,714 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:37:10,606 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 18:37:27,575 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:37:44,837 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 18:38:02,025 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:38:19,236 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:38:36,344 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:38:53,573 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:39:10,518 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:39:27,263 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:39:44,407 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 18:40:01,432 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 18:40:18,235 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:40:35,323 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 18:40:51,788 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 18:41:08,493 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:41:25,252 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:41:42,176 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:41:42,177 INFO    : [INFO] The learning rate now is 0.000010
2023-05-10 18:41:42,177 INFO    :    | end of epoch  51 | time: 842.16s | epoch train loss 0.1330 | 
2023-05-10 18:41:42,177 INFO    : [INFO] Found new best model with 0.133 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:41:42,313 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:41:42,313 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:41:46,916 INFO    : [INFO] End of valid | time:  4.60s | valid loss 46.7178 | 
2023-05-10 18:41:46,917 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.341232, r:0.261818, f:0.296296

2023-05-10 18:41:46,917 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:41:46,917 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:42:03,982 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:42:20,674 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:42:37,882 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 18:42:55,363 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 18:43:12,710 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:43:29,628 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:43:47,048 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 18:43:59,798 INFO    :        | end of iter   0 | time:  1.41s | train loss 0.0000 | 
2023-05-10 18:44:16,945 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 18:44:34,314 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 18:44:51,625 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:45:09,268 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 18:45:26,554 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 18:45:43,417 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 18:46:00,308 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:46:16,747 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 18:46:33,467 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 18:46:50,176 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 18:47:07,224 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:47:24,167 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 18:47:40,672 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 18:47:57,250 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:48:14,341 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 18:48:31,641 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:48:48,801 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 18:49:05,861 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:49:22,989 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:49:39,984 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:49:57,093 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:50:14,480 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:50:31,498 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:50:48,038 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 18:51:04,849 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 18:51:22,026 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:51:39,371 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:51:56,864 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 18:52:14,161 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:52:31,246 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 18:52:48,103 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 18:53:04,643 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:53:21,792 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 18:53:38,793 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 18:53:55,234 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:54:11,830 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 18:54:28,920 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 18:54:46,119 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:55:03,140 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 18:55:20,236 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 18:55:37,655 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 18:55:54,362 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 18:55:54,363 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 18:55:54,363 INFO    :    | end of epoch  52 | time: 847.45s | epoch train loss 0.1306 | 
2023-05-10 18:55:54,363 INFO    : [INFO] Found new best model with 0.131 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 18:55:54,522 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 18:55:54,523 INFO    : [INFO] Starting eval for this model ...
2023-05-10 18:55:59,191 INFO    : [INFO] End of valid | time:  4.67s | valid loss 46.7858 | 
2023-05-10 18:55:59,191 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.350711, r:0.269091, f:0.304527

2023-05-10 18:55:59,191 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 18:55:59,191 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 18:56:15,647 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 18:56:32,549 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 18:56:49,540 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 18:57:07,122 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-10 18:57:24,461 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 18:57:41,616 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 18:57:58,760 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 18:58:15,761 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 18:58:33,265 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 18:58:50,744 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 18:59:07,729 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 18:59:23,922 INFO    :        | end of iter   0 | time:  5.12s | train loss 0.0000 | 
2023-05-10 18:59:40,911 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 18:59:57,603 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 19:00:14,510 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:00:31,412 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:00:48,404 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 19:01:05,543 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:01:22,621 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 19:01:39,841 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 19:01:56,891 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 19:02:14,175 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 19:02:30,761 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:02:47,682 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 19:03:04,586 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:03:21,849 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 19:03:38,709 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 19:03:55,508 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 19:04:12,197 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:04:28,856 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 19:04:45,185 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 19:05:02,015 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 19:05:18,517 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 19:05:35,399 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 19:05:52,287 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:06:08,938 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:06:25,590 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:06:42,482 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 19:06:59,352 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 19:07:16,676 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 19:07:33,682 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 19:07:51,498 INFO    :        | end of iter   0 | time:  6.85s | train loss 0.0000 | 
2023-05-10 19:08:08,766 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 19:08:25,751 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 19:08:42,952 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 19:08:59,652 INFO    :        | end of iter   0 | time:  5.23s | train loss 0.0000 | 
2023-05-10 19:09:16,857 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 19:09:33,863 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:09:50,523 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 19:10:07,422 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 19:10:07,422 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 19:10:07,423 INFO    :    | end of epoch  53 | time: 848.23s | epoch train loss 0.1281 | 
2023-05-10 19:10:07,423 INFO    : [INFO] Found new best model with 0.128 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 19:10:07,562 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 19:10:07,563 INFO    : [INFO] Starting eval for this model ...
2023-05-10 19:10:12,174 INFO    : [INFO] End of valid | time:  4.61s | valid loss 46.6701 | 
2023-05-10 19:10:12,174 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 19:10:12,174 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 19:10:12,174 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 19:10:29,079 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 19:10:45,692 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 19:11:02,754 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 19:11:19,563 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 19:11:35,957 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 19:11:52,771 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 19:12:09,054 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 19:12:25,531 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 19:12:42,279 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 19:12:58,681 INFO    :        | end of iter   0 | time:  5.39s | train loss 0.0000 | 
2023-05-10 19:13:15,219 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 19:13:32,388 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 19:13:49,450 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:14:06,691 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 19:14:23,846 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:14:40,595 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:14:57,656 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:15:14,766 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:15:31,732 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 19:15:49,149 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-10 19:16:06,209 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:16:23,373 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:16:39,984 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:16:57,027 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-10 19:17:13,923 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 19:17:30,616 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 19:17:47,550 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 19:18:04,358 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 19:18:20,987 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 19:18:37,719 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:18:54,303 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:19:11,260 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 19:19:27,877 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 19:19:44,490 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 19:20:01,400 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 19:20:18,368 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:20:35,751 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:20:53,227 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 19:21:10,521 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:21:27,580 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 19:21:44,323 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 19:22:01,385 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 19:22:18,066 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 19:22:34,565 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 19:22:51,028 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:23:08,061 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 19:23:24,517 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:23:41,236 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:23:58,554 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 19:24:15,694 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 19:24:15,694 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 19:24:15,694 INFO    :    | end of epoch  54 | time: 843.52s | epoch train loss 0.1254 | 
2023-05-10 19:24:15,694 INFO    : [INFO] Found new best model with 0.125 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 19:24:15,847 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 19:24:15,847 INFO    : [INFO] Starting eval for this model ...
2023-05-10 19:24:20,437 INFO    : [INFO] End of valid | time:  4.59s | valid loss 46.7818 | 
2023-05-10 19:24:20,437 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 19:24:20,437 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 19:24:20,438 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 19:24:33,389 INFO    :        | end of iter   0 | time:  1.53s | train loss 0.0000 | 
2023-05-10 19:24:50,618 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 19:25:07,661 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:25:24,830 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 19:25:41,543 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 19:25:58,596 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:26:15,358 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 19:26:32,291 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 19:26:48,656 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 19:27:05,785 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 19:27:22,568 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:27:39,317 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:27:56,175 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 19:28:12,985 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:28:29,838 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 19:28:47,143 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 19:29:04,172 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 19:29:20,994 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 19:29:37,372 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:29:54,096 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 19:30:10,990 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 19:30:28,057 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-10 19:30:44,695 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:31:01,421 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 19:31:18,545 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:31:35,770 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 19:31:52,541 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 19:32:09,307 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:32:26,213 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 19:32:42,723 INFO    :        | end of iter   0 | time:  5.18s | train loss 0.0000 | 
2023-05-10 19:32:59,605 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 19:33:16,603 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:33:33,287 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 19:33:50,272 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 19:34:06,910 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 19:34:23,696 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 19:34:40,804 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 19:34:57,683 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 19:35:14,431 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 19:35:31,365 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 19:35:48,339 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 19:36:05,125 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 19:36:21,718 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 19:36:37,650 INFO    :        | end of iter   0 | time:  5.28s | train loss 0.0000 | 
2023-05-10 19:36:54,597 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 19:37:11,417 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:37:28,154 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 19:37:44,820 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:38:01,277 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 19:38:18,012 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 19:38:18,013 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 19:38:18,013 INFO    :    | end of epoch  55 | time: 837.58s | epoch train loss 0.1234 | 
2023-05-10 19:38:18,013 INFO    : [INFO] Found new best model with 0.123 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 19:38:18,145 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 19:38:18,145 INFO    : [INFO] Starting eval for this model ...
2023-05-10 19:38:22,393 INFO    : [INFO] End of valid | time:  4.25s | valid loss 46.8337 | 
2023-05-10 19:38:22,393 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.350711, r:0.269091, f:0.304527

2023-05-10 19:38:22,393 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 19:38:22,394 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 19:38:39,395 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 19:38:56,199 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 19:39:13,140 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:39:29,920 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 19:39:47,092 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 19:40:04,141 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 19:40:20,918 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 19:40:37,995 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 19:40:55,083 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 19:41:12,091 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 19:41:28,957 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 19:41:45,618 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 19:42:02,942 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 19:42:19,766 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:42:36,988 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 19:42:54,099 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 19:43:11,200 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 19:43:27,873 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 19:43:44,625 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 19:44:01,635 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 19:44:18,808 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 19:44:35,586 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 19:44:52,563 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 19:45:09,069 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 19:45:26,506 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 19:45:43,792 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:46:01,021 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:46:18,592 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 19:46:35,516 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 19:46:52,609 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 19:47:09,694 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 19:47:26,666 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 19:47:44,010 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 19:48:01,046 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-10 19:48:17,832 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 19:48:34,601 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 19:48:51,299 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:49:08,395 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 19:49:25,713 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 19:49:42,842 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 19:49:59,876 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 19:50:17,112 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 19:50:33,828 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 19:50:50,325 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 19:51:07,383 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 19:51:24,877 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-10 19:51:41,896 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 19:51:58,371 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 19:52:15,177 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 19:52:31,962 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 19:52:31,963 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 19:52:31,963 INFO    :    | end of epoch  56 | time: 849.57s | epoch train loss 0.1209 | 
2023-05-10 19:52:31,963 INFO    : [INFO] Found new best model with 0.121 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 19:52:32,111 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 19:52:32,111 INFO    : [INFO] Starting eval for this model ...
2023-05-10 19:52:36,604 INFO    : [INFO] End of valid | time:  4.49s | valid loss 46.7809 | 
2023-05-10 19:52:36,604 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 19:52:36,605 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 19:52:36,605 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 19:52:53,054 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 19:53:10,305 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 19:53:27,852 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 19:53:44,448 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 19:54:00,971 INFO    :        | end of iter   0 | time:  5.30s | train loss 0.0000 | 
2023-05-10 19:54:18,971 INFO    :        | end of iter   0 | time:  6.72s | train loss 0.0000 | 
2023-05-10 19:54:36,682 INFO    :        | end of iter   0 | time:  6.73s | train loss 0.0000 | 
2023-05-10 19:54:53,310 INFO    :        | end of iter   0 | time:  5.26s | train loss 0.0000 | 
2023-05-10 19:55:10,391 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 19:55:26,981 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 19:55:43,730 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 19:56:00,495 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 19:56:17,259 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 19:56:33,928 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 19:56:50,761 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 19:57:07,891 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 19:57:24,931 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:57:42,084 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 19:57:58,845 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 19:58:16,241 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 19:58:33,454 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:58:50,703 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 19:59:07,733 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 19:59:24,760 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 19:59:42,115 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 19:59:59,326 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 20:00:16,523 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 20:00:33,747 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 20:00:50,801 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 20:01:07,888 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 20:01:24,757 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 20:01:41,885 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 20:01:58,550 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 20:02:15,254 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 20:02:32,149 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 20:02:48,889 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 20:03:05,889 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 20:03:22,675 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 20:03:39,494 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 20:03:56,326 INFO    :        | end of iter   0 | time:  5.11s | train loss 0.0000 | 
2023-05-10 20:04:14,029 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 20:04:31,133 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 20:04:48,202 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 20:05:04,565 INFO    :        | end of iter   0 | time:  5.25s | train loss 0.0000 | 
2023-05-10 20:05:21,731 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 20:05:38,338 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 20:05:55,392 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 20:06:12,216 INFO    :        | end of iter   0 | time:  5.28s | train loss 0.0000 | 
2023-05-10 20:06:29,072 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 20:06:46,238 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 20:06:46,239 INFO    : [INFO] The learning rate now is 0.000009
2023-05-10 20:06:46,239 INFO    :    | end of epoch  57 | time: 849.63s | epoch train loss 0.1185 | 
2023-05-10 20:06:46,239 INFO    : [INFO] Found new best model with 0.118 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 20:06:46,386 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 20:06:46,387 INFO    : [INFO] Starting eval for this model ...
2023-05-10 20:06:50,856 INFO    : [INFO] End of valid | time:  4.47s | valid loss 46.8396 | 
2023-05-10 20:06:50,857 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 20:06:50,857 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 20:06:50,857 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 20:07:07,807 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 20:07:24,804 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 20:07:41,442 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 20:07:57,842 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 20:08:14,646 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 20:08:31,099 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 20:08:48,291 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 20:09:05,169 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 20:09:22,328 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 20:09:39,367 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 20:09:56,394 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 20:10:13,322 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 20:10:30,640 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 20:10:47,916 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 20:11:04,796 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 20:11:21,825 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 20:11:38,921 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 20:11:55,740 INFO    :        | end of iter   0 | time:  5.25s | train loss 0.0000 | 
2023-05-10 20:12:12,635 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 20:12:29,626 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 20:12:46,176 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 20:13:02,914 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 20:13:19,610 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 20:13:36,264 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 20:13:52,863 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 20:14:09,675 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 20:14:26,592 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 20:14:43,416 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 20:15:00,121 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 20:15:16,554 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 20:15:33,358 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 20:15:50,334 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-10 20:16:07,067 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 20:16:23,520 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 20:16:39,749 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 20:16:56,668 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 20:17:13,941 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 20:17:30,487 INFO    :        | end of iter   0 | time:  5.21s | train loss 0.0000 | 
2023-05-10 20:17:47,834 INFO    :        | end of iter   0 | time:  5.28s | train loss 0.0000 | 
2023-05-10 20:18:11,030 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 20:18:31,123 INFO    :        | end of iter   0 | time:  5.41s | train loss 0.0000 | 
2023-05-10 20:18:51,531 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 20:19:08,371 INFO    :        | end of iter   0 | time:  5.21s | train loss 0.0000 | 
2023-05-10 20:19:34,748 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 20:19:55,048 INFO    :        | end of iter   0 | time:  5.38s | train loss 0.0000 | 
2023-05-10 20:20:15,528 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 20:20:35,905 INFO    :        | end of iter   0 | time:  5.10s | train loss 0.0000 | 
2023-05-10 20:20:52,681 INFO    :        | end of iter   0 | time:  4.84s | train loss 0.0000 | 
2023-05-10 20:21:15,609 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 20:21:38,099 INFO    :        | end of iter   0 | time:  5.35s | train loss 0.0000 | 
2023-05-10 20:21:38,100 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 20:21:38,100 INFO    :    | end of epoch  58 | time: 887.24s | epoch train loss 0.1165 | 
2023-05-10 20:21:38,100 INFO    : [INFO] Found new best model with 0.116 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 20:21:38,225 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 20:21:38,630 INFO    : [INFO] Starting eval for this model ...
2023-05-10 20:21:43,164 INFO    : [INFO] End of valid | time:  4.53s | valid loss 46.8907 | 
2023-05-10 20:21:43,164 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.341232, r:0.261818, f:0.296296

2023-05-10 20:21:43,164 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 20:21:43,165 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 20:22:00,244 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 20:22:16,759 INFO    :        | end of iter   0 | time:  5.15s | train loss 0.0000 | 
2023-05-10 20:22:33,345 INFO    :        | end of iter   0 | time:  5.20s | train loss 0.0000 | 
2023-05-10 20:22:50,168 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 20:23:07,287 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 20:23:24,183 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 20:23:40,865 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 20:23:57,631 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 20:24:14,624 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 20:24:31,573 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 20:24:48,095 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 20:25:04,772 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 20:25:21,499 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 20:25:37,888 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 20:25:54,447 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 20:26:11,045 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 20:26:27,662 INFO    :        | end of iter   0 | time:  5.32s | train loss 0.0000 | 
2023-05-10 20:26:44,703 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 20:27:01,050 INFO    :        | end of iter   0 | time:  5.29s | train loss 0.0000 | 
2023-05-10 20:27:17,688 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 20:27:33,845 INFO    :        | end of iter   0 | time:  5.09s | train loss 0.0000 | 
2023-05-10 20:27:50,832 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 20:28:07,679 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 20:28:24,681 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-10 20:28:41,625 INFO    :        | end of iter   0 | time:  5.36s | train loss 0.0000 | 
2023-05-10 20:28:58,492 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 20:29:15,537 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 20:29:32,706 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 20:29:49,764 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 20:30:06,274 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 20:30:22,738 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 20:30:39,524 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 20:30:56,548 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 20:31:13,542 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 20:31:30,616 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 20:31:47,738 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 20:32:04,706 INFO    :        | end of iter   0 | time:  5.44s | train loss 0.0000 | 
2023-05-10 20:32:21,844 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 20:32:38,739 INFO    :        | end of iter   0 | time:  5.61s | train loss 0.0000 | 
2023-05-10 20:32:55,511 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 20:33:12,281 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 20:33:29,197 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 20:33:46,351 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 20:34:03,081 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 20:34:19,933 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 20:34:36,656 INFO    :        | end of iter   0 | time:  5.45s | train loss 0.0000 | 
2023-05-10 20:34:53,555 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 20:35:10,618 INFO    :        | end of iter   0 | time:  5.29s | train loss 0.0000 | 
2023-05-10 20:35:28,027 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 20:35:44,895 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 20:35:44,896 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 20:35:44,896 INFO    :    | end of epoch  59 | time: 841.73s | epoch train loss 0.1146 | 
2023-05-10 20:35:44,896 INFO    : [INFO] Found new best model with 0.115 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 20:35:45,036 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 20:35:45,036 INFO    : [INFO] Starting eval for this model ...
2023-05-10 20:35:49,389 INFO    : [INFO] End of valid | time:  4.35s | valid loss 46.8890 | 
2023-05-10 20:35:49,389 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.341232, r:0.261818, f:0.296296

2023-05-10 20:35:49,389 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 20:35:49,389 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 20:36:06,283 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 20:36:22,615 INFO    :        | end of iter   0 | time:  5.34s | train loss 0.0000 | 
2023-05-10 20:36:39,367 INFO    :        | end of iter   0 | time:  5.25s | train loss 0.0000 | 
2023-05-10 20:36:56,232 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 20:37:13,288 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 20:37:29,852 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 20:37:46,283 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 20:38:03,366 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 20:38:20,487 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 20:38:37,048 INFO    :        | end of iter   0 | time:  5.46s | train loss 0.0000 | 
2023-05-10 20:38:53,390 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 20:39:10,078 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 20:39:22,175 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:39:34,303 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0000 | 
2023-05-10 20:39:46,826 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:39:59,106 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 20:40:11,209 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 20:40:23,467 INFO    :        | end of iter   0 | time:  1.29s | train loss 0.0000 | 
2023-05-10 20:40:35,571 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:40:47,861 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0000 | 
2023-05-10 20:40:59,978 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 20:41:11,870 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:41:24,443 INFO    :        | end of iter   0 | time:  1.30s | train loss 0.0000 | 
2023-05-10 20:41:36,370 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:41:48,432 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:42:00,805 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:42:13,358 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:42:25,491 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:42:37,840 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:42:50,273 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:43:02,536 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 20:43:14,730 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 20:43:27,153 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:43:39,070 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:43:51,167 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:44:03,517 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0000 | 
2023-05-10 20:44:16,154 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:44:28,713 INFO    :        | end of iter   0 | time:  1.27s | train loss 0.0000 | 
2023-05-10 20:44:41,317 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:44:53,974 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:45:06,206 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:45:18,627 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:45:30,668 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:45:42,343 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 20:45:54,510 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:46:06,694 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:46:18,761 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:46:31,106 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:46:43,344 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 20:46:55,316 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 20:46:55,316 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 20:46:55,317 INFO    :    | end of epoch  60 | time: 665.93s | epoch train loss 0.1122 | 
2023-05-10 20:46:55,317 INFO    : [INFO] Found new best model with 0.112 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 20:46:55,488 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 20:46:55,488 INFO    : [INFO] Starting eval for this model ...
2023-05-10 20:46:57,538 INFO    : [INFO] End of valid | time:  2.05s | valid loss 46.9155 | 
2023-05-10 20:46:57,538 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 20:46:57,538 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 20:46:57,538 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 20:47:09,644 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 20:47:21,964 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:47:34,498 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:47:46,865 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:47:59,032 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:48:11,022 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:48:22,611 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:48:34,819 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:48:47,018 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 20:48:59,393 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 20:49:11,416 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:49:23,405 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 20:49:35,541 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:49:47,694 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:49:59,844 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:50:11,953 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 20:50:24,368 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:50:36,635 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:50:48,619 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:51:00,691 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:51:12,626 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:51:24,595 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:51:36,622 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 20:51:49,045 INFO    :        | end of iter   0 | time:  1.14s | train loss 0.0000 | 
2023-05-10 20:52:00,911 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:52:12,923 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 20:52:24,945 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:52:36,817 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:52:48,651 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:53:00,841 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:53:12,942 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 20:53:24,881 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:53:37,043 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 20:53:48,923 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:54:01,089 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:54:13,304 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 20:54:25,077 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:54:36,743 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 20:54:48,684 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:55:00,536 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:55:12,403 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 20:55:24,346 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:55:35,988 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:55:47,954 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:56:00,219 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 20:56:12,409 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:56:24,130 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:56:36,167 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:56:48,125 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:56:59,838 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:56:59,838 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 20:56:59,838 INFO    :    | end of epoch  61 | time: 602.30s | epoch train loss 0.1105 | 
2023-05-10 20:56:59,838 INFO    : [INFO] Found new best model with 0.111 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 20:56:59,975 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 20:56:59,976 INFO    : [INFO] Starting eval for this model ...
2023-05-10 20:57:02,057 INFO    : [INFO] End of valid | time:  2.08s | valid loss 46.9716 | 
2023-05-10 20:57:02,057 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.345972, r:0.265455, f:0.300412

2023-05-10 20:57:02,057 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 20:57:02,057 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 20:57:14,188 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:57:26,644 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:57:38,894 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 20:57:51,357 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 20:58:03,386 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 20:58:15,555 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 20:58:27,564 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 20:58:39,624 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:58:51,498 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 20:59:03,453 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 20:59:15,096 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 20:59:27,018 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 20:59:39,084 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 20:59:51,068 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 21:00:03,129 INFO    :        | end of iter   0 | time:  1.41s | train loss 0.0000 | 
2023-05-10 21:00:15,205 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 21:00:26,899 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:00:38,763 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 21:00:50,662 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 21:01:02,452 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:01:14,486 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:01:26,685 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 21:01:38,713 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:01:50,628 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:02:02,764 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:02:15,055 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:02:27,199 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:02:39,710 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:02:52,033 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:03:04,218 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:03:16,118 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:03:27,915 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:03:40,102 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:03:52,025 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:04:04,347 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:04:16,655 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:04:28,939 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:04:40,819 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:04:52,804 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:05:05,079 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:05:17,433 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:05:29,533 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:05:41,667 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:05:54,103 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 21:06:06,286 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:06:18,180 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:06:30,363 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0000 | 
2023-05-10 21:06:42,531 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 21:06:54,633 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:07:06,469 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:07:06,470 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 21:07:06,470 INFO    :    | end of epoch  62 | time: 604.41s | epoch train loss 0.1084 | 
2023-05-10 21:07:06,470 INFO    : [INFO] Found new best model with 0.108 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 21:07:06,799 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 21:07:06,799 INFO    : [INFO] Starting eval for this model ...
2023-05-10 21:07:08,785 INFO    : [INFO] End of valid | time:  1.99s | valid loss 47.0486 | 
2023-05-10 21:07:08,786 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 21:07:08,786 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 21:07:08,786 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 21:07:20,938 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:07:33,166 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:07:45,437 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:07:57,312 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 21:08:09,339 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:08:21,372 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 21:08:33,259 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 21:08:44,971 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:08:56,820 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:09:08,526 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:09:20,230 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:09:32,512 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:09:44,896 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:09:57,248 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:10:09,643 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:10:21,920 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:10:33,650 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:10:45,822 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:10:57,822 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:11:09,972 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 21:11:22,237 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:11:34,544 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:11:46,851 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:11:59,155 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:12:11,193 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:12:23,366 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:12:35,683 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:12:47,853 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 21:12:59,731 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 21:13:11,570 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:13:23,683 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:13:35,409 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 21:13:47,388 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:13:59,406 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:14:11,338 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:14:23,406 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:14:35,794 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:14:48,139 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:15:00,345 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:15:12,424 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:15:24,241 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:15:36,105 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:15:47,881 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:15:59,812 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:16:11,618 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:16:23,574 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:16:35,536 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:16:47,498 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:16:59,303 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:17:11,048 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:17:11,048 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 21:17:11,048 INFO    :    | end of epoch  63 | time: 602.26s | epoch train loss 0.1065 | 
2023-05-10 21:17:11,048 INFO    : [INFO] Found new best model with 0.106 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 21:17:11,202 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 21:17:11,202 INFO    : [INFO] Starting eval for this model ...
2023-05-10 21:17:13,236 INFO    : [INFO] End of valid | time:  2.03s | valid loss 47.0132 | 
2023-05-10 21:17:13,237 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.336493, r:0.258182, f:0.292181

2023-05-10 21:17:13,237 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 21:17:13,237 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 21:17:25,159 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:17:36,981 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:17:49,068 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:18:01,060 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:18:12,879 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:18:24,891 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:18:37,012 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:18:48,949 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 21:19:00,795 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:19:12,676 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:19:24,576 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:19:36,523 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:19:48,254 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:20:00,278 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 21:20:12,194 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0000 | 
2023-05-10 21:20:23,775 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:20:35,577 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:20:47,549 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:20:59,558 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:21:11,404 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:21:23,400 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:21:35,334 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:21:47,358 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:21:59,478 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:22:11,756 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:22:23,560 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:22:35,273 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:22:47,327 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 21:22:59,560 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:23:11,761 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:23:24,284 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 21:23:36,600 INFO    :        | end of iter   0 | time:  1.15s | train loss 0.0000 | 
2023-05-10 21:23:48,663 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 21:24:00,670 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 21:24:12,620 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 21:24:24,988 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 21:24:37,080 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:24:49,268 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:25:01,308 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:25:13,531 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 21:25:26,022 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:25:37,988 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:25:49,905 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:26:01,615 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:26:13,772 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:26:25,755 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:26:37,603 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:26:49,451 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 21:27:01,493 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 21:27:13,680 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:27:13,681 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 21:27:13,681 INFO    :    | end of epoch  64 | time: 600.44s | epoch train loss 0.1046 | 
2023-05-10 21:27:13,681 INFO    : [INFO] Found new best model with 0.105 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 21:27:13,910 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 21:27:13,910 INFO    : [INFO] Starting eval for this model ...
2023-05-10 21:27:15,997 INFO    : [INFO] End of valid | time:  2.09s | valid loss 47.1677 | 
2023-05-10 21:27:15,997 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 21:27:15,997 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 21:27:15,997 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 21:27:28,245 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:27:40,431 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:27:52,640 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:28:04,941 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 21:28:17,307 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 21:28:29,580 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:28:41,826 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 21:28:54,200 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:29:06,532 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:29:18,817 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:29:31,198 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:29:42,844 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:29:54,862 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:30:06,880 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:30:18,640 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 21:30:30,577 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:30:42,601 INFO    :        | end of iter   0 | time:  1.18s | train loss 0.0000 | 
2023-05-10 21:30:54,436 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:31:06,854 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 21:31:18,849 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:31:31,110 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:31:43,529 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:31:56,035 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:32:08,260 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:32:20,341 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:32:32,413 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:32:44,622 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:32:56,934 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:33:09,285 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:33:21,607 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:33:33,716 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:33:45,939 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:33:57,716 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:34:09,981 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:34:22,067 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:34:34,227 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:34:46,107 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:34:58,144 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:35:10,183 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 21:35:22,682 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:35:35,060 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:35:47,298 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:35:59,328 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:36:11,423 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:36:23,294 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:36:35,139 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:36:46,935 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:36:58,809 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:37:10,634 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:37:22,423 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:37:22,423 INFO    : [INFO] The learning rate now is 0.000008
2023-05-10 21:37:22,423 INFO    :    | end of epoch  65 | time: 606.43s | epoch train loss 0.1028 | 
2023-05-10 21:37:22,423 INFO    : [INFO] Found new best model with 0.103 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 21:37:22,547 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 21:37:22,548 INFO    : [INFO] Starting eval for this model ...
2023-05-10 21:37:24,640 INFO    : [INFO] End of valid | time:  2.09s | valid loss 47.0920 | 
2023-05-10 21:37:24,640 INFO    : Rouge1:
	p:0.374408, r:0.287273, f:0.325103
Rouge2:
	p:0.124590, r:0.091127, f:0.105263
Rougel:
	p:0.336493, r:0.258182, f:0.292181

2023-05-10 21:37:24,640 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 21:37:24,640 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 21:37:36,930 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:37:48,838 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:38:01,062 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:38:13,206 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:38:25,631 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:38:37,632 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:38:49,874 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 21:39:01,850 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:39:13,835 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:39:25,629 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:39:37,708 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:39:49,687 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:40:01,569 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:40:13,409 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:40:25,647 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:40:37,845 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:40:50,257 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:41:02,159 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:41:14,065 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:41:26,009 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:41:37,653 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:41:49,664 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:42:01,622 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:42:13,463 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:42:25,514 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:42:37,596 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:42:49,453 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:43:01,421 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 21:43:13,691 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:43:25,646 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:43:37,572 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:43:49,476 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:44:01,499 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:44:13,453 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:44:25,420 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:44:37,451 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:44:49,447 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:45:01,625 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:45:13,804 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:45:26,057 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 21:45:38,123 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:45:50,038 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:46:02,251 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:46:14,313 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:46:26,402 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:46:38,573 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:46:50,569 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:47:02,688 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:47:14,719 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 21:47:26,622 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:47:26,622 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 21:47:26,622 INFO    :    | end of epoch  66 | time: 601.98s | epoch train loss 0.1011 | 
2023-05-10 21:47:26,622 INFO    : [INFO] Found new best model with 0.101 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 21:47:26,800 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 21:47:26,800 INFO    : [INFO] Starting eval for this model ...
2023-05-10 21:47:28,824 INFO    : [INFO] End of valid | time:  2.02s | valid loss 47.2256 | 
2023-05-10 21:47:28,824 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 21:47:28,824 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 21:47:28,824 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 21:47:40,752 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:47:52,886 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:48:05,142 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:48:17,267 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:48:29,572 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:48:41,785 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:48:54,064 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:49:06,412 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0000 | 
2023-05-10 21:49:18,718 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:49:31,042 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 21:49:43,435 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 21:49:55,690 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:50:07,922 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:50:19,942 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:50:31,853 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:50:43,715 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:50:55,594 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:51:07,522 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:51:19,273 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:51:31,430 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 21:51:43,563 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:51:55,677 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 21:52:08,160 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:52:20,594 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 21:52:32,901 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 21:52:45,063 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 21:52:57,404 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:53:09,645 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:53:21,858 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:53:33,945 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:53:45,919 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:53:57,839 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:54:09,950 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:54:21,937 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:54:33,993 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:54:46,336 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:54:58,190 INFO    :        | end of iter   0 | time:  1.25s | train loss 0.0000 | 
2023-05-10 21:55:10,190 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 21:55:22,157 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 21:55:34,196 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:55:46,094 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:55:58,044 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:56:10,029 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:56:22,274 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:56:34,394 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:56:46,239 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:56:58,151 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:57:10,224 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 21:57:22,155 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:57:34,083 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 21:57:34,083 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 21:57:34,083 INFO    :    | end of epoch  67 | time: 605.26s | epoch train loss 0.0996 | 
2023-05-10 21:57:34,083 INFO    : [INFO] Found new best model with 0.100 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 21:57:34,217 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 21:57:34,217 INFO    : [INFO] Starting eval for this model ...
2023-05-10 21:57:36,285 INFO    : [INFO] End of valid | time:  2.07s | valid loss 47.2439 | 
2023-05-10 21:57:36,286 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 21:57:36,286 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 21:57:36,286 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 21:57:48,143 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:57:59,990 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:58:11,767 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:58:23,558 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:58:35,464 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 21:58:47,303 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:58:59,316 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:59:10,959 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:59:22,738 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 21:59:34,683 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 21:59:46,557 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 21:59:58,753 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:00:10,791 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:00:22,719 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:00:34,643 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:00:46,644 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:00:58,849 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:01:10,778 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:01:22,775 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:01:35,053 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 22:01:47,223 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:01:59,310 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:02:11,323 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:02:23,375 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:02:35,809 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:02:48,181 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:03:00,473 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:03:12,687 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:03:24,935 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:03:37,274 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:03:49,539 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:04:01,945 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:04:15,126 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:04:27,425 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:04:40,335 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:04:52,805 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:05:05,005 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:05:17,353 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:05:29,744 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:05:41,899 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:05:54,085 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 22:06:06,599 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:06:19,164 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:06:31,287 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:06:43,750 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:06:55,816 INFO    :        | end of iter   0 | time:  1.28s | train loss 0.0000 | 
2023-05-10 22:07:07,808 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:07:20,300 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:07:32,826 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:07:45,261 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:07:45,262 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 22:07:45,262 INFO    :    | end of epoch  68 | time: 608.98s | epoch train loss 0.0979 | 
2023-05-10 22:07:45,262 INFO    : [INFO] Found new best model with 0.098 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 22:07:45,394 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 22:07:45,394 INFO    : [INFO] Starting eval for this model ...
2023-05-10 22:07:47,648 INFO    : [INFO] End of valid | time:  2.25s | valid loss 47.2453 | 
2023-05-10 22:07:47,648 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.334928, r:0.254545, f:0.289256

2023-05-10 22:07:47,648 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 22:07:47,648 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 22:08:00,102 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 22:08:12,188 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 22:08:24,148 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:08:36,207 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:08:48,559 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:09:00,658 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:09:12,421 INFO    :        | end of iter   0 | time:  1.01s | train loss 0.0000 | 
2023-05-10 22:09:24,166 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:09:36,251 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:09:48,497 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:10:00,270 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:10:12,291 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:10:24,180 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:10:36,742 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:10:49,468 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 22:11:01,740 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:11:14,071 INFO    :        | end of iter   0 | time:  1.22s | train loss 0.0000 | 
2023-05-10 22:11:26,082 INFO    :        | end of iter   0 | time:  1.23s | train loss 0.0000 | 
2023-05-10 22:11:38,040 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:11:50,031 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:12:02,144 INFO    :        | end of iter   0 | time:  1.29s | train loss 0.0000 | 
2023-05-10 22:12:14,569 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:12:27,035 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:12:40,847 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:12:52,821 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:13:04,914 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:13:17,455 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:13:29,647 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:13:41,531 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:13:53,474 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:14:05,664 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:14:17,758 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:14:30,058 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:14:42,208 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:14:54,252 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:15:06,434 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:15:19,008 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:15:31,546 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:15:45,547 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 22:15:57,943 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:16:10,414 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 22:16:22,348 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:16:34,138 INFO    :        | end of iter   0 | time:  1.17s | train loss 0.0000 | 
2023-05-10 22:16:45,890 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:16:58,054 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:17:11,868 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:17:24,014 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:17:37,539 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:17:49,814 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:18:02,141 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:18:02,141 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 22:18:02,141 INFO    :    | end of epoch  69 | time: 614.49s | epoch train loss 0.0964 | 
2023-05-10 22:18:02,141 INFO    : [INFO] Found new best model with 0.096 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 22:18:02,319 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 22:18:02,320 INFO    : [INFO] Starting eval for this model ...
2023-05-10 22:18:04,362 INFO    : [INFO] End of valid | time:  2.04s | valid loss 47.3329 | 
2023-05-10 22:18:04,362 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 22:18:04,363 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 22:18:04,363 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 22:18:16,036 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:18:27,835 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:18:39,972 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:18:51,935 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:19:03,679 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:19:15,768 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:19:27,745 INFO    :        | end of iter   0 | time:  1.00s | train loss 0.0000 | 
2023-05-10 22:19:39,745 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:19:51,769 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:20:03,570 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:20:15,608 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:20:27,448 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:20:39,101 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:20:50,900 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:21:03,020 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:21:14,819 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:21:26,886 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:21:39,020 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:21:51,373 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:22:03,593 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:22:15,888 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:22:27,779 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:22:39,670 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:22:51,514 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:23:03,176 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:23:15,013 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:23:26,843 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 22:23:38,702 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:23:50,439 INFO    :        | end of iter   0 | time:  1.19s | train loss 0.0000 | 
2023-05-10 22:24:02,525 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 22:24:14,290 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:24:26,346 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:24:38,485 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:24:50,340 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:25:02,147 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:25:13,828 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:25:25,642 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:25:37,418 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:25:49,535 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:26:01,396 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:26:13,889 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:26:26,070 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:26:38,762 INFO    :        | end of iter   0 | time:  1.21s | train loss 0.0000 | 
2023-05-10 22:26:51,543 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:27:05,057 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 22:27:17,115 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:27:29,270 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 22:27:41,317 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:27:53,504 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:28:06,069 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 22:28:06,070 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 22:28:06,070 INFO    :    | end of epoch  70 | time: 601.71s | epoch train loss 0.0948 | 
2023-05-10 22:28:06,070 INFO    : [INFO] Found new best model with 0.095 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 22:28:06,212 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 22:28:06,213 INFO    : [INFO] Starting eval for this model ...
2023-05-10 22:28:08,295 INFO    : [INFO] End of valid | time:  2.08s | valid loss 47.3638 | 
2023-05-10 22:28:08,295 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 22:28:08,296 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 22:28:08,296 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 22:28:20,418 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:28:32,770 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:28:44,866 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 22:28:56,995 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:29:09,139 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:29:21,281 INFO    :        | end of iter   0 | time:  1.11s | train loss 0.0000 | 
2023-05-10 22:29:38,642 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:29:50,352 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:30:02,144 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:30:14,130 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:30:26,628 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:30:38,645 INFO    :        | end of iter   0 | time:  1.20s | train loss 0.0000 | 
2023-05-10 22:30:50,424 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:31:02,497 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:31:14,952 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:31:27,293 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:31:39,605 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:31:51,851 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:32:04,232 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:32:16,381 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:32:28,390 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:32:40,239 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:32:52,198 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:33:04,045 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:33:15,883 INFO    :        | end of iter   0 | time:  1.02s | train loss 0.0000 | 
2023-05-10 22:33:27,860 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:33:39,987 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:33:51,717 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:34:03,590 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:34:15,626 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:34:27,812 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:34:40,095 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:34:52,378 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:35:04,691 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:35:16,621 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:35:29,546 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:35:41,655 INFO    :        | end of iter   0 | time:  1.09s | train loss 0.0000 | 
2023-05-10 22:35:53,903 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:36:05,962 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:36:18,189 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:36:30,566 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:36:42,900 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:36:55,329 INFO    :        | end of iter   0 | time:  1.24s | train loss 0.0000 | 
2023-05-10 22:37:07,665 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:37:19,884 INFO    :        | end of iter   0 | time:  1.07s | train loss 0.0000 | 
2023-05-10 22:37:32,049 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 22:37:44,548 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:37:56,523 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:38:08,632 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:38:21,045 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:38:21,045 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 22:38:21,045 INFO    :    | end of epoch  71 | time: 612.75s | epoch train loss 0.0930 | 
2023-05-10 22:38:21,045 INFO    : [INFO] Found new best model with 0.093 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 22:38:21,238 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 22:38:21,238 INFO    : [INFO] Starting eval for this model ...
2023-05-10 22:38:23,283 INFO    : [INFO] End of valid | time:  2.04s | valid loss 47.4222 | 
2023-05-10 22:38:23,284 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 22:38:23,284 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 22:38:23,284 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 22:38:35,252 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:38:47,370 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:38:59,575 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 22:39:11,535 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:39:23,929 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:39:36,894 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:39:51,621 INFO    :        | end of iter   0 | time:  1.12s | train loss 0.0000 | 
2023-05-10 22:40:08,844 INFO    :        | end of iter   0 | time:  5.49s | train loss 0.0000 | 
2023-05-10 22:40:27,736 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 22:40:44,440 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 22:41:01,432 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 22:41:18,259 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 22:41:34,874 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 22:41:51,446 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 22:42:03,790 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:42:16,040 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:42:28,159 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:42:40,107 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:42:52,095 INFO    :        | end of iter   0 | time:  1.04s | train loss 0.0000 | 
2023-05-10 22:43:04,128 INFO    :        | end of iter   0 | time:  1.03s | train loss 0.0000 | 
2023-05-10 22:43:16,495 INFO    :        | end of iter   0 | time:  1.06s | train loss 0.0000 | 
2023-05-10 22:43:28,514 INFO    :        | end of iter   0 | time:  1.05s | train loss 0.0000 | 
2023-05-10 22:43:40,969 INFO    :        | end of iter   0 | time:  1.08s | train loss 0.0000 | 
2023-05-10 22:43:53,239 INFO    :        | end of iter   0 | time:  1.10s | train loss 0.0000 | 
2023-05-10 22:44:06,166 INFO    :        | end of iter   0 | time:  1.26s | train loss 0.0000 | 
2023-05-10 22:44:19,261 INFO    :        | end of iter   0 | time:  1.16s | train loss 0.0000 | 
2023-05-10 22:44:34,471 INFO    :        | end of iter   0 | time:  1.31s | train loss 0.0000 | 
2023-05-10 22:44:53,588 INFO    :        | end of iter   0 | time:  4.93s | train loss 0.0000 | 
2023-05-10 22:45:12,008 INFO    :        | end of iter   0 | time:  5.28s | train loss 0.0000 | 
2023-05-10 22:45:30,867 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 22:45:53,448 INFO    :        | end of iter   0 | time:  4.98s | train loss 0.0000 | 
2023-05-10 22:46:11,409 INFO    :        | end of iter   0 | time:  5.33s | train loss 0.0000 | 
2023-05-10 22:46:30,274 INFO    :        | end of iter   0 | time:  4.90s | train loss 0.0000 | 
2023-05-10 22:46:49,363 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 22:47:08,594 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 22:47:27,539 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-10 22:47:47,728 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 22:48:06,809 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 22:48:24,554 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-10 22:48:41,704 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 22:48:58,667 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 22:49:16,071 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 22:49:33,319 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 22:49:50,316 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 22:50:07,408 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-10 22:50:23,962 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 22:50:40,658 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 22:50:57,627 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 22:51:13,702 INFO    :        | end of iter   0 | time:  5.23s | train loss 0.0000 | 
2023-05-10 22:51:30,880 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 22:51:30,880 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 22:51:30,880 INFO    :    | end of epoch  72 | time: 787.60s | epoch train loss 0.0915 | 
2023-05-10 22:51:30,880 INFO    : [INFO] Found new best model with 0.091 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 22:51:31,035 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 22:51:31,035 INFO    : [INFO] Starting eval for this model ...
2023-05-10 22:51:39,168 INFO    : [INFO] End of valid | time:  8.13s | valid loss 47.4661 | 
2023-05-10 22:51:39,169 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 22:51:39,169 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 22:51:39,169 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 22:51:59,218 INFO    :        | end of iter   0 | time:  5.40s | train loss 0.0000 | 
2023-05-10 22:52:17,711 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 22:52:35,884 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 22:52:55,445 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-10 22:53:15,093 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 22:53:33,821 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-10 22:53:52,599 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 22:54:11,182 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 22:54:28,576 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-10 22:54:45,691 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 22:55:02,867 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 22:55:19,656 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 22:55:36,282 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-10 22:55:52,793 INFO    :        | end of iter   0 | time:  5.34s | train loss 0.0000 | 
2023-05-10 22:56:09,963 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 22:56:29,062 INFO    :        | end of iter   0 | time:  5.19s | train loss 0.0000 | 
2023-05-10 22:56:45,532 INFO    :        | end of iter   0 | time:  4.87s | train loss 0.0000 | 
2023-05-10 22:57:05,228 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 22:57:24,961 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 22:57:44,196 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-10 22:58:03,011 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 22:58:23,040 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 22:58:42,869 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 22:59:02,962 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 22:59:21,019 INFO    :        | end of iter   0 | time:  5.51s | train loss 0.0000 | 
2023-05-10 22:59:39,394 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 22:59:56,734 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-10 23:00:14,188 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 23:00:35,038 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 23:00:52,398 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 23:01:09,697 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 23:01:27,149 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:01:44,688 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-10 23:02:02,277 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 23:02:19,901 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 23:02:39,052 INFO    :        | end of iter   0 | time:  5.37s | train loss 0.0000 | 
2023-05-10 23:02:57,121 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:03:14,592 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 23:03:32,279 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 23:03:51,171 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-10 23:04:10,448 INFO    :        | end of iter   0 | time:  5.47s | train loss 0.0000 | 
2023-05-10 23:04:29,285 INFO    :        | end of iter   0 | time:  6.26s | train loss 0.0000 | 
2023-05-10 23:04:48,203 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 23:05:05,949 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-10 23:05:23,448 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-10 23:05:41,147 INFO    :        | end of iter   0 | time:  5.17s | train loss 0.0000 | 
2023-05-10 23:05:59,900 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-10 23:06:19,830 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 23:06:38,005 INFO    :        | end of iter   0 | time:  5.48s | train loss 0.0000 | 
2023-05-10 23:06:56,403 INFO    :        | end of iter   0 | time:  5.54s | train loss 0.0000 | 
2023-05-10 23:06:56,403 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 23:06:56,403 INFO    :    | end of epoch  73 | time: 917.23s | epoch train loss 0.0904 | 
2023-05-10 23:06:56,403 INFO    : [INFO] Found new best model with 0.090 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 23:06:56,603 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 23:06:56,603 INFO    : [INFO] Starting eval for this model ...
2023-05-10 23:07:00,802 INFO    : [INFO] End of valid | time:  4.20s | valid loss 47.6321 | 
2023-05-10 23:07:00,802 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 23:07:00,802 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 23:07:00,803 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 23:07:19,580 INFO    :        | end of iter   0 | time:  5.55s | train loss 0.0000 | 
2023-05-10 23:07:38,026 INFO    :        | end of iter   0 | time:  5.26s | train loss 0.0000 | 
2023-05-10 23:07:56,575 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-10 23:08:14,736 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 23:08:33,889 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 23:08:51,284 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 23:09:08,276 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 23:09:25,346 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-10 23:09:42,845 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 23:10:00,256 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 23:10:17,371 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-10 23:10:34,411 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:10:51,469 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:11:08,590 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 23:11:25,840 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 23:11:43,160 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-10 23:12:01,094 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 23:12:18,838 INFO    :        | end of iter   0 | time:  6.32s | train loss 0.0000 | 
2023-05-10 23:12:36,262 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 23:12:53,419 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-10 23:13:10,148 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-10 23:13:27,421 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-10 23:13:44,726 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-10 23:14:02,015 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 23:14:19,011 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-10 23:14:36,327 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-10 23:14:53,443 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 23:15:10,485 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:15:27,309 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 23:15:44,914 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-10 23:16:02,503 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 23:16:19,978 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 23:16:37,300 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 23:16:54,666 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-10 23:17:11,849 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 23:17:28,772 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 23:17:45,744 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 23:18:02,563 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 23:18:19,437 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:18:36,521 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 23:18:53,455 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 23:19:10,142 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 23:19:27,106 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 23:19:44,468 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-10 23:20:02,234 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-10 23:20:19,735 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-10 23:20:37,560 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 23:20:54,939 INFO    :        | end of iter   0 | time:  6.32s | train loss 0.0000 | 
2023-05-10 23:21:12,260 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-10 23:21:29,524 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:21:29,525 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 23:21:29,525 INFO    :    | end of epoch  74 | time: 868.72s | epoch train loss 0.0888 | 
2023-05-10 23:21:29,525 INFO    : [INFO] Found new best model with 0.089 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 23:21:29,670 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 23:21:29,670 INFO    : [INFO] Starting eval for this model ...
2023-05-10 23:21:34,255 INFO    : [INFO] End of valid | time:  4.58s | valid loss 47.5722 | 
2023-05-10 23:21:34,255 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 23:21:34,255 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 23:21:34,255 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 23:21:51,098 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 23:22:08,584 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-10 23:22:25,493 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-10 23:22:42,701 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 23:22:59,918 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 23:23:17,314 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 23:23:34,842 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-10 23:23:51,933 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 23:24:09,579 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 23:24:27,219 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 23:24:44,785 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 23:25:02,344 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-10 23:25:20,183 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 23:25:37,594 INFO    :        | end of iter   0 | time:  6.37s | train loss 0.0000 | 
2023-05-10 23:25:55,134 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-10 23:26:12,789 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-10 23:26:30,286 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-10 23:26:47,831 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-10 23:27:05,431 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-10 23:27:22,883 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:27:40,223 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 23:27:58,048 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:28:15,264 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-10 23:28:33,253 INFO    :        | end of iter   0 | time:  6.50s | train loss 0.0000 | 
2023-05-10 23:28:51,017 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-10 23:29:08,598 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 23:29:25,722 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-10 23:29:42,996 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 23:30:00,384 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 23:30:17,456 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-10 23:30:35,145 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-10 23:30:52,484 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 23:31:09,649 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 23:31:26,836 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 23:31:44,390 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 23:31:58,892 INFO    :        | end of iter   0 | time:  2.86s | train loss 0.0000 | 
2023-05-10 23:32:16,418 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 23:32:33,802 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:32:51,317 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-10 23:33:03,653 INFO    :        | end of iter   0 | time:  1.44s | train loss 0.0000 | 
2023-05-10 23:33:21,448 INFO    :        | end of iter   0 | time:  6.70s | train loss 0.0000 | 
2023-05-10 23:33:39,303 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-10 23:33:56,547 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:34:14,022 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-10 23:34:31,852 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 23:34:49,229 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 23:35:06,332 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 23:35:23,823 INFO    :        | end of iter   0 | time:  6.32s | train loss 0.0000 | 
2023-05-10 23:35:40,955 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 23:35:58,340 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 23:35:58,341 INFO    : [INFO] The learning rate now is 0.000007
2023-05-10 23:35:58,341 INFO    :    | end of epoch  75 | time: 864.09s | epoch train loss 0.0872 | 
2023-05-10 23:35:58,341 INFO    : [INFO] Found new best model with 0.087 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 23:35:58,533 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 23:35:58,534 INFO    : [INFO] Starting eval for this model ...
2023-05-10 23:36:03,249 INFO    : [INFO] End of valid | time:  4.71s | valid loss 47.6707 | 
2023-05-10 23:36:03,249 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 23:36:03,249 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 23:36:03,249 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 23:36:20,409 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 23:36:37,889 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-10 23:36:54,879 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:37:12,292 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 23:37:29,637 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 23:37:46,610 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 23:38:03,293 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-10 23:38:20,194 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-10 23:38:37,624 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:38:54,808 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-10 23:39:11,806 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-10 23:39:29,520 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-10 23:39:46,820 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 23:40:04,166 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-10 23:40:21,423 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-10 23:40:38,571 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-10 23:40:55,608 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:41:13,038 INFO    :        | end of iter   0 | time:  6.32s | train loss 0.0000 | 
2023-05-10 23:41:30,174 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-10 23:41:47,517 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-10 23:42:05,008 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-10 23:42:22,290 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 23:42:39,434 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-10 23:42:56,130 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-10 23:43:13,118 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-10 23:43:29,882 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-10 23:43:46,978 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-10 23:44:04,058 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:44:21,853 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-10 23:44:39,467 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 23:44:57,137 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-10 23:45:14,435 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 23:45:31,552 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-10 23:45:48,929 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-10 23:46:06,334 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 23:46:23,790 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 23:46:41,184 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-10 23:46:59,020 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-10 23:47:16,590 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-10 23:47:34,028 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-10 23:47:51,585 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:48:09,036 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-10 23:48:26,168 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 23:48:43,538 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:49:00,343 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 23:49:17,450 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-10 23:49:34,913 INFO    :        | end of iter   0 | time:  6.55s | train loss 0.0000 | 
2023-05-10 23:49:52,534 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:50:10,020 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:50:27,663 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 23:50:27,663 INFO    : [INFO] The learning rate now is 0.000006
2023-05-10 23:50:27,663 INFO    :    | end of epoch  76 | time: 864.41s | epoch train loss 0.0859 | 
2023-05-10 23:50:27,663 INFO    : [INFO] Found new best model with 0.086 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-10 23:50:27,817 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-10 23:50:27,817 INFO    : [INFO] Starting eval for this model ...
2023-05-10 23:50:32,651 INFO    : [INFO] End of valid | time:  4.83s | valid loss 47.7267 | 
2023-05-10 23:50:32,651 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-10 23:50:32,651 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-10 23:50:32,652 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-10 23:50:49,794 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-10 23:51:07,017 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 23:51:24,816 INFO    :        | end of iter   0 | time:  6.47s | train loss 0.0000 | 
2023-05-10 23:51:42,093 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-10 23:51:58,706 INFO    :        | end of iter   0 | time:  5.50s | train loss 0.0000 | 
2023-05-10 23:52:15,840 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 23:52:32,685 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-10 23:52:49,335 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-10 23:53:06,013 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-10 23:53:23,145 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-10 23:53:40,499 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-10 23:53:57,800 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-10 23:54:15,249 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-10 23:54:32,485 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-10 23:54:50,259 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-10 23:55:07,925 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:55:25,476 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 23:55:43,091 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-10 23:56:00,448 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 23:56:18,274 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-10 23:56:35,841 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-10 23:56:53,167 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-10 23:57:10,900 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-10 23:57:28,323 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 23:57:45,448 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-10 23:58:03,083 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-10 23:58:20,669 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-10 23:58:37,707 INFO    :        | end of iter   0 | time:  5.66s | train loss 0.0000 | 
2023-05-10 23:58:54,646 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-10 23:59:11,401 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-10 23:59:24,762 INFO    :        | end of iter   0 | time:  2.26s | train loss 0.0000 | 
2023-05-10 23:59:41,459 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-10 23:59:58,353 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-11 00:00:15,316 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 00:00:32,205 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 00:00:49,199 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 00:01:06,125 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 00:01:23,569 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 00:01:40,283 INFO    :        | end of iter   0 | time:  5.65s | train loss 0.0000 | 
2023-05-11 00:01:57,401 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 00:02:14,656 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:02:32,000 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 00:02:49,622 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-11 00:03:06,342 INFO    :        | end of iter   0 | time:  5.64s | train loss 0.0000 | 
2023-05-11 00:03:23,875 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 00:03:40,946 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 00:03:58,523 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:04:15,717 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 00:04:32,842 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 00:04:49,786 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 00:04:49,786 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 00:04:49,787 INFO    :    | end of epoch  77 | time: 857.13s | epoch train loss 0.0846 | 
2023-05-11 00:04:49,787 INFO    : [INFO] Found new best model with 0.085 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 00:04:50,007 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 00:04:50,007 INFO    : [INFO] Starting eval for this model ...
2023-05-11 00:04:54,772 INFO    : [INFO] End of valid | time:  4.76s | valid loss 47.7957 | 
2023-05-11 00:04:54,772 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 00:04:54,772 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 00:04:54,773 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 00:05:11,654 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-11 00:05:28,959 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 00:05:46,248 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 00:06:03,821 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 00:06:21,250 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 00:06:38,778 INFO    :        | end of iter   0 | time:  6.39s | train loss 0.0000 | 
2023-05-11 00:06:56,452 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 00:07:13,617 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 00:07:31,318 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 00:07:48,894 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 00:08:06,506 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 00:08:24,139 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:08:41,450 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 00:08:58,727 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 00:09:16,335 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 00:09:33,429 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 00:09:50,604 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 00:10:07,458 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 00:10:24,701 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 00:10:41,726 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 00:10:59,086 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 00:11:16,113 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 00:11:33,621 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 00:11:51,223 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:12:08,934 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 00:12:25,896 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 00:12:42,840 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 00:13:00,196 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-11 00:13:15,880 INFO    :        | end of iter   0 | time:  4.13s | train loss 0.0000 | 
2023-05-11 00:13:33,276 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 00:13:51,071 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 00:14:08,555 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 00:14:25,931 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 00:14:43,205 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 00:15:00,822 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 00:15:17,836 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:15:34,686 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 00:15:51,995 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 00:16:09,375 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 00:16:26,830 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 00:16:43,458 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 00:17:00,987 INFO    :        | end of iter   0 | time:  6.29s | train loss 0.0000 | 
2023-05-11 00:17:18,234 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:17:35,523 INFO    :        | end of iter   0 | time:  6.33s | train loss 0.0000 | 
2023-05-11 00:17:53,031 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 00:18:10,461 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 00:18:27,999 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:18:45,582 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 00:19:02,293 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 00:19:19,935 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 00:19:19,935 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 00:19:19,935 INFO    :    | end of epoch  78 | time: 865.16s | epoch train loss 0.0833 | 
2023-05-11 00:19:19,936 INFO    : [INFO] Found new best model with 0.083 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 00:19:20,081 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 00:19:20,082 INFO    : [INFO] Starting eval for this model ...
2023-05-11 00:19:24,825 INFO    : [INFO] End of valid | time:  4.74s | valid loss 47.8161 | 
2023-05-11 00:19:24,825 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 00:19:24,825 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 00:19:24,825 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 00:19:42,590 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 00:19:59,702 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 00:20:17,092 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:20:34,629 INFO    :        | end of iter   0 | time:  6.62s | train loss 0.0000 | 
2023-05-11 00:20:52,069 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 00:21:09,426 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-11 00:21:23,131 INFO    :        | end of iter   0 | time:  2.75s | train loss 0.0000 | 
2023-05-11 00:21:41,068 INFO    :        | end of iter   0 | time:  6.62s | train loss 0.0000 | 
2023-05-11 00:21:58,094 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 00:22:15,874 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 00:22:33,542 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 00:22:51,049 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 00:23:08,521 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 00:23:25,548 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 00:23:42,854 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:23:59,820 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 00:24:16,894 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 00:24:34,291 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 00:24:51,257 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 00:25:08,554 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 00:25:25,758 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 00:25:43,438 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 00:26:00,742 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 00:26:17,953 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 00:26:35,789 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 00:26:53,092 INFO    :        | end of iter   0 | time:  6.29s | train loss 0.0000 | 
2023-05-11 00:27:09,903 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 00:27:26,452 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 00:27:44,171 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 00:28:01,357 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 00:28:17,982 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-11 00:28:35,104 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 00:28:52,272 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 00:29:09,117 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 00:29:26,368 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 00:29:43,190 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 00:30:00,726 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-11 00:30:17,898 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 00:30:34,776 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 00:30:51,893 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 00:31:09,662 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 00:31:27,071 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-11 00:31:45,080 INFO    :        | end of iter   0 | time:  6.32s | train loss 0.0000 | 
2023-05-11 00:32:02,682 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 00:32:20,411 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 00:32:38,051 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:32:55,421 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 00:33:12,985 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 00:33:30,764 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 00:33:47,671 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-11 00:33:47,671 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 00:33:47,671 INFO    :    | end of epoch  79 | time: 862.85s | epoch train loss 0.0820 | 
2023-05-11 00:33:47,671 INFO    : [INFO] Found new best model with 0.082 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 00:33:47,882 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 00:33:47,882 INFO    : [INFO] Starting eval for this model ...
2023-05-11 00:33:52,357 INFO    : [INFO] End of valid | time:  4.47s | valid loss 47.8601 | 
2023-05-11 00:33:52,358 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 00:33:52,358 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 00:33:52,358 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 00:34:09,464 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 00:34:26,980 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 00:34:44,605 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 00:35:02,099 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 00:35:19,703 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 00:35:37,637 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-11 00:35:54,478 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 00:36:11,825 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 00:36:29,446 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 00:36:47,131 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 00:37:04,584 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 00:37:22,017 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 00:37:39,320 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 00:37:56,795 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-11 00:38:14,230 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 00:38:31,452 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 00:38:48,390 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 00:39:05,213 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 00:39:22,086 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 00:39:39,431 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-11 00:39:56,463 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 00:40:13,355 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 00:40:30,756 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 00:40:43,413 INFO    :        | end of iter   0 | time:  1.13s | train loss 0.0000 | 
2023-05-11 00:41:00,443 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 00:41:17,615 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:41:34,856 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 00:41:52,172 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 00:42:09,161 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:42:26,678 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 00:42:44,174 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 00:43:01,213 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 00:43:18,565 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 00:43:35,745 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 00:43:52,696 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-11 00:44:09,788 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 00:44:27,072 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 00:44:44,763 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 00:45:01,668 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 00:45:18,911 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 00:45:36,437 INFO    :        | end of iter   0 | time:  6.31s | train loss 0.0000 | 
2023-05-11 00:45:53,683 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 00:46:10,772 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-11 00:46:28,952 INFO    :        | end of iter   0 | time:  6.43s | train loss 0.0000 | 
2023-05-11 00:46:46,246 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 00:47:03,248 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 00:47:20,552 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 00:47:37,523 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 00:47:54,169 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 00:48:11,632 INFO    :        | end of iter   0 | time:  6.26s | train loss 0.0000 | 
2023-05-11 00:48:11,632 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 00:48:11,632 INFO    :    | end of epoch  80 | time: 859.27s | epoch train loss 0.0809 | 
2023-05-11 00:48:11,632 INFO    : [INFO] Found new best model with 0.081 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 00:48:11,787 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 00:48:11,787 INFO    : [INFO] Starting eval for this model ...
2023-05-11 00:48:16,316 INFO    : [INFO] End of valid | time:  4.53s | valid loss 47.9515 | 
2023-05-11 00:48:16,317 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 00:48:16,317 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 00:48:16,317 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 00:48:33,645 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 00:48:50,727 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 00:49:07,865 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-11 00:49:25,298 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 00:49:42,338 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 00:49:59,480 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 00:50:16,634 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 00:50:33,896 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-11 00:50:51,555 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 00:51:09,048 INFO    :        | end of iter   0 | time:  6.36s | train loss 0.0000 | 
2023-05-11 00:51:26,183 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 00:51:43,100 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 00:52:00,403 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 00:52:17,644 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 00:52:34,818 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 00:52:51,520 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 00:53:08,887 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 00:53:26,114 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-11 00:53:43,557 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 00:54:00,922 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 00:54:18,290 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 00:54:33,817 INFO    :        | end of iter   0 | time:  4.01s | train loss 0.0000 | 
2023-05-11 00:54:51,216 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 00:55:08,775 INFO    :        | end of iter   0 | time:  6.29s | train loss 0.0000 | 
2023-05-11 00:55:26,346 INFO    :        | end of iter   0 | time:  6.27s | train loss 0.0000 | 
2023-05-11 00:55:43,733 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 00:56:01,135 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-11 00:56:18,870 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 00:56:36,616 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-11 00:56:54,170 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 00:57:11,553 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 00:57:29,393 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 00:57:46,436 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 00:58:03,888 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 00:58:21,130 INFO    :        | end of iter   0 | time:  5.57s | train loss 0.0000 | 
2023-05-11 00:58:38,617 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 00:58:55,655 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 00:59:12,718 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 00:59:29,668 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 00:59:46,742 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 01:00:02,929 INFO    :        | end of iter   0 | time:  5.36s | train loss 0.0000 | 
2023-05-11 01:00:19,968 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 01:00:36,738 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 01:00:53,910 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-11 01:01:10,557 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-11 01:01:27,452 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 01:01:44,319 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 01:02:01,094 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-11 01:02:17,972 INFO    :        | end of iter   0 | time:  5.58s | train loss 0.0000 | 
2023-05-11 01:02:34,990 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 01:02:34,991 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 01:02:34,991 INFO    :    | end of epoch  81 | time: 858.67s | epoch train loss 0.0792 | 
2023-05-11 01:02:34,991 INFO    : [INFO] Found new best model with 0.079 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 01:02:35,196 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 01:02:35,196 INFO    : [INFO] Starting eval for this model ...
2023-05-11 01:02:39,863 INFO    : [INFO] End of valid | time:  4.67s | valid loss 48.0173 | 
2023-05-11 01:02:39,864 INFO    : Rouge1:
	p:0.357143, r:0.272727, f:0.309278
Rouge2:
	p:0.122186, r:0.091127, f:0.104396
Rougel:
	p:0.323810, r:0.247273, f:0.280412

2023-05-11 01:02:39,864 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 01:02:39,864 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 01:02:56,533 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-11 01:03:13,327 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 01:03:30,626 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 01:03:48,198 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 01:04:05,504 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 01:04:22,368 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 01:04:39,327 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 01:04:56,456 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:05:13,789 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 01:05:30,588 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-11 01:05:46,918 INFO    :        | end of iter   0 | time:  5.31s | train loss 0.0000 | 
2023-05-11 01:06:04,121 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 01:06:21,172 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-11 01:06:38,393 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 01:06:55,173 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 01:07:12,806 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 01:07:29,964 INFO    :        | end of iter   0 | time:  5.60s | train loss 0.0000 | 
2023-05-11 01:07:47,304 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 01:08:04,305 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-11 01:08:21,768 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 01:08:39,420 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 01:08:56,969 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 01:09:14,305 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 01:09:31,466 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-11 01:09:48,893 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 01:10:06,166 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 01:10:23,236 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 01:10:40,157 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 01:10:57,265 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 01:11:14,349 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 01:11:31,145 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 01:11:48,492 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 01:12:06,231 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 01:12:23,294 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 01:12:41,089 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-11 01:12:58,467 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 01:13:15,839 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 01:13:33,782 INFO    :        | end of iter   0 | time:  6.33s | train loss 0.0000 | 
2023-05-11 01:13:51,328 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:14:09,036 INFO    :        | end of iter   0 | time:  6.43s | train loss 0.0000 | 
2023-05-11 01:14:26,808 INFO    :        | end of iter   0 | time:  6.41s | train loss 0.0000 | 
2023-05-11 01:14:44,464 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 01:15:01,255 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 01:15:18,875 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 01:15:36,330 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 01:15:53,688 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 01:16:10,776 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 01:16:27,716 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-11 01:16:44,601 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 01:17:02,193 INFO    :        | end of iter   0 | time:  6.35s | train loss 0.0000 | 
2023-05-11 01:17:02,193 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 01:17:02,194 INFO    :    | end of epoch  82 | time: 862.33s | epoch train loss 0.0781 | 
2023-05-11 01:17:02,194 INFO    : [INFO] Found new best model with 0.078 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 01:17:02,371 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 01:17:02,371 INFO    : [INFO] Starting eval for this model ...
2023-05-11 01:17:06,867 INFO    : [INFO] End of valid | time:  4.49s | valid loss 48.0658 | 
2023-05-11 01:17:06,867 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.339713, r:0.258182, f:0.293388

2023-05-11 01:17:06,867 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 01:17:06,867 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 01:17:23,924 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 01:17:41,367 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:17:58,390 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 01:18:15,193 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 01:18:32,061 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 01:18:49,137 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:19:06,557 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:19:23,724 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 01:19:41,088 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 01:19:57,965 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 01:20:15,306 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 01:20:32,888 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-11 01:20:50,042 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 01:21:07,127 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 01:21:24,278 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 01:21:41,043 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 01:21:58,036 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 01:22:14,801 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 01:22:32,191 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 01:22:49,202 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 01:23:06,448 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 01:23:23,610 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 01:23:40,558 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 01:23:58,251 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 01:24:15,869 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:24:33,303 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 01:24:50,474 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 01:25:07,770 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 01:25:25,256 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 01:25:42,059 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 01:25:59,135 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 01:26:15,977 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 01:26:33,269 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 01:26:50,820 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 01:27:08,401 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 01:27:26,333 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 01:27:43,783 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 01:28:01,195 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 01:28:18,499 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:28:35,969 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 01:28:53,513 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:29:10,919 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 01:29:28,327 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:29:45,425 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 01:30:02,706 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:30:19,947 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 01:30:37,091 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 01:30:54,277 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:31:11,439 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 01:31:28,816 INFO    :        | end of iter   0 | time:  6.41s | train loss 0.0000 | 
2023-05-11 01:31:28,816 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 01:31:28,816 INFO    :    | end of epoch  83 | time: 861.95s | epoch train loss 0.0768 | 
2023-05-11 01:31:28,816 INFO    : [INFO] Found new best model with 0.077 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 01:31:29,035 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 01:31:29,035 INFO    : [INFO] Starting eval for this model ...
2023-05-11 01:31:33,600 INFO    : [INFO] End of valid | time:  4.56s | valid loss 48.2045 | 
2023-05-11 01:31:33,600 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 01:31:33,600 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 01:31:33,600 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 01:31:51,334 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:32:08,879 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 01:32:25,870 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-11 01:32:43,415 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 01:33:00,443 INFO    :        | end of iter   0 | time:  5.53s | train loss 0.0000 | 
2023-05-11 01:33:18,383 INFO    :        | end of iter   0 | time:  6.27s | train loss 0.0000 | 
2023-05-11 01:33:35,658 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 01:33:52,875 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 01:34:10,141 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:34:27,618 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 01:34:44,692 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 01:35:01,656 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 01:35:18,999 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 01:35:36,093 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 01:35:53,101 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 01:36:10,184 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 01:36:27,340 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 01:36:44,473 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 01:37:01,749 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 01:37:18,721 INFO    :        | end of iter   0 | time:  5.68s | train loss 0.0000 | 
2023-05-11 01:37:35,890 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 01:37:53,683 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 01:38:11,354 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 01:38:28,271 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 01:38:45,773 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 01:39:03,077 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 01:39:20,424 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:39:37,753 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 01:39:55,025 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 01:40:12,331 INFO    :        | end of iter   0 | time:  6.35s | train loss 0.0000 | 
2023-05-11 01:40:29,744 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 01:40:46,955 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-11 01:41:04,632 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:41:22,210 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 01:41:39,653 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-11 01:41:57,494 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 01:42:14,958 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:42:32,032 INFO    :        | end of iter   0 | time:  5.78s | train loss 0.0000 | 
2023-05-11 01:42:49,025 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 01:43:05,992 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 01:43:22,967 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 01:43:39,933 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-11 01:43:57,036 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 01:44:14,771 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:44:32,590 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 01:44:49,650 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 01:45:06,795 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 01:45:24,158 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 01:45:41,643 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:45:58,501 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 01:45:58,501 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 01:45:58,501 INFO    :    | end of epoch  84 | time: 864.90s | epoch train loss 0.0758 | 
2023-05-11 01:45:58,501 INFO    : [INFO] Found new best model with 0.076 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 01:45:58,843 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 01:45:58,843 INFO    : [INFO] Starting eval for this model ...
2023-05-11 01:46:03,721 INFO    : [INFO] End of valid | time:  4.88s | valid loss 48.1637 | 
2023-05-11 01:46:03,721 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 01:46:03,721 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 01:46:03,721 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 01:46:20,709 INFO    :        | end of iter   0 | time:  5.56s | train loss 0.0000 | 
2023-05-11 01:46:37,974 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 01:46:54,967 INFO    :        | end of iter   0 | time:  5.67s | train loss 0.0000 | 
2023-05-11 01:47:11,928 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 01:47:28,971 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 01:47:45,889 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 01:48:02,963 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 01:48:20,182 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 01:48:37,576 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 01:48:54,688 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 01:49:11,831 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 01:49:28,821 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 01:49:46,044 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 01:50:03,330 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 01:50:20,298 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 01:50:37,408 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 01:50:54,432 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 01:51:11,742 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 01:51:29,247 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 01:51:46,875 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 01:52:04,108 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 01:52:20,861 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 01:52:38,080 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 01:52:55,064 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 01:53:12,417 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 01:53:29,888 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 01:53:46,809 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 01:54:03,875 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 01:54:21,039 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 01:54:38,451 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 01:54:55,617 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 01:55:12,938 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 01:55:30,396 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 01:55:47,913 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 01:56:05,223 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 01:56:22,448 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 01:56:39,908 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 01:56:57,102 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 01:57:14,277 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 01:57:31,265 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-11 01:57:48,417 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 01:58:01,267 INFO    :        | end of iter   0 | time:  1.71s | train loss 0.0000 | 
2023-05-11 01:58:19,057 INFO    :        | end of iter   0 | time:  6.56s | train loss 0.0000 | 
2023-05-11 01:58:36,136 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 01:58:53,239 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 01:59:10,271 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 01:59:27,167 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 01:59:44,594 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 02:00:01,511 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 02:00:18,718 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 02:00:18,719 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 02:00:18,719 INFO    :    | end of epoch  85 | time: 855.00s | epoch train loss 0.0747 | 
2023-05-11 02:00:18,719 INFO    : [INFO] Found new best model with 0.075 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 02:00:18,938 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 02:00:18,938 INFO    : [INFO] Starting eval for this model ...
2023-05-11 02:00:23,625 INFO    : [INFO] End of valid | time:  4.69s | valid loss 48.1955 | 
2023-05-11 02:00:23,625 INFO    : Rouge1:
	p:0.357143, r:0.272727, f:0.309278
Rouge2:
	p:0.122186, r:0.091127, f:0.104396
Rougel:
	p:0.323810, r:0.247273, f:0.280412

2023-05-11 02:00:23,625 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 02:00:23,626 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 02:00:41,389 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 02:00:58,931 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 02:01:16,485 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 02:01:33,842 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:01:51,504 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:02:09,481 INFO    :        | end of iter   0 | time:  6.29s | train loss 0.0000 | 
2023-05-11 02:02:26,876 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 02:02:44,114 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:03:01,113 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 02:03:18,233 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 02:03:35,793 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 02:03:53,307 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 02:04:11,111 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 02:04:28,739 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 02:04:46,290 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:05:03,434 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:05:20,531 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 02:05:37,415 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 02:05:54,614 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:06:11,810 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:06:29,352 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 02:06:46,871 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-11 02:07:04,429 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 02:07:21,589 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:07:38,862 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 02:07:56,324 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 02:08:13,558 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:08:30,259 INFO    :        | end of iter   0 | time:  5.63s | train loss 0.0000 | 
2023-05-11 02:08:47,548 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 02:09:04,781 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:09:22,046 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:09:39,578 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 02:09:56,251 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 02:10:13,361 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:10:30,653 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 02:10:47,869 INFO    :        | end of iter   0 | time:  6.27s | train loss 0.0000 | 
2023-05-11 02:11:05,554 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 02:11:23,080 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 02:11:40,393 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 02:11:58,231 INFO    :        | end of iter   0 | time:  6.40s | train loss 0.0000 | 
2023-05-11 02:12:15,482 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 02:12:33,041 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 02:12:50,473 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 02:13:07,531 INFO    :        | end of iter   0 | time:  5.43s | train loss 0.0000 | 
2023-05-11 02:13:24,526 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 02:13:41,738 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 02:13:58,995 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 02:14:16,263 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 02:14:33,317 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 02:14:50,654 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 02:14:50,654 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 02:14:50,654 INFO    :    | end of epoch  86 | time: 867.03s | epoch train loss 0.0736 | 
2023-05-11 02:14:50,654 INFO    : [INFO] Found new best model with 0.074 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 02:14:50,821 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 02:14:50,822 INFO    : [INFO] Starting eval for this model ...
2023-05-11 02:14:55,261 INFO    : [INFO] End of valid | time:  4.44s | valid loss 48.3634 | 
2023-05-11 02:14:55,261 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 02:14:55,261 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 02:14:55,261 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 02:15:12,162 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:15:29,310 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 02:15:46,062 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 02:16:03,135 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 02:16:20,761 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 02:16:38,166 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 02:16:55,434 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-11 02:17:12,821 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 02:17:29,771 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 02:17:47,147 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 02:18:04,041 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:18:20,751 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 02:18:37,860 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 02:18:54,904 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 02:19:12,187 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 02:19:29,473 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:19:46,337 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-11 02:20:03,242 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:20:20,554 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 02:20:37,606 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 02:20:54,813 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 02:21:11,994 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 02:21:28,937 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 02:21:45,721 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 02:22:02,909 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 02:22:20,533 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 02:22:37,747 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 02:22:54,769 INFO    :        | end of iter   0 | time:  5.72s | train loss 0.0000 | 
2023-05-11 02:23:12,004 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 02:23:29,295 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:23:46,421 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 02:24:03,197 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 02:24:20,509 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 02:24:37,752 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 02:24:54,960 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:25:12,137 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 02:25:29,061 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 02:25:46,026 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 02:26:02,939 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 02:26:19,943 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 02:26:37,180 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:26:54,278 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 02:27:11,032 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 02:27:27,835 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 02:27:44,645 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 02:28:01,625 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 02:28:18,540 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:28:35,713 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 02:28:53,133 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 02:29:10,631 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:29:10,631 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 02:29:10,631 INFO    :    | end of epoch  87 | time: 855.37s | epoch train loss 0.0724 | 
2023-05-11 02:29:10,631 INFO    : [INFO] Found new best model with 0.072 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 02:29:10,840 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 02:29:10,840 INFO    : [INFO] Starting eval for this model ...
2023-05-11 02:29:15,677 INFO    : [INFO] End of valid | time:  4.84s | valid loss 48.3756 | 
2023-05-11 02:29:15,677 INFO    : Rouge1:
	p:0.373206, r:0.283636, f:0.322314
Rouge2:
	p:0.123377, r:0.091127, f:0.104828
Rougel:
	p:0.344498, r:0.261818, f:0.297521

2023-05-11 02:29:15,677 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 02:29:15,677 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 02:29:32,999 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 02:29:50,236 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 02:30:07,027 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 02:30:24,318 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 02:30:41,523 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 02:30:58,715 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:31:15,851 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 02:31:32,973 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:31:49,819 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 02:32:06,433 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 02:32:23,262 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 02:32:40,574 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 02:32:57,655 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 02:33:15,459 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 02:33:32,818 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 02:33:50,187 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 02:34:07,190 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 02:34:24,416 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 02:34:41,298 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 02:34:58,657 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 02:35:15,635 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 02:35:33,178 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 02:35:50,483 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 02:36:07,549 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 02:36:24,835 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-11 02:36:42,132 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 02:36:59,220 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 02:37:16,440 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 02:37:33,352 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 02:37:50,595 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 02:38:07,973 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 02:38:21,371 INFO    :        | end of iter   0 | time:  2.28s | train loss 0.0000 | 
2023-05-11 02:38:38,338 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 02:38:55,475 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 02:39:12,351 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 02:39:29,951 INFO    :        | end of iter   0 | time:  5.96s | train loss 0.0000 | 
2023-05-11 02:39:47,590 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 02:40:05,065 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:40:22,402 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 02:40:39,327 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-11 02:40:56,838 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 02:41:13,991 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 02:41:31,318 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:41:48,095 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 02:42:05,180 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 02:42:22,332 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 02:42:40,085 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 02:42:57,846 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 02:43:14,895 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:43:32,111 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:43:32,111 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 02:43:32,111 INFO    :    | end of epoch  88 | time: 856.43s | epoch train loss 0.0713 | 
2023-05-11 02:43:32,111 INFO    : [INFO] Found new best model with 0.071 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 02:43:32,260 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 02:43:32,260 INFO    : [INFO] Starting eval for this model ...
2023-05-11 02:43:36,927 INFO    : [INFO] End of valid | time:  4.67s | valid loss 48.4583 | 
2023-05-11 02:43:36,927 INFO    : Rouge1:
	p:0.352381, r:0.269091, f:0.305155
Rouge2:
	p:0.114286, r:0.086331, f:0.098361
Rougel:
	p:0.323810, r:0.247273, f:0.280412

2023-05-11 02:43:36,927 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 02:43:36,927 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 02:43:54,322 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-11 02:44:11,522 INFO    :        | end of iter   0 | time:  5.76s | train loss 0.0000 | 
2023-05-11 02:44:29,286 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 02:44:46,284 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 02:45:04,062 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 02:45:21,125 INFO    :        | end of iter   0 | time:  6.14s | train loss 0.0000 | 
2023-05-11 02:45:38,222 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 02:45:55,369 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:46:12,778 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 02:46:30,559 INFO    :        | end of iter   0 | time:  6.57s | train loss 0.0000 | 
2023-05-11 02:46:48,369 INFO    :        | end of iter   0 | time:  6.44s | train loss 0.0000 | 
2023-05-11 02:47:05,996 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 02:47:23,362 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 02:47:41,028 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:47:57,977 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 02:48:15,627 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 02:48:33,038 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 02:48:50,425 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:49:07,462 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 02:49:24,509 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 02:49:41,929 INFO    :        | end of iter   0 | time:  6.20s | train loss 0.0000 | 
2023-05-11 02:49:58,848 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 02:50:16,080 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:50:33,579 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 02:50:51,278 INFO    :        | end of iter   0 | time:  6.08s | train loss 0.0000 | 
2023-05-11 02:51:08,775 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:51:26,243 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 02:51:43,709 INFO    :        | end of iter   0 | time:  5.81s | train loss 0.0000 | 
2023-05-11 02:52:01,603 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 02:52:19,425 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 02:52:37,149 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-11 02:52:54,115 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 02:53:11,147 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:53:27,975 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:53:44,683 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:54:01,890 INFO    :        | end of iter   0 | time:  6.02s | train loss 0.0000 | 
2023-05-11 02:54:18,778 INFO    :        | end of iter   0 | time:  5.59s | train loss 0.0000 | 
2023-05-11 02:54:35,958 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-11 02:54:53,162 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 02:55:10,784 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 02:55:28,278 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 02:55:45,153 INFO    :        | end of iter   0 | time:  5.70s | train loss 0.0000 | 
2023-05-11 02:56:02,446 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 02:56:20,349 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 02:56:37,826 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 02:56:55,092 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 02:57:12,474 INFO    :        | end of iter   0 | time:  6.36s | train loss 0.0000 | 
2023-05-11 02:57:29,575 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 02:57:46,319 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 02:58:03,641 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 02:58:03,642 INFO    : [INFO] The learning rate now is 0.000006
2023-05-11 02:58:03,642 INFO    :    | end of epoch  89 | time: 866.71s | epoch train loss 0.0704 | 
2023-05-11 02:58:03,642 INFO    : [INFO] Found new best model with 0.070 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 02:58:03,834 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 02:58:03,834 INFO    : [INFO] Starting eval for this model ...
2023-05-11 02:58:08,288 INFO    : [INFO] End of valid | time:  4.45s | valid loss 48.4159 | 
2023-05-11 02:58:08,288 INFO    : Rouge1:
	p:0.357143, r:0.272727, f:0.309278
Rouge2:
	p:0.122186, r:0.091127, f:0.104396
Rougel:
	p:0.328571, r:0.250909, f:0.284536

2023-05-11 02:58:08,288 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 02:58:08,288 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 02:58:26,102 INFO    :        | end of iter   0 | time:  6.23s | train loss 0.0000 | 
2023-05-11 02:58:43,210 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 02:59:00,133 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 02:59:17,736 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 02:59:34,537 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 02:59:51,158 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-11 03:00:08,283 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 03:00:25,615 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-11 03:00:42,342 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 03:00:59,213 INFO    :        | end of iter   0 | time:  5.73s | train loss 0.0000 | 
2023-05-11 03:01:16,150 INFO    :        | end of iter   0 | time:  5.52s | train loss 0.0000 | 
2023-05-11 03:01:34,021 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 03:01:51,611 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 03:02:08,892 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 03:02:26,511 INFO    :        | end of iter   0 | time:  6.01s | train loss 0.0000 | 
2023-05-11 03:02:43,894 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 03:03:01,238 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 03:03:18,339 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 03:03:35,310 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 03:03:52,721 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 03:04:09,578 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 03:04:27,244 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 03:04:44,704 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 03:05:01,592 INFO    :        | end of iter   0 | time:  5.93s | train loss 0.0000 | 
2023-05-11 03:05:19,390 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 03:05:37,006 INFO    :        | end of iter   0 | time:  6.13s | train loss 0.0000 | 
2023-05-11 03:05:54,505 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 03:06:11,469 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 03:06:28,313 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 03:06:45,554 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 03:07:02,673 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 03:07:20,243 INFO    :        | end of iter   0 | time:  6.26s | train loss 0.0000 | 
2023-05-11 03:07:37,356 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 03:07:54,522 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 03:08:11,754 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 03:08:29,041 INFO    :        | end of iter   0 | time:  6.11s | train loss 0.0000 | 
2023-05-11 03:08:46,224 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 03:09:03,490 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 03:09:20,330 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 03:09:37,385 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 03:09:54,201 INFO    :        | end of iter   0 | time:  5.75s | train loss 0.0000 | 
2023-05-11 03:10:11,381 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 03:10:28,427 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 03:10:46,040 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 03:11:03,281 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 03:11:20,553 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 03:11:37,885 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 03:11:54,565 INFO    :        | end of iter   0 | time:  5.62s | train loss 0.0000 | 
2023-05-11 03:12:12,140 INFO    :        | end of iter   0 | time:  6.27s | train loss 0.0000 | 
2023-05-11 03:12:29,768 INFO    :        | end of iter   0 | time:  6.12s | train loss 0.0000 | 
2023-05-11 03:12:29,768 INFO    : [INFO] The learning rate now is 0.000005
2023-05-11 03:12:29,769 INFO    :    | end of epoch  90 | time: 861.48s | epoch train loss 0.0693 | 
2023-05-11 03:12:29,769 INFO    : [INFO] Found new best model with 0.069 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 03:12:29,927 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 03:12:29,928 INFO    : [INFO] Starting eval for this model ...
2023-05-11 03:12:34,565 INFO    : [INFO] End of valid | time:  4.64s | valid loss 48.4872 | 
2023-05-11 03:12:34,565 INFO    : Rouge1:
	p:0.357143, r:0.272727, f:0.309278
Rouge2:
	p:0.122186, r:0.091127, f:0.104396
Rougel:
	p:0.328571, r:0.250909, f:0.284536

2023-05-11 03:12:34,565 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 03:12:34,566 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 03:12:51,890 INFO    :        | end of iter   0 | time:  5.94s | train loss 0.0000 | 
2023-05-11 03:13:09,313 INFO    :        | end of iter   0 | time:  5.90s | train loss 0.0000 | 
2023-05-11 03:13:26,870 INFO    :        | end of iter   0 | time:  6.07s | train loss 0.0000 | 
2023-05-11 03:13:44,581 INFO    :        | end of iter   0 | time:  6.33s | train loss 0.0000 | 
2023-05-11 03:14:01,688 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 03:14:18,819 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 03:14:36,138 INFO    :        | end of iter   0 | time:  6.25s | train loss 0.0000 | 
2023-05-11 03:14:53,650 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 03:15:11,214 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 03:15:28,701 INFO    :        | end of iter   0 | time:  6.22s | train loss 0.0000 | 
2023-05-11 03:15:46,178 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 03:16:03,517 INFO    :        | end of iter   0 | time:  5.79s | train loss 0.0000 | 
2023-05-11 03:16:20,918 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 03:16:38,341 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 03:16:55,197 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 03:17:12,479 INFO    :        | end of iter   0 | time:  5.98s | train loss 0.0000 | 
2023-05-11 03:17:30,194 INFO    :        | end of iter   0 | time:  6.42s | train loss 0.0000 | 
2023-05-11 03:17:47,451 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 03:18:04,384 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 03:18:21,554 INFO    :        | end of iter   0 | time:  6.29s | train loss 0.0000 | 
2023-05-11 03:18:38,676 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 03:18:56,010 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 03:19:13,253 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 03:19:30,256 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 03:19:47,715 INFO    :        | end of iter   0 | time:  6.18s | train loss 0.0000 | 
2023-05-11 03:20:05,401 INFO    :        | end of iter   0 | time:  6.33s | train loss 0.0000 | 
2023-05-11 03:20:22,777 INFO    :        | end of iter   0 | time:  6.35s | train loss 0.0000 | 
2023-05-11 03:20:39,844 INFO    :        | end of iter   0 | time:  5.85s | train loss 0.0000 | 
2023-05-11 03:20:56,900 INFO    :        | end of iter   0 | time:  6.15s | train loss 0.0000 | 
2023-05-11 03:21:14,109 INFO    :        | end of iter   0 | time:  6.36s | train loss 0.0000 | 
2023-05-11 03:21:31,442 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 03:21:48,430 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 03:22:05,293 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 03:22:22,497 INFO    :        | end of iter   0 | time:  6.09s | train loss 0.0000 | 
2023-05-11 03:22:39,324 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 03:22:57,023 INFO    :        | end of iter   0 | time:  6.30s | train loss 0.0000 | 
2023-05-11 03:23:13,997 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 03:23:31,087 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 03:23:47,963 INFO    :        | end of iter   0 | time:  6.05s | train loss 0.0000 | 
2023-05-11 03:24:05,301 INFO    :        | end of iter   0 | time:  6.17s | train loss 0.0000 | 
2023-05-11 03:24:22,409 INFO    :        | end of iter   0 | time:  6.10s | train loss 0.0000 | 
2023-05-11 03:24:39,445 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 03:24:56,786 INFO    :        | end of iter   0 | time:  6.19s | train loss 0.0000 | 
2023-05-11 03:25:14,078 INFO    :        | end of iter   0 | time:  6.00s | train loss 0.0000 | 
2023-05-11 03:25:31,477 INFO    :        | end of iter   0 | time:  5.74s | train loss 0.0000 | 
2023-05-11 03:25:48,669 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-11 03:26:06,032 INFO    :        | end of iter   0 | time:  6.34s | train loss 0.0000 | 
2023-05-11 03:26:23,180 INFO    :        | end of iter   0 | time:  6.03s | train loss 0.0000 | 
2023-05-11 03:26:39,873 INFO    :        | end of iter   0 | time:  5.77s | train loss 0.0000 | 
2023-05-11 03:26:56,800 INFO    :        | end of iter   0 | time:  5.95s | train loss 0.0000 | 
2023-05-11 03:26:56,800 INFO    : [INFO] The learning rate now is 0.000005
2023-05-11 03:26:56,800 INFO    :    | end of epoch  91 | time: 862.23s | epoch train loss 0.0684 | 
2023-05-11 03:26:56,800 INFO    : [INFO] Found new best model with 0.068 running_train_loss. Saving to models_tweet/train/bestmodel
2023-05-11 03:26:57,165 INFO    : [INFO] Saving model to models_tweet/train/bestmodel
2023-05-11 03:26:57,166 INFO    : [INFO] Starting eval for this model ...
2023-05-11 03:27:01,674 INFO    : [INFO] End of valid | time:  4.51s | valid loss 48.5416 | 
2023-05-11 03:27:01,674 INFO    : Rouge1:
	p:0.357143, r:0.272727, f:0.309278
Rouge2:
	p:0.122186, r:0.091127, f:0.104396
Rougel:
	p:0.328571, r:0.250909, f:0.284536

2023-05-11 03:27:01,674 INFO    : [INFO] Validset match_true 1, pred 15, true 4, total 150, match 133
2023-05-11 03:27:01,674 INFO    : [INFO] The size of totalset is 1, sent_number is 150, accu is 0.886667, precision is 0.066667, recall is 0.250000, F is 0.105263
2023-05-11 03:27:18,888 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 03:27:36,273 INFO    :        | end of iter   0 | time:  6.21s | train loss 0.0000 | 
2023-05-11 03:27:53,045 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 03:28:10,406 INFO    :        | end of iter   0 | time:  6.28s | train loss 0.0000 | 
2023-05-11 03:28:27,235 INFO    :        | end of iter   0 | time:  5.91s | train loss 0.0000 | 
2023-05-11 03:28:44,601 INFO    :        | end of iter   0 | time:  6.04s | train loss 0.0000 | 
2023-05-11 03:29:01,733 INFO    :        | end of iter   0 | time:  5.89s | train loss 0.0000 | 
2023-05-11 03:29:19,138 INFO    :        | end of iter   0 | time:  6.27s | train loss 0.0000 | 
2023-05-11 03:29:36,339 INFO    :        | end of iter   0 | time:  5.99s | train loss 0.0000 | 
2023-05-11 03:29:53,409 INFO    :        | end of iter   0 | time:  5.88s | train loss 0.0000 | 
2023-05-11 03:30:10,898 INFO    :        | end of iter   0 | time:  5.80s | train loss 0.0000 | 
2023-05-11 03:30:28,373 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 03:30:45,693 INFO    :        | end of iter   0 | time:  5.71s | train loss 0.0000 | 
2023-05-11 03:31:03,098 INFO    :        | end of iter   0 | time:  5.69s | train loss 0.0000 | 
2023-05-11 03:31:20,007 INFO    :        | end of iter   0 | time:  5.84s | train loss 0.0000 | 
2023-05-11 03:31:37,098 INFO    :        | end of iter   0 | time:  5.92s | train loss 0.0000 | 
2023-05-11 03:31:54,173 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 03:32:11,567 INFO    :        | end of iter   0 | time:  6.06s | train loss 0.0000 | 
2023-05-11 03:32:28,990 INFO    :        | end of iter   0 | time:  5.97s | train loss 0.0000 | 
2023-05-11 03:32:46,262 INFO    :        | end of iter   0 | time:  6.16s | train loss 0.0000 | 
2023-05-11 03:33:03,789 INFO    :        | end of iter   0 | time:  6.32s | train loss 0.0000 | 
2023-05-11 03:33:21,452 INFO    :        | end of iter   0 | time:  6.24s | train loss 0.0000 | 
2023-05-11 03:33:38,486 INFO    :        | end of iter   0 | time:  5.86s | train loss 0.0000 | 
2023-05-11 03:33:55,780 INFO    :        | end of iter   0 | time:  5.87s | train loss 0.0000 | 
2023-05-11 03:34:13,130 INFO    :        | end of iter   0 | time:  5.82s | train loss 0.0000 | 
2023-05-11 03:34:30,417 INFO    :        | end of iter   0 | time:  5.83s | train loss 0.0000 | 
2023-05-11 03:34:48,594 INFO    :        | end of iter   0 | time:  6.68s | train loss 0.0000 | 
2023-05-11 03:35:06,277 INFO    :        | end of iter   0 | time:  6.49s | train loss 0.0000 | 
